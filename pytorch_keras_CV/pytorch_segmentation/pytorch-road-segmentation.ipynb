{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm.autonotebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\nfrom glob import glob\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\n\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:09.676096Z","iopub.execute_input":"2022-07-22T10:55:09.676491Z","iopub.status.idle":"2022-07-22T10:55:12.395869Z","shell.execute_reply.started":"2022-07-22T10:55:09.676415Z","shell.execute_reply":"2022-07-22T10:55:12.393956Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f'Currently using \"{device}\" device.')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:12.398036Z","iopub.execute_input":"2022-07-22T10:55:12.399266Z","iopub.status.idle":"2022-07-22T10:55:12.471732Z","shell.execute_reply.started":"2022-07-22T10:55:12.399223Z","shell.execute_reply":"2022-07-22T10:55:12.469906Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"np.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\n\nbatch_size = 4\nimage_size = 256\nnum_classes = 1\nepochs = 30\npath = r'seg_model.pth'","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:12.473547Z","iopub.execute_input":"2022-07-22T10:55:12.476130Z","iopub.status.idle":"2022-07-22T10:55:12.485823Z","shell.execute_reply.started":"2022-07-22T10:55:12.476102Z","shell.execute_reply":"2022-07-22T10:55:12.485062Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"path_images = r'../input/crack-segmentation-dataset/crack_segmentation_dataset/images/'\npath_masks = r'../input/crack-segmentation-dataset/crack_segmentation_dataset/masks/'\n\nimages_paths = glob(path_images + '*.jpg')\nmasks_paths = glob(path_masks + '*.jpg')\n\nimages_paths = sorted([str(p) for p in images_paths])\nmasks_paths = sorted([str(p) for p in masks_paths])\n\ndf = pd.DataFrame({'images': images_paths, 'masks': masks_paths})\n\ndf.sample(2)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:12.487216Z","iopub.execute_input":"2022-07-22T10:55:12.487870Z","iopub.status.idle":"2022-07-22T10:55:14.800712Z","shell.execute_reply.started":"2022-07-22T10:55:12.487836Z","shell.execute_reply":"2022-07-22T10:55:14.799652Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(df, test_size=200, shuffle=True, random_state=seed)\ntrain, valid = train_test_split(train, test_size=0.15, shuffle=True, random_state=seed)\n\nprint(f'Train size: {len(train)}, validation size: {len(valid)} and test size: {len(test)}')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:14.803895Z","iopub.execute_input":"2022-07-22T10:55:14.804332Z","iopub.status.idle":"2022-07-22T10:55:14.815790Z","shell.execute_reply.started":"2022-07-22T10:55:14.804302Z","shell.execute_reply":"2022-07-22T10:55:14.814625Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n    T.ToPILImage(),\n    T.Resize((image_size, image_size)),\n    # add some color augmentations manually if needed\n    T.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:14.818168Z","iopub.execute_input":"2022-07-22T10:55:14.818643Z","iopub.status.idle":"2022-07-22T10:55:14.824139Z","shell.execute_reply.started":"2022-07-22T10:55:14.818560Z","shell.execute_reply":"2022-07-22T10:55:14.822789Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class CrackDataset(Dataset):\n    def __init__(self, dataset, transforms=train_transforms):\n        self.dataset = dataset.reset_index(drop=True)\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, ix):\n        row = self.dataset.loc[ix].squeeze()\n        image_path = row['images']\n        mask_path = row['masks']\n        \n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image_tensor = self.transforms(image).float()\n        \n        mask = cv2.imread(mask_path)\n        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n        mask = cv2.resize(mask, (image_size, image_size))\n        _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n        \n        mask_tensor = torch.as_tensor(mask[None], dtype=torch.float32)\n        \n        # mask_tensor /= 255.\n        \n        return image_tensor, mask_tensor\n    \n    def collate_fn(self, batch):\n        images, masks = tuple(zip(*batch))\n        images = [img[None] for img in images]\n        masks = [msk[None] for msk in masks]\n        images, masks = [torch.cat(i).to(device) for i in [images, masks]]\n        return images, masks","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:14.826325Z","iopub.execute_input":"2022-07-22T10:55:14.826745Z","iopub.status.idle":"2022-07-22T10:55:14.840808Z","shell.execute_reply.started":"2022-07-22T10:55:14.826711Z","shell.execute_reply":"2022-07-22T10:55:14.839760Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ds = CrackDataset(train)\nplt.subplot(121)\nplt.imshow(ds[1][0].cpu().detach().numpy().transpose(1,2,0))\nplt.subplot(122)\nplt.imshow(ds[1][1].cpu().detach().numpy().transpose(1,2,0), cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:14.841946Z","iopub.execute_input":"2022-07-22T10:55:14.842969Z","iopub.status.idle":"2022-07-22T10:55:15.333901Z","shell.execute_reply.started":"2022-07-22T10:55:14.842918Z","shell.execute_reply":"2022-07-22T10:55:15.332815Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef validate_test_image(model, dataset):\n    idx = np.random.randint(len(dataset))\n    dataset = dataset.reset_index(drop=True)\n    row = dataset.loc[idx].squeeze()\n    \n    image = cv2.imread(row['images'])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image_tensor = train_transforms(image).unsqueeze(0).to(device)\n    \n    mask = cv2.imread(row['masks'])\n    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n    mask = cv2.resize(mask, (image_size, image_size))\n    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n    \n    model.eval()\n    output = model(image_tensor)\n    output = output['out'][0].cpu().detach().numpy().transpose(1,2,0)\n    \n    plt.figure(figsize=(8, 4))\n    plt.subplot(131)\n    plt.title('Original image')\n    plt.imshow(image)\n    \n    plt.subplot(132)\n    plt.title('Original mask')\n    plt.imshow(mask, cmap='gray')\n    \n    plt.subplot(133)\n    plt.title('Predicted mask')\n    plt.imshow(output, cmap='gray')\n    \n    plt.tight_layout()\n    plt.show()\n    plt.pause(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:15.335045Z","iopub.execute_input":"2022-07-22T10:55:15.336200Z","iopub.status.idle":"2022-07-22T10:55:15.347597Z","shell.execute_reply.started":"2022-07-22T10:55:15.336165Z","shell.execute_reply":"2022-07-22T10:55:15.346430Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset = CrackDataset(train)\nvalid_dataset = CrackDataset(valid)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=valid_dataset.collate_fn, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:15.350550Z","iopub.execute_input":"2022-07-22T10:55:15.351342Z","iopub.status.idle":"2022-07-22T10:55:15.363804Z","shell.execute_reply.started":"2022-07-22T10:55:15.351282Z","shell.execute_reply":"2022-07-22T10:55:15.362679Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n\ndef get_model(output_channels=1, unfreeze=True):\n    model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True, progress=False)\n    \n    for param in model.parameters():\n        param.requires_grad = unfreeze\n    \n    model.classifier = DeepLabHead(2048, output_channels)\n    \n    return model.to(device)\n\nmodel = get_model()  # set output_channels = 3 if we work with colored masks","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:15.367077Z","iopub.execute_input":"2022-07-22T10:55:15.368188Z","iopub.status.idle":"2022-07-22T10:55:30.344998Z","shell.execute_reply.started":"2022-07-22T10:55:15.368144Z","shell.execute_reply":"2022-07-22T10:55:30.344000Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=5, min_delta=0, path=path):\n        self.path = path\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = np.inf\n        self.early_stop = False\n        \n    def __call__(self, val_loss, model=None):\n        if self.best_loss - val_loss > self.min_delta:\n            torch.save(model.state_dict(), self.path)\n            print(f'Model saved to: {self.path}')\n            self.best_loss = val_loss\n            self.counter = 0\n        elif self.best_loss - val_loss < self.min_delta:\n            self.counter += 1\n            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n            if self.counter >= self.patience:\n                print('INFO: Early stopping')\n                self.early_stop = True","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:30.346728Z","iopub.execute_input":"2022-07-22T10:55:30.347160Z","iopub.status.idle":"2022-07-22T10:55:30.355700Z","shell.execute_reply.started":"2022-07-22T10:55:30.347117Z","shell.execute_reply":"2022-07-22T10:55:30.354369Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # if unfreeze=True -> 1e-4, 1e-5, so not to ruin good init w\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, min_lr=1e-6, factor=0.1)\nearly = EarlyStopping()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:30.357464Z","iopub.execute_input":"2022-07-22T10:55:30.358182Z","iopub.status.idle":"2022-07-22T10:55:30.372785Z","shell.execute_reply.started":"2022-07-22T10:55:30.358147Z","shell.execute_reply":"2022-07-22T10:55:30.371813Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train_one_batch(batch, model, criterion, optimizer):\n    images, masks = batch\n    optimizer.zero_grad()\n    output = model(images)\n    loss = criterion(output['out'], masks)\n    loss.backward()\n    optimizer.step()\n    \n    return loss.item()\n\n@torch.no_grad()\ndef validate_one_batch(batch, model, criterion):\n    images, masks = batch\n    output = model(images)\n    loss = criterion(output['out'], masks)\n    return loss.item()","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:30.376843Z","iopub.execute_input":"2022-07-22T10:55:30.377109Z","iopub.status.idle":"2022-07-22T10:55:30.385213Z","shell.execute_reply.started":"2022-07-22T10:55:30.377086Z","shell.execute_reply":"2022-07-22T10:55:30.384351Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_losses, valid_losses = [], []\n\nfor epoch in range(epochs):\n\n    print(f'Epoch {epoch + 1}/{epochs}')\n    epoch_train_losses, epoch_valid_losses = [], []\n    \n    model.train()\n    for _, batch in enumerate(tqdm(train_dataloader, leave=False)):\n        batch_train_loss = train_one_batch(batch, model, criterion, optimizer)\n        epoch_train_losses.append(batch_train_loss)\n    epoch_train_loss = np.array(epoch_train_losses).mean()\n    train_losses.append(epoch_train_loss)\n\n    print(f'Train loss: {epoch_train_loss:.4f}.')\n    \n    model.eval()\n    for i, batch in enumerate(tqdm(valid_dataloader, leave=False)):\n        batch_valid_loss = validate_one_batch(batch, model, criterion)\n        epoch_valid_losses.append(batch_valid_loss)\n    epoch_valid_loss = np.array(epoch_valid_losses).mean()\n    valid_losses.append(epoch_valid_loss)\n    print(f'Valid loss: {epoch_valid_loss:.4f}.')\n    print('-'*50)    \n    \n    validate_test_image(model, test)\n    \n    scheduler.step(epoch_valid_loss)\n    early(epoch_valid_loss, model=model)\n    if early.early_stop:\n        print(f'Validation loss did not improve for {early.patience} epochs. Training stopped.')\n        model.load_state_dict(torch.load(path))\n        break","metadata":{"execution":{"iopub.status.busy":"2022-07-22T10:55:30.386416Z","iopub.execute_input":"2022-07-22T10:55:30.387176Z","iopub.status.idle":"2022-07-22T11:14:09.571820Z","shell.execute_reply.started":"2022-07-22T10:55:30.387139Z","shell.execute_reply":"2022-07-22T11:14:09.570443Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"[Link to the training process result](https://www.kaggle.com/code/pankratozzi/pytorch-road-segmentation)","metadata":{}}]}