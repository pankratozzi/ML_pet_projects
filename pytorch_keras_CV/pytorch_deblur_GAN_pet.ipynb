{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torchvision import transforms as T\nimport torch.autograd as autograd\n\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nimport functools\nfrom functools import partial","metadata":{"id":"hTiW5Yl9uJov","execution":{"iopub.status.busy":"2022-06-18T06:04:45.494316Z","iopub.execute_input":"2022-06-18T06:04:45.494725Z","iopub.status.idle":"2022-06-18T06:04:48.458882Z","shell.execute_reply.started":"2022-06-18T06:04:45.494648Z","shell.execute_reply":"2022-06-18T06:04:48.457965Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"blurred = glob('../input/hideblur/HIDE_dataset/train' + '/*.png')\nsharp = glob('../input/hideblur/HIDE_dataset/GT' + '/*.png')\n\nblurred_name = sorted([str(x) for x in blurred])\nsharp_name = sorted([str(x) for x in sharp])\n\nblurred_idx = [int(str(x).replace('.MP4', '').split('fromGOPR')[-1].split('.')[0]) for x in blurred_name]\nsharp_idx = [int(str(x).replace('.MP4', '').split('fromGOPR')[-1].split('.')[0]) for x in sharp_name]\n\nexisting_idx = np.nonzero(np.isin(sharp_idx, blurred_idx))[0]\nsharp_name = np.array(sharp_name)\n\ndf = pd.DataFrame(data={'blur': blurred_name, 'sharp': sharp_name[existing_idx]})\ndf.sample(5)","metadata":{"id":"zsfrYNKQuRdD","outputId":"beef3b08-5272-4901-b138-7ce6c37e0b3e","execution":{"iopub.status.busy":"2022-06-18T06:04:52.106410Z","iopub.execute_input":"2022-06-18T06:04:52.106932Z","iopub.status.idle":"2022-06-18T06:04:52.534097Z","shell.execute_reply.started":"2022-06-18T06:04:52.106887Z","shell.execute_reply":"2022-06-18T06:04:52.533354Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df, test_size=500, shuffle=True, random_state=123)\ntrain.shape, valid.shape","metadata":{"id":"wzcJPPR6pliw","outputId":"273122bd-e241-4586-9d73-1158d03e6081","execution":{"iopub.status.busy":"2022-06-18T06:04:55.335020Z","iopub.execute_input":"2022-06-18T06:04:55.335704Z","iopub.status.idle":"2022-06-18T06:04:55.347240Z","shell.execute_reply.started":"2022-06-18T06:04:55.335663Z","shell.execute_reply":"2022-06-18T06:04:55.346213Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"torch.random.manual_seed(123)\ntorch.cuda.manual_seed(123)\nnp.random.seed(123)\n\nBATCH_SIZE = 16  # when batch_size is not very small use batch_norm instead instance_norm\nIMAGE_HEIGHT = 640\nIMAGE_WIDTH = 360\nepochs = 50\nFINE_SIZE = 256\ngp_lambda = 10\ncontent_loss_lambda = 100\n\nPATH = r'/content/drive/My Drive/data/deblur_model.pth'\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"id":"Hq3ec4xNhEYr","outputId":"40096f6f-307b-4f4c-806e-1b672b8f13bc","execution":{"iopub.status.busy":"2022-06-18T06:04:57.544090Z","iopub.execute_input":"2022-06-18T06:04:57.544611Z","iopub.status.idle":"2022-06-18T06:04:57.628587Z","shell.execute_reply.started":"2022-06-18T06:04:57.544570Z","shell.execute_reply":"2022-06-18T06:04:57.627514Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((FINE_SIZE, FINE_SIZE)), #, Image.BICUBIC),\n                              T.RandomHorizontalFlip(p=0.2),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])\nvalid_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((FINE_SIZE, FINE_SIZE)), # Image.BICUBIC),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])","metadata":{"id":"r4J5fqq3kD9L","execution":{"iopub.status.busy":"2022-06-18T06:05:00.704691Z","iopub.execute_input":"2022-06-18T06:05:00.705183Z","iopub.status.idle":"2022-06-18T06:05:00.718077Z","shell.execute_reply.started":"2022-06-18T06:05:00.705139Z","shell.execute_reply":"2022-06-18T06:05:00.717075Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BlurDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, ix):\n        row = self.df.iloc[ix].squeeze()\n        blurred_img = cv2.imread(row['blur'])\n        blurred_img = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB)\n        sharp_img = cv2.imread(row['sharp'])\n        sharp_img = cv2.cvtColor(sharp_img, cv2.COLOR_BGR2RGB)\n        return blurred_img, sharp_img\n\n    def collate_fn(self, batch):\n        blurs, sharps = list(zip(*batch))\n        blurs = [self.transforms(img)[None] for img in blurs]\n        sharps = [self.transforms(img)[None] for img in sharps]\n        blurs, sharps = [torch.cat(i).to(device) for i in [blurs, sharps]]\n        return blurs, sharps","metadata":{"id":"gcvvOrWylyOq","execution":{"iopub.status.busy":"2022-06-18T06:05:02.789213Z","iopub.execute_input":"2022-06-18T06:05:02.789667Z","iopub.status.idle":"2022-06-18T06:05:02.806686Z","shell.execute_reply.started":"2022-06-18T06:05:02.789630Z","shell.execute_reply":"2022-06-18T06:05:02.805471Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset = BlurDataset(train, transforms=train_transforms)\nvalid_dataset = BlurDataset(valid, transforms=valid_transforms)\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn)\nvalid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=True, collate_fn=valid_dataset.collate_fn)","metadata":{"id":"tNANTOeEoS94","execution":{"iopub.status.busy":"2022-06-18T06:05:07.632137Z","iopub.execute_input":"2022-06-18T06:05:07.632479Z","iopub.status.idle":"2022-06-18T06:05:07.638287Z","shell.execute_reply.started":"2022-06-18T06:05:07.632449Z","shell.execute_reply":"2022-06-18T06:05:07.637117Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_norm_layer(layer_type='batch'):\n    if layer_type == 'batch':\n        return nn.BatchNorm2d\n    else:\n        return partial(nn.InstanceNorm2d, track_running_stats=False)\n\ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)\n\nclass ResNetBlock(nn.Module):\n    def __init__(self, dim, norm_layer, use_bias, dropout=False):\n        super(ResNetBlock, self).__init__()\n        sequence = list()\n\n        sequence += [nn.ReflectionPad2d(1)]\n\n        sequence += [\n            nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias),\n            norm_layer(dim),\n            nn.ReLU(True)\n        ]\n        if dropout:\n            sequence += [nn.Dropout(0.5)]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = x + self.model(x)\n        return out\n\nclass Generator(nn.Module):\n\n    def __init__(self, input_nc, output_nc, ngf=64, n_blocks=9, norm_type='batch'):\n        super(Generator, self).__init__()\n\n        norm_layer = get_norm_layer(norm_type)\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func != nn.BatchNorm2d\n        else:\n            use_bias = norm_layer != nn.BatchNorm2d\n\n        sequence = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(input_nc, ngf, kernel_size=7, stride=1, padding=0, bias=use_bias),\n            norm_layer(ngf),\n            nn.ReLU(True)\n        ]\n\n        n_downsampling = 2\n        for i in range(n_downsampling):\n            mult = 2 ** i\n            sequence += [\n                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n                norm_layer(ngf * mult * 2),\n                nn.ReLU(True)\n            ]\n\n        for i in range(n_blocks):\n            sequence += [\n                ResNetBlock(ngf * 2 ** n_downsampling, norm_layer, use_bias)\n            ]\n\n        for i in range(n_downsampling):\n            mult = 2 ** (n_downsampling - i)\n            sequence += [\n                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1,\n                                   output_padding=1, bias=use_bias),\n                norm_layer(int(ngf * mult / 2)),\n                nn.ReLU(True)\n            ]\n\n        sequence += [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(ngf, output_nc, kernel_size=7, stride=1, padding=0),\n            nn.Tanh()\n        ]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = self.model(x)\n        out = x + out\n        out = torch.clamp(out, min=-1, max=1)\n        return out\n\nclass Discriminator(nn.Module):\n\n    def __init__(self, input_nc, ndf=64, n_layers=3, use_sigmoid=False, norm_type='batch'):\n        super(Discriminator, self).__init__()\n\n        norm_layer = get_norm_layer(norm_type)\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func != nn.BatchNorm2d\n        else:\n            use_bias = norm_layer != nn.BatchNorm2d\n\n        kernel_size = 4\n        padding = 1\n        sequence = [\n            nn.Conv2d(input_nc, ndf, kernel_size=kernel_size, stride=2, padding=padding),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        nf_mult = 1\n        for n in range(1, n_layers):\n            nf_mult_prev = nf_mult\n            nf_mult = min(2 ** n, 8)\n            sequence += [\n                nn.utils.spectral_norm(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kernel_size, stride=2, padding=padding,\n                          bias=use_bias), n_power_iterations=2),\n                norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, True),\n                nn.Dropout(0.5)\n            ]\n\n        nf_mult_prev = nf_mult\n        nf_mult = min(2 ** n_layers, 8)\n        sequence += [\n            nn.utils.spectral_norm(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kernel_size, stride=1, padding=padding,\n                      bias=use_bias), n_power_iterations=2),\n            norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, True),\n            nn.Dropout(0.5)\n        ]\n\n        sequence += [\n            nn.Conv2d(ndf * nf_mult, 1, kernel_size=kernel_size, stride=1, padding=padding)\n        ]\n\n        if use_sigmoid:\n            sequence += [nn.Sigmoid()]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = self.model(x)\n        return out","metadata":{"id":"y1ZsWy34q9mM","execution":{"iopub.status.busy":"2022-06-18T06:05:16.273882Z","iopub.execute_input":"2022-06-18T06:05:16.274458Z","iopub.status.idle":"2022-06-18T06:05:16.305324Z","shell.execute_reply.started":"2022-06-18T06:05:16.274421Z","shell.execute_reply":"2022-06-18T06:05:16.304483Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# generator = Generator(3, 3, n_blocks=9).apply(init_weights).to(device)\ndiscriminator = Discriminator(3).apply(init_weights).to(device)\n\nCONV3_3_IN_VGG_19 = torchvision.models.vgg19(pretrained=True, progress=False).features[:15].to(device)","metadata":{"id":"YdVrXi4Ku2am","execution":{"iopub.status.busy":"2022-06-18T06:05:21.933705Z","iopub.execute_input":"2022-06-18T06:05:21.934067Z","iopub.status.idle":"2022-06-18T06:05:44.912757Z","shell.execute_reply.started":"2022-06-18T06:05:21.934037Z","shell.execute_reply":"2022-06-18T06:05:44.911771Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!pip install -qq torchsummary\nfrom torchsummary import summary\n\nsummary(generator, (3, FINE_SIZE, FINE_SIZE))","metadata":{"id":"OM5HuhAxusbZ","outputId":"499f299c-195a-45d3-dadf-08eb82ae111b","execution":{"iopub.status.busy":"2022-06-18T06:12:09.551541Z","iopub.execute_input":"2022-06-18T06:12:09.551976Z","iopub.status.idle":"2022-06-18T06:12:22.534260Z","shell.execute_reply.started":"2022-06-18T06:12:09.551933Z","shell.execute_reply":"2022-06-18T06:12:22.533158Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"summary(discriminator, (3, FINE_SIZE, FINE_SIZE))","metadata":{"id":"vz5Evdj9wQvm","outputId":"3d98ecda-ae47-42d9-b2cc-a8f84561be4b","execution":{"iopub.status.busy":"2022-06-17T16:39:13.212003Z","iopub.execute_input":"2022-06-17T16:39:13.212396Z","iopub.status.idle":"2022-06-17T16:39:14.135199Z","shell.execute_reply.started":"2022-06-17T16:39:13.212353Z","shell.execute_reply":"2022-06-17T16:39:14.134382Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"summary(CONV3_3_IN_VGG_19, (3, FINE_SIZE, FINE_SIZE))","metadata":{"id":"64-9FgHPFzJ4","outputId":"4f8f3b16-6980-4a6e-b0d3-3dfe4f1d71d8","execution":{"iopub.status.busy":"2022-06-17T16:39:14.136530Z","iopub.execute_input":"2022-06-17T16:39:14.137284Z","iopub.status.idle":"2022-06-17T16:39:14.153918Z","shell.execute_reply.started":"2022-06-17T16:39:14.137245Z","shell.execute_reply":"2022-06-17T16:39:14.153064Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def load_model(path, device=device):\n    if device == 'cuda':\n        checkpoint = torch.load(path)\n    else:\n        checkpoint = torch.load(path, map_location=torch.device('cpu'))\n    epoch = checkpoint['epoch']\n    generator = checkpoint['G']\n    discriminator = checkpoint['D']\n    optimizerG = checkpoint['optimizerG']\n    optimizerD = checkpoint['optimizerD']\n    return generator, discriminator, optimizerG, optimizerD, epoch\n\ndef PSNR(deblurred, sharp):\n    mse = torch.mean((deblurred - sharp) ** 2)\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1\n    return 10 * np.log10(PIXEL_MAX ** 2 / mse)\n\nclass WGANLoss(nn.Module):\n    def forward(self, mtype, **kwargs):\n        if mtype == 'G':\n            deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n            return -deblurred_discriminator_out.mean()\n\n        elif mtype == 'D':  \n            gp_lambda = kwargs['gp_lambda']\n            interpolates = kwargs['interpolates']\n            interpolates_discriminator_out = kwargs['interpolates_discriminator_out']\n            sharp_discriminator_out = kwargs['sharp_discriminator_out']\n            deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n\n            wgan_loss = deblurred_discriminator_out.mean() - sharp_discriminator_out.mean()\n\n            gradients = autograd.grad(outputs=interpolates_discriminator_out, inputs=interpolates,\n                                      grad_outputs=torch.ones(interpolates_discriminator_out.size()).to(device),\n                                      retain_graph=True,\n                                      create_graph=True)[0]\n            gradient_penalty = ((gradients.view(gradients.size(0), -1).norm(2, dim=1) - 1) ** 2).mean()\n\n            return wgan_loss, gp_lambda * gradient_penalty\n\nclass ContentLoss(nn.Module):\n    def __init__(self):\n        super(ContentLoss, self).__init__()\n        self.normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\n    def forward(self, deblurred, sharp, model=CONV3_3_IN_VGG_19):\n        model.eval()\n        deblurred = (deblurred + 1) * 0.5\n        sharp = (sharp + 1) * 0.5\n\n        deblurred = nn.functional.interpolate(deblurred, mode='bilinear', size=(224, 224), align_corners=False)\n        sharp = nn.functional.interpolate(sharp, mode='bilinear', size=(224, 224), align_corners=False)\n\n        deblurred, sharp = [[self.normalize(img)[None] for img in imgs] for imgs in [deblurred, sharp]]\n        deblurred, sharp = [torch.cat(i) for i in [deblurred, sharp]]\n\n        deblurred_feature_map = model.forward(deblurred)\n        sharp_feature_map = model.forward(sharp).detach()\n        loss = nn.functional.mse_loss(deblurred_feature_map, sharp_feature_map)\n\n        return loss\n\ndef simple_gan_loss(mtype, **kwargs):\n    if mtype == 'G':\n        deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n        return nn.functional.binary_cross_entropy(deblurred_discriminator_out, torch.ones_like(deblurred_discriminator_out))\n\n    elif mtype == 'D':\n        sharp_discriminator_out = kwargs['sharp_discriminator_out']\n        deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n        real_loss = nn.functional.binary_cross_entropy(sharp_discriminator_out, torch.ones_like(sharp_discriminator_out))\n        fake_loss = nn.functional.binary_cross_entropy(deblurred_discriminator_out, torch.zeros_like(deblurred_discriminator_out))\n        return (real_loss + fake_loss) / 2.0","metadata":{"id":"rZ1gLaJWxBk3","execution":{"iopub.status.busy":"2022-06-18T06:05:44.918037Z","iopub.execute_input":"2022-06-18T06:05:44.918550Z","iopub.status.idle":"2022-06-18T06:05:44.951023Z","shell.execute_reply.started":"2022-06-18T06:05:44.918513Z","shell.execute_reply":"2022-06-18T06:05:44.949370Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"criterion_wgan = WGANLoss()\ncriterion_content = ContentLoss()\n\noptimizerG = torch.optim.AdamW(generator.parameters(), lr=0.0001, betas=(0.5, 0.999), amsgrad=True, weight_decay=0.)\noptimizerD = torch.optim.AdamW(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999), amsgrad=True, weight_decay=0.)\n\n#optimizerG = torch.optim.AdamW(generator.parameters(), lr=1e-4, betas=(0., 0.9))\n#optimizerD = torch.optim.AdamW(discriminator.parameters(), lr=1e-4, betas=(0., 0.9), weight_decay=1e-3)\n\n#lr_lambda = lambda epoch: (1 - (epoch - 150) / 150) if epoch > 150 else 1\n#schedulerG = torch.optim.lr_scheduler.LambdaLR(optimizerG, lr_lambda=lr_lambda)\n#schedulerD = torch.optim.lr_scheduler.LambdaLR(optimizerD, lr_lambda=lr_lambda)","metadata":{"id":"VfwAckSRy9G0","execution":{"iopub.status.busy":"2022-06-18T10:19:49.389428Z","iopub.execute_input":"2022-06-18T10:19:49.389781Z","iopub.status.idle":"2022-06-18T10:19:49.397616Z","shell.execute_reply.started":"2022-06-18T10:19:49.389752Z","shell.execute_reply":"2022-06-18T10:19:49.396754Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def denormalize(image_tensor):\n    return (image_tensor + 1) / 2.0\n\ndef train_one_batch(generator, discriminator, data, criterionW, criterionC, optimizerG, optimizerD, critic_updates=5):\n    generator.train()\n    discriminator.train()\n\n    blur, sharp = data\n\n    discriminator_loss = 0\n    for param in discriminator.parameters():\n        param.requires_grad = True\n\n    for _ in range(critic_updates):\n\n        deblur = generator(blur)\n\n        d_sharp_out = discriminator(sharp)\n        d_deblur_out = discriminator(deblur)\n\n        optimizerD.zero_grad()\n        alpha = np.random.random()\n        interpolates = alpha * sharp + (1 - alpha) * deblur\n        interpolates_discriminator_out = discriminator(interpolates)\n        kwargs = {\n                  'gp_lambda': gp_lambda,\n                  'interpolates': interpolates, \n                  'interpolates_discriminator_out': interpolates_discriminator_out, \n                  'sharp_discriminator_out': d_sharp_out, \n                  'deblurred_discriminator_out': d_deblur_out,  \n                  }\n        wgan_loss_d, gp_d = criterionW('D', **kwargs)\n        discriminator_loss_per_update = wgan_loss_d + gp_d\n        discriminator_loss_per_update.backward(retain_graph=critic_updates>1)\n        optimizerD.step()\n        discriminator_loss += discriminator_loss_per_update.item()\n    discriminator_loss /= critic_updates\n\n    for param in discriminator.parameters():\n        param.requires_grad = False\n    optimizerG.zero_grad()\n    \n    deblur = generator(blur)\n    d_deblur_out = discriminator(deblur)\n    \n    kwargs = {\n              'deblurred_discriminator_out': d_deblur_out, \n              }    \n    wgan_loss_g = criterionW('G', **kwargs)\n    content_loss_g = criterionC(deblur, sharp) * content_loss_lambda\n    generator_loss = wgan_loss_g + content_loss_g\n    generator_loss.backward()\n    optimizerG.step()\n\n    with torch.no_grad():\n        denormalized_sharp = denormalize(sharp).cpu().detach()\n        denormalized_deblurred = denormalize(deblur).cpu().detach()\n\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    return discriminator_loss, generator_loss.item(), metric\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterionW, criterionC):\n    generator.eval()\n    discriminator.eval()\n\n    blur, sharp = data\n    deblur = generator(blur)\n    d_deblur = discriminator(deblur)\n\n    kwargs = {\n              'deblurred_discriminator_out': d_deblur, }\n    adversarial_loss_g = criterionW('G', **kwargs)\n    content_loss_g = criterionC(deblur, sharp) * content_loss_lambda\n    loss_g = adversarial_loss_g + content_loss_g\n\n    denormalized_sharp = denormalize(sharp).cpu().detach()\n    denormalized_deblurred = denormalize(deblur).cpu().detach()\n\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    return loss_g.item(), metric\n\n@torch.no_grad()\ndef visual_validate(data, model):\n    img, tar = data\n    model.eval()\n    out = model(img)\n    out, img, tar = [denormalize(tensor) for tensor in [out, img, tar]]\n    out, img, tar = [tensor.squeeze().cpu().detach().numpy().transpose(1,2,0) for tensor in [out, img, tar]]\n    plt.figure(figsize=(12,14))\n    plt.subplot(131)\n    plt.title('Blurred')\n    plt.imshow(img)\n    plt.subplot(132)\n    plt.title('Target')\n    plt.imshow(tar)\n    plt.subplot(133)\n    plt.title('Deblurred')\n    plt.imshow(out)\n    plt.show()\n    plt.pause(0.001)","metadata":{"id":"_WoaCwuH1xXa","execution":{"iopub.status.busy":"2022-06-18T06:05:46.233711Z","iopub.execute_input":"2022-06-18T06:05:46.234804Z","iopub.status.idle":"2022-06-18T06:05:46.264722Z","shell.execute_reply.started":"2022-06-18T06:05:46.234745Z","shell.execute_reply":"2022-06-18T06:05:46.262366Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# generator, discriminator, optimizerG, optimizerD, ep = load_model(PATH)","metadata":{"id":"DWF6Uu0oGjVL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_d_losses, train_g_losses, valid_g_losses = [], [], []\ntrain_metric_total, valid_metric_total = [], []\n\ntry:\n    ep += 1\nexcept NameError:\n    ep = 0\n\nfor epoch in range(ep, epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n\n    train_epoch_d_loss, train_epoch_g_loss, train_epoch_metric = [],[],[]\n    for i, data in enumerate(tqdm(train_dataloader, leave=False)): \n        with autograd.set_detect_anomaly(True): \n            d_loss, g_loss, metric = train_one_batch(generator, discriminator, data, criterion_wgan, criterion_content,\n                                                     optimizerG, optimizerD, critic_updates=3)\n        train_epoch_d_loss.append(d_loss)\n        train_epoch_g_loss.append(g_loss)\n        train_epoch_metric.append(metric)\n    epoch_d_loss = np.array(train_epoch_d_loss).mean()\n    epoch_g_loss = np.array(train_epoch_g_loss).mean()\n    train_metric = np.array(train_epoch_metric).mean()\n    train_d_losses.append(epoch_d_loss)\n    train_g_losses.append(epoch_g_loss)\n    train_metric_total.append(train_metric)\n    print(f'Train D loss: {epoch_d_loss:.4f}, train G loss: {epoch_g_loss:.4f}')\n    print(f'Train metric: {train_metric:.4f}')\n\n    valid_epoch_g_loss, valid_epoch_metric = [],[]\n    for i, data in enumerate(tqdm(valid_dataloader, leave=False)):\n        g_loss, metric = validate(generator, discriminator, data, criterion_wgan, criterion_content)\n        valid_epoch_g_loss.append(g_loss)\n        valid_epoch_metric.append(metric)\n    epoch_g_loss = np.array(valid_epoch_g_loss).mean()\n    valid_metric = np.array(valid_epoch_metric).mean()\n    valid_g_losses.append(epoch_g_loss)\n    valid_metric_total.append(valid_metric)\n    print(f'Valid G loss: {epoch_g_loss:.4f}')\n    print(f'Valid metric: {valid_metric:.4f}')\n    print('-'*50)    \n\n    #schedulerD.step()\n    #schedulerG.step()\n    if (epoch + 1) % 2 == 0:\n        checkpoint = {\n                      'epoch': epoch,     \n                      'G': generator,\n                      'D': discriminator,\n                      'optimizerG': optimizerG,\n                      'optimizerD': optimizerD,\n                      }\n        torch.save(checkpoint, PATH)\n        data = next(iter(valid_dataloader))\n        visual_validate(data, generator)","metadata":{"id":"sfNzeLp1aggs","outputId":"a7c02774-bcfe-4125-ef47-46f4d2f58d57","execution":{"iopub.status.busy":"2022-06-18T10:20:02.566061Z","iopub.execute_input":"2022-06-18T10:20:02.566516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* critic updates = 3\n* pretrained generator\n* lrD=lrG = 1e-4\n* D norm = batch","metadata":{}},{"cell_type":"markdown","source":"#### Image colorizing analogue","metadata":{"id":"mZDGkcSS6gUr"}},{"cell_type":"code","source":"from fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet\n\n\ndef build_res_unet(n_input=3, n_output=3, size=256, pretrained=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    body = create_body(resnet18, pretrained=pretrained, n_in=n_input)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n\nclass Generator(nn.Module):\n    def __init__(self, pretrained=False):\n        super(Generator, self).__init__()\n        self.backbone = build_res_unet(pretrained=pretrained)\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        out = self.tanh(self.backbone(x))\n        out = x + out\n        out = torch.clamp(out, min=-1, max=1)\n        return out\n\ndef pretrain_generator(model, train_dl, opt, criterion, epochs):\n    for e in tqdm(range(epochs), total=epochs, leave=False):\n        for data in tqdm(train_dl, total=len(train_dl), leave=False):\n            blur, sharp = data\n            deblur = model(blur)\n            loss = criterion(deblur, sharp)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n\ngenerator = Generator(pretrained=True)\noptimizer = torch.optim.AdamW(generator.parameters(), lr=0.0001, betas=(0.5, 0.999), amsgrad=True, weight_decay=0.)\ncriterion = ContentLoss()\npretrain_generator(generator, train_dataloader, optimizer, criterion, 20)\n\ntorch.save(generator.state_dict(), 'generator.pth')","metadata":{"id":"NptRx29d2n9N","execution":{"iopub.status.busy":"2022-06-18T06:18:41.052213Z","iopub.execute_input":"2022-06-18T06:18:41.052729Z","iopub.status.idle":"2022-06-18T10:08:29.288629Z","shell.execute_reply.started":"2022-06-18T06:18:41.052682Z","shell.execute_reply":"2022-06-18T10:08:29.286891Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"generator.load_state_dict(torch.load('generator.pth'))","metadata":{"id":"45jCn9cCHZMn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(5):\n    data = next(iter(valid_dataloader))\n    visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:11:13.314679Z","iopub.execute_input":"2022-06-18T10:11:13.315114Z","iopub.status.idle":"2022-06-18T10:11:16.231791Z","shell.execute_reply.started":"2022-06-18T10:11:13.315068Z","shell.execute_reply":"2022-06-18T10:11:16.230978Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'../working')\nfrom IPython.display import FileLink\nFileLink(r'generator.pth')","metadata":{"execution":{"iopub.status.busy":"2022-06-18T10:08:40.774193Z","iopub.execute_input":"2022-06-18T10:08:40.774781Z","iopub.status.idle":"2022-06-18T10:08:40.783133Z","shell.execute_reply.started":"2022-06-18T10:08:40.774744Z","shell.execute_reply":"2022-06-18T10:08:40.782165Z"},"trusted":true},"execution_count":15,"outputs":[]}]}