{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/pankratozzi/Yolov7-training\n!pip install -qq pytorch_accelerated func_to_script pycocotools\n    \nimport sys\nsys.path.append(\"/kaggle/working/Yolov7-training/\")","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:58:09.391712Z","iopub.execute_input":"2022-12-18T21:58:09.392127Z","iopub.status.idle":"2022-12-18T21:58:49.413652Z","shell.execute_reply.started":"2022-12-18T21:58:09.392047Z","shell.execute_reply":"2022-12-18T21:58:49.411977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\n\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import trange\nfrom tqdm.contrib.concurrent import process_map\n\nimport random\nfrom functools import partial\nfrom pathlib import Path\nfrom glob import glob\n\nfrom func_to_script import script\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom pytorch_accelerated.callbacks import (\n    TrainerCallback,\n    EarlyStoppingCallback,\n    ModelEmaCallback,\n    ProgressBarCallback,\n    SaveBestModelCallback,\n    get_default_callbacks,\n)\n\nfrom pytorch_accelerated.utils import local_process_zero_only\nfrom pytorch_accelerated.schedulers import CosineLrScheduler\nfrom torch.utils.data import Dataset\n\nfrom yolov7 import create_yolov7_model\nfrom yolov7.dataset import (\n    Yolov7Dataset,\n    create_base_transforms,\n    create_yolov7_transforms,\n    yolov7_collate_fn,\n)\nfrom yolov7.evaluation import CalculateMeanAveragePrecisionCallback\nfrom yolov7.loss_factory import create_yolov7_loss\nfrom yolov7.mosaic import MosaicMixupDataset, create_post_mosaic_transform\nfrom yolov7.trainer import Yolov7Trainer, filter_eval_predictions\nfrom yolov7.utils import SaveBatchesCallback, Yolov7ModelEma\n\nfrom yolov7.plotting import show_image","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:58:49.418637Z","iopub.execute_input":"2022-12-18T21:58:49.418950Z","iopub.status.idle":"2022-12-18T21:58:53.617273Z","shell.execute_reply.started":"2022-12-18T21:58:49.418923Z","shell.execute_reply":"2022-12-18T21:58:53.616293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:58:53.618795Z","iopub.execute_input":"2022-12-18T21:58:53.619563Z","iopub.status.idle":"2022-12-18T21:58:53.628933Z","shell.execute_reply.started":"2022-12-18T21:58:53.619527Z","shell.execute_reply":"2022-12-18T21:58:53.627873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using {device.upper()} device.\")\n\nroot = \"/kaggle/input/wider-data/WIDER/\"\npretrained = True  # True to get COCO weights\nimage_size = 640\nbatch_size = 2\nnum_epochs = 16\nnum_classes = 1","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:58:53.631921Z","iopub.execute_input":"2022-12-18T21:58:53.632691Z","iopub.status.idle":"2022-12-18T21:58:53.694204Z","shell.execute_reply.started":"2022-12-18T21:58:53.632629Z","shell.execute_reply":"2022-12-18T21:58:53.693247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_yolov7_model(\n        architecture=\"yolov7\", num_classes=num_classes, pretrained=pretrained\n    ).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:58:53.695699Z","iopub.execute_input":"2022-12-18T21:58:53.696241Z","iopub.status.idle":"2022-12-18T21:59:12.873352Z","shell.execute_reply.started":"2022-12-18T21:58:53.696206Z","shell.execute_reply":"2022-12-18T21:59:12.872299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_annots(file, max_faces=20):\n    def get_coords(line):\n        coor = line.split(\" \")\n        xywh = [int(coor[i]) for i in range(4)] if(len(coor) > 4) else None\n        return xywh\n    \n    data = []\n    \n    with open(file, \"r\") as f:\n        lines = f.readlines()\n        for i, line in enumerate(lines):\n            if \".jpg\" in line:\n                annot = {\n                    \"path\": line.strip(),\n                    \"box_num\": int(lines[i+1]),\n                    \"boxes\": [],\n                    \"label\": [],\n                }\n                if max_faces >= annot[\"box_num\"]:\n                    for j in range(annot[\"box_num\"]):\n                        box = get_coords(lines[i+2+j].replace(\"\\n\", \"\"))\n                        if box is not None:\n                            x,y,w,h = box\n                            \n                            # xmin, ymin, xmax, ymax\n                            box = [x, y, x+w, y+h]\n                            annot[\"boxes\"].append(box)\n                            annot[\"label\"].append(0)  # 1\n                    if len(annot[\"boxes\"]) > 0:\n                        data.append(annot)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:59:12.875192Z","iopub.execute_input":"2022-12-18T21:59:12.875598Z","iopub.status.idle":"2022-12-18T21:59:12.887269Z","shell.execute_reply.started":"2022-12-18T21:59:12.875563Z","shell.execute_reply":"2022-12-18T21:59:12.884368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = read_annots(\"../input/wider-data/WIDER/wider_face_train_bbx_gt.txt\")\nvalid = read_annots(\"../input/wider-data/WIDER/wider_face_val_bbx_gt.txt\")","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:59:12.889067Z","iopub.execute_input":"2022-12-18T21:59:12.889456Z","iopub.status.idle":"2022-12-18T21:59:13.348640Z","shell.execute_reply.started":"2022-12-18T21:59:12.889413Z","shell.execute_reply":"2022-12-18T21:59:13.347549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = pd.DataFrame.from_records(train, columns=list(train[0].keys())).explode(\"boxes\").reset_index(drop=True)\ntrain_points = pd.DataFrame(x_train[\"boxes\"].values.tolist(), columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"], index=x_train.index)\nx_train = pd.concat([x_train, train_points], axis=1)\nx_train = x_train[~((x_train.xmin == x_train.xmax) | (x_train.ymin == x_train.ymax))]\nx_train[\"class_id\"] = 0\nimage_ids = {p: i for i, p in enumerate(x_train[\"path\"].unique())}\nx_train[\"image_id\"] = x_train[\"path\"].map(image_ids)\n\nx_train[\"w\"] = x_train[\"xmax\"] - x_train[\"xmin\"]\nx_train[\"h\"] = x_train[\"ymax\"] - x_train[\"ymin\"]\n\nx_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:59:13.350186Z","iopub.execute_input":"2022-12-18T21:59:13.350916Z","iopub.status.idle":"2022-12-18T21:59:13.484604Z","shell.execute_reply.started":"2022-12-18T21:59:13.350877Z","shell.execute_reply":"2022-12-18T21:59:13.483521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_valid = pd.DataFrame.from_records(valid, columns=list(train[0].keys())).explode(\"boxes\").reset_index(drop=True)\nvalid_points = pd.DataFrame(x_valid[\"boxes\"].values.tolist(), columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"], index=x_valid.index)\nx_valid = pd.concat([x_valid, valid_points], axis=1)\nx_valid = x_valid[~((x_valid.xmin == x_valid.xmax) | (x_valid.ymin == x_valid.ymax))]\n\nx_valid[\"class_id\"] = 0\nimage_ids = {p: i for i, p in enumerate(x_valid[\"path\"].unique())}\nx_valid[\"image_id\"] = x_valid[\"path\"].map(image_ids)\n\nx_valid[\"w\"] = x_valid[\"xmax\"] - x_valid[\"xmin\"]\nx_valid[\"h\"] = x_valid[\"ymax\"] - x_valid[\"ymin\"]\n\nx_valid.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:59:13.486003Z","iopub.execute_input":"2022-12-18T21:59:13.486533Z","iopub.status.idle":"2022-12-18T21:59:13.539651Z","shell.execute_reply.started":"2022-12-18T21:59:13.486497Z","shell.execute_reply":"2022-12-18T21:59:13.538631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_paths = glob(\"../input/wider-data/WIDER/WIDER_test/\"+\"*/*.jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:59:13.543599Z","iopub.execute_input":"2022-12-18T21:59:13.543873Z","iopub.status.idle":"2022-12-18T21:59:16.678594Z","shell.execute_reply.started":"2022-12-18T21:59:13.543849Z","shell.execute_reply":"2022-12-18T21:59:16.677566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from yolov7.anchors import (calculate_resized_gt_wh, \n                            calculate_resized_gt_wh, \n                            calculate_best_possible_recall,\n                            calculate_best_anchor_ratio, \n                            estimate_anchors\n                           )\nfrom scipy.cluster.vq import kmeans\nLOSS_ANCHOR_MULTIPLE_THRESHOLD = 4.0\n\n\ndef find_image_sizes(path):\n    image = Image.open(root+\"WIDER_train/\"+path)\n    image = np.array(image)\n    return path, (image.shape[1], image.shape[0])\n\nimage_sizes = process_map(find_image_sizes, [path for path in x_train.path.unique()])\n\nimage_sizes_df = pd.DataFrame(dict(image_sizes)).T.reset_index().rename(columns={\"index\": \"path\", 0: \"image_w\", 1: \"image_h\"})\nx_train = x_train.merge(image_sizes_df, on=\"path\", how=\"left\")\n\n# use one bbox from image to calculate anchors, otherwise dims in gt_wh and image_sizes don't match\nraw_gt_wh = x_train.groupby(\"path\").agg({\"w\": \"last\", \"h\": \"last\"}).values\nimage_sizes = image_sizes_df.groupby(\"path\").agg({\"image_w\": \"last\", \"image_h\": \"last\"}).values\n\ngt_wh = calculate_resized_gt_wh(raw_gt_wh, image_sizes, target_image_size=640)\n\ncurrent_anchors = model.detection_head.anchor_grid.clone().cpu().view(-1, 2)\n\nrecall = calculate_best_possible_recall(current_anchors, gt_wh)\nprint(f\"Best possible recall with given images: {recall.item()}\")\n\nif recall < 0.98:\n\n    proposed_anchors = estimate_anchors(9, gt_wh)\n    recall = calculate_best_possible_recall(proposed_anchors, gt_wh)\n    print(f\"Best possible new recall with given images: {recall.item()}\")\n\n    model.update_anchors(np.sort(proposed_anchors, axis=0))  # sort as inbuilt method throws error\nelse:\n    print(f\"Default anchors are suitable for this task.\")","metadata":{"execution":{"iopub.status.busy":"2022-12-18T21:59:16.680189Z","iopub.execute_input":"2022-12-18T21:59:16.680645Z","iopub.status.idle":"2022-12-18T22:01:35.240244Z","shell.execute_reply.started":"2022-12-18T21:59:16.680609Z","shell.execute_reply":"2022-12-18T22:01:35.239119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FaceDataset(Dataset):\n    def __init__(self, data, train=True, transforms=None):\n        self.annotations_df = data\n        self.transforms = transforms\n        self.sub_path = \"WIDER_train/\" if train else \"WIDER_val/\"\n\n    def __len__(self):\n        return self.annotations_df.image_id.nunique()\n\n    def __getitem__(self, ix):\n        image_id = self.annotations_df[\"image_id\"].unique()[ix]\n        image_info = self.annotations_df[self.annotations_df.image_id == image_id]\n        path = image_info[\"path\"].iloc[0]\n        \n        image = Image.open(root + self.sub_path + path).convert(\"RGB\")\n        image = np.array(image)\n        image_hw = image.shape[:2]\n\n        xyxy_bboxes = image_info[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n        class_ids = image_info[\"class_id\"].values\n\n        if self.transforms is not None:\n            transformed = self.transforms(\n                image=image, bboxes=xyxy_bboxes, labels=class_ids\n            )\n            image = transformed[\"image\"]\n            xyxy_bboxes = np.array(transformed[\"bboxes\"])\n            class_ids = np.array(transformed[\"labels\"])\n\n        return image, xyxy_bboxes, class_ids, image_id, image_hw","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:01:35.242054Z","iopub.execute_input":"2022-12-18T22:01:35.242745Z","iopub.status.idle":"2022-12-18T22:01:35.252872Z","shell.execute_reply.started":"2022-12-18T22:01:35.242705Z","shell.execute_reply":"2022-12-18T22:01:35.251586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = FaceDataset(x_train, transforms=create_base_transforms(image_size))\nvalid_ds = FaceDataset(x_valid, train=False)\n\nmds = MosaicMixupDataset(\n        train_ds,\n        apply_mixup_probability=0.15,\n        post_mosaic_transforms=create_post_mosaic_transform(\n        output_height=image_size, output_width=image_size\n        ),\n    )\nif pretrained:\n    # disable mosaic if finetuning\n    mds.disable()\n    \ntrain_yds = Yolov7Dataset(\n    mds,\n    create_yolov7_transforms(training=True, image_size=(image_size, image_size)),\n)\neval_yds = Yolov7Dataset(\n    valid_ds,\n    create_yolov7_transforms(training=False, image_size=(image_size, image_size)),\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:01:35.254479Z","iopub.execute_input":"2022-12-18T22:01:35.254944Z","iopub.status.idle":"2022-12-18T22:01:35.268856Z","shell.execute_reply.started":"2022-12-18T22:01:35.254912Z","shell.execute_reply":"2022-12-18T22:01:35.267851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_groups = model.get_parameter_groups()\n\nloss_func = create_yolov7_loss(model, image_size=image_size)\n\noptimizer = torch.optim.SGD(\n    param_groups[\"other_params\"], lr=0.01, momentum=0.9, nesterov=True  # 0.937\n)\n\ncalculate_map_callback = (\n    CalculateMeanAveragePrecisionCallback.create_from_targets_df(\n        targets_df=x_valid[\n            [\"image_id\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"class_id\"]\n        ],\n        image_ids=set(x_valid.image_id.unique()),\n        iou_threshold=0.2,\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:01:35.271362Z","iopub.execute_input":"2022-12-18T22:01:35.272195Z","iopub.status.idle":"2022-12-18T22:01:35.336307Z","shell.execute_reply.started":"2022-12-18T22:01:35.272111Z","shell.execute_reply":"2022-12-18T22:01:35.335435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PlotImageCallback(TrainerCallback):\n    def __init__(self, image_paths):\n        self.image_paths = image_paths\n        \n    def plot_image(self):\n        idx = np.random.randint(len(self.image_paths))\n        path = self.image_paths[idx]\n        image = Image.open(path).convert(\"RGB\").resize((image_size, image_size))\n        image = np.array(image)\n        image_tensor = torch.FloatTensor(image / 255.).permute(2,0,1).unsqueeze(0).to(device)\n        \n        model.eval()\n        with torch.no_grad():\n            out = model(image_tensor)\n        output = model.postprocess(out, conf_thres=0.001, max_detections=100, multiple_labels_per_box=True)  # postprocess 3 fpn outputs\n        output = filter_eval_predictions(output, confidence_threshold=0.2, nms_threshold=0.65)  # nms\n        output = output[0].cpu().detach().numpy()\n        boxes = output[:, :4].tolist()\n        labels = output[:, -1].astype(int).tolist()\n\n        show_image(image, bboxes=boxes, \n                   class_labels=[\"face\"]*len(boxes), \n                   bbox_format=\"xyxy\")\n        \n        model.train()\n\n    def on_eval_epoch_end(self, trainer, **kwargs):\n        self.plot_image()","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:31:19.027507Z","iopub.execute_input":"2022-12-18T22:31:19.027897Z","iopub.status.idle":"2022-12-18T22:31:19.038016Z","shell.execute_reply.started":"2022-12-18T22:31:19.027866Z","shell.execute_reply":"2022-12-18T22:31:19.036778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Yolov7Trainer(\n        model=model,\n        optimizer=optimizer,\n        loss_func=loss_func,\n        filter_eval_predictions_fn=partial(\n            filter_eval_predictions, confidence_threshold=0.01, nms_threshold=0.3\n        ),\n        callbacks=[\n                    PlotImageCallback(test_paths),\n                    calculate_map_callback,\n                    ModelEmaCallback(\n                        decay=0.9999,\n                        model_ema=Yolov7ModelEma,\n                        callbacks=[ProgressBarCallback, calculate_map_callback],\n                    ),\n                    SaveBestModelCallback(watch_metric=\"map\", greater_is_better=True),\n                    SaveBatchesCallback(\"./batches\", num_images_per_batch=2),\n                    EarlyStoppingCallback(\n                        early_stopping_patience=3,\n                        watch_metric=\"map\",\n                        greater_is_better=True,\n                        early_stopping_threshold=0.001,\n                    ),\n                    *get_default_callbacks(progress_bar=False),  # True \n                ],\n    )","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:01:35.350656Z","iopub.execute_input":"2022-12-18T22:01:35.351071Z","iopub.status.idle":"2022-12-18T22:01:35.359423Z","shell.execute_reply.started":"2022-12-18T22:01:35.351038Z","shell.execute_reply":"2022-12-18T22:01:35.358097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate scaled weight decay and gradient accumulation steps (simulates larger batch size)\ntotal_batch_size = (\n    batch_size * trainer._accelerator.num_processes\n)  # batch size across all processes\n\nnominal_batch_size = 64\nnum_accumulate_steps = max(round(nominal_batch_size / total_batch_size), 1)\nbase_weight_decay = 0.0005\nscaled_weight_decay = (\n    base_weight_decay * total_batch_size * num_accumulate_steps / nominal_batch_size\n)\n\noptimizer.add_param_group(\n    {\"params\": param_groups[\"conv_weights\"], \"weight_decay\": scaled_weight_decay}\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:01:35.361183Z","iopub.execute_input":"2022-12-18T22:01:35.361611Z","iopub.status.idle":"2022-12-18T22:01:35.372030Z","shell.execute_reply.started":"2022-12-18T22:01:35.361578Z","shell.execute_reply":"2022-12-18T22:01:35.371044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train(\n        num_epochs=num_epochs,\n        train_dataset=train_yds,\n        eval_dataset=eval_yds,\n        per_device_batch_size=batch_size,\n        create_scheduler_fn=CosineLrScheduler.create_scheduler_fn(\n            num_warmup_epochs=2,  # 5\n            num_cooldown_epochs=2,  # 5\n            k_decay=2,\n        ),\n        collate_fn=yolov7_collate_fn,\n        gradient_accumulation_steps=num_accumulate_steps,\n    )","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:01:35.373549Z","iopub.execute_input":"2022-12-18T22:01:35.374042Z","iopub.status.idle":"2022-12-18T22:28:15.606044Z","shell.execute_reply.started":"2022-12-18T22:01:35.374008Z","shell.execute_reply":"2022-12-18T22:28:15.604354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotter = PlotImageCallback(test_paths)\n\nfor _ in range(10):\n    plotter.plot_image()","metadata":{"execution":{"iopub.status.busy":"2022-12-18T22:31:33.582301Z","iopub.execute_input":"2022-12-18T22:31:33.583587Z","iopub.status.idle":"2022-12-18T22:31:38.739075Z","shell.execute_reply.started":"2022-12-18T22:31:33.583537Z","shell.execute_reply":"2022-12-18T22:31:38.738291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# [SEE RESULTS: param tunning needed + more epochs](https://www.kaggle.com/code/pankratozzi/pytorch-yolov7-widerface-accelerated)","metadata":{}}]}