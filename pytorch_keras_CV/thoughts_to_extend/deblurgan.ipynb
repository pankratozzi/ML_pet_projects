{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n!pip install -qU torchsummary\nfrom torchsummary import summary\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nfrom torch.nn.utils import spectral_norm\nimport torch.autograd as autograd\n\nimport cv2\nfrom PIL import Image\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom functools import partial\n\nseed = 42","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-14T06:04:19.340647Z","iopub.execute_input":"2022-04-14T06:04:19.341102Z","iopub.status.idle":"2022-04-14T06:04:31.603311Z","shell.execute_reply.started":"2022-04-14T06:04:19.340982Z","shell.execute_reply":"2022-04-14T06:04:31.602513Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"torch.random.manual_seed(seed)\nnp.random.seed(seed)\n\nBATCH_SIZE = 2\nIMAGE_HEIGHT = 640\nIMAGE_WIDTH = 360\nepochs = 300\nFINE_SIZE = 256\ngp_lambda = 10\ncontent_loss_lambda = 100\n\nPATH = r'./deblur_model.pth'\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Currently using {device.upper()} device')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:04:31.606950Z","iopub.execute_input":"2022-04-14T06:04:31.607160Z","iopub.status.idle":"2022-04-14T06:04:31.667996Z","shell.execute_reply.started":"2022-04-14T06:04:31.607135Z","shell.execute_reply":"2022-04-14T06:04:31.667269Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = '../input/blur-dataset/'\nblurred = glob(path + 'motion_blurred' + '/*')\nsharp = glob(path + 'sharp' + '/*')\n\nblurred = sorted([str(x) for x in blurred])\nsharp = sorted([str(x) for x in sharp])\n\ndf = pd.DataFrame(data={'blur': blurred, 'sharp': sharp})\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:04:31.669360Z","iopub.execute_input":"2022-04-14T06:04:31.669650Z","iopub.status.idle":"2022-04-14T06:04:31.929057Z","shell.execute_reply.started":"2022-04-14T06:04:31.669614Z","shell.execute_reply":"2022-04-14T06:04:31.928219Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(df, test_size=5, shuffle=True, random_state=123)\ntrain, valid = train_test_split(train, test_size=30, shuffle=True, random_state=123)\nprint(f'Train size: {train.shape[0]}, valid size: {valid.shape[0]}, test size: {test.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:04:31.930857Z","iopub.execute_input":"2022-04-14T06:04:31.931183Z","iopub.status.idle":"2022-04-14T06:04:31.940683Z","shell.execute_reply.started":"2022-04-14T06:04:31.931146Z","shell.execute_reply":"2022-04-14T06:04:31.939759Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.BICUBIC),\n                              T.RandomHorizontalFlip(p=0.2),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])\nvalid_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT), Image.BICUBIC),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])\ninvTrans = T.Compose([ T.Normalize(mean = [ 0., 0., 0. ],\n                                   std = [ 1/0.5, 1/0.5, 1/0.5 ]),\n                       T.Normalize(mean = [ -0.5, -0.5, -0.5 ],\n                                   std = [ 1., 1., 1. ]),\n                               ])","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:04:35.352585Z","iopub.execute_input":"2022-04-14T06:04:35.353124Z","iopub.status.idle":"2022-04-14T06:04:35.360832Z","shell.execute_reply.started":"2022-04-14T06:04:35.353085Z","shell.execute_reply":"2022-04-14T06:04:35.359925Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BlurDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, ix):\n        row = self.df.iloc[ix].squeeze()\n        blurred_img = cv2.imread(row['blur'])\n        blurred_img = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB)\n        sharp_img = cv2.imread(row['sharp'])\n        sharp_img = cv2.cvtColor(sharp_img, cv2.COLOR_BGR2RGB)\n        return blurred_img, sharp_img\n\n    def collate_fn(self, batch):\n        blurs, sharps = list(zip(*batch))\n        blurs = [self.transforms(img)[None] for img in blurs]\n        sharps = [self.transforms(img)[None] for img in sharps]\n        blurs, sharps = [torch.cat(i).to(device) for i in [blurs, sharps]]\n        return blurs, sharps","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:04:38.647890Z","iopub.execute_input":"2022-04-14T06:04:38.648420Z","iopub.status.idle":"2022-04-14T06:04:38.657247Z","shell.execute_reply.started":"2022-04-14T06:04:38.648379Z","shell.execute_reply":"2022-04-14T06:04:38.656291Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset = BlurDataset(train, transforms=train_transforms)\nvalid_dataset = BlurDataset(valid, transforms=valid_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=train_dataset.collate_fn)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False, collate_fn=valid_dataset.collate_fn)\n\n# imgA = invTrans(imgA).squeeze().detach().cpu().numpy().transpose(1,2,0)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:04:40.737336Z","iopub.execute_input":"2022-04-14T06:04:40.737604Z","iopub.status.idle":"2022-04-14T06:04:40.743468Z","shell.execute_reply.started":"2022-04-14T06:04:40.737575Z","shell.execute_reply":"2022-04-14T06:04:40.742407Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_norm_layer():\n    return partial(nn.InstanceNorm2d, track_running_stats=False)\n\ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)\n\nclass ResNetBlock(nn.Module):\n    def __init__(self, dim, norm_layer, use_bias):\n        super(ResNetBlock, self).__init__()\n        sequence = list()\n\n        sequence += [nn.ReflectionPad2d(1)]\n\n        sequence += [\n            nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias),\n            norm_layer(dim),\n            nn.ReLU(True)\n        ]\n\n        sequence += [nn.Dropout(0.5)]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = x + self.model(x)\n        return out\n\nclass Generator(nn.Module):\n\n    def __init__(self, input_nc, output_nc, ngf=64, n_blocks=9):\n        super(Generator, self).__init__()\n\n        norm_layer = get_norm_layer()\n        use_bias = norm_layer.func != nn.BatchNorm2d\n\n        sequence = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(input_nc, ngf, kernel_size=7, stride=1, padding=0, bias=use_bias),\n            norm_layer(ngf),\n            nn.ReLU(True)\n        ]\n\n        n_downsampling = 2\n        for i in range(n_downsampling):\n            mult = 2 ** i\n            sequence += [\n                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n                norm_layer(ngf * mult * 2),\n                nn.ReLU(True)\n            ]\n\n        for i in range(n_blocks):\n            sequence += [\n                ResNetBlock(ngf * 2 ** n_downsampling, norm_layer, use_bias)\n            ]\n\n        for i in range(n_downsampling):\n            mult = 2 ** (n_downsampling - i)\n            sequence += [\n                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1,\n                                   output_padding=1, bias=use_bias),\n                norm_layer(int(ngf * mult / 2)),\n                nn.ReLU(True)\n            ]\n        sequence += [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(ngf, output_nc, kernel_size=7, stride=1, padding=0),\n            nn.Tanh()\n        ]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = self.model(x)\n        out = x + out\n        out = torch.clamp(out, min=-1, max=1)\n        return out\n    \nclass Discriminator(nn.Module):\n\n    def __init__(self, input_nc, ndf=64, n_layers=3, use_sigmoid=False):\n        super(Discriminator, self).__init__()\n\n        norm_layer = get_norm_layer()\n        use_bias = norm_layer.func != nn.BatchNorm2d\n\n        kernel_size = 4\n        padding = 1\n        sequence = [\n            nn.Conv2d(input_nc, ndf, kernel_size=kernel_size, stride=2, padding=padding),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        nf_mult = 1\n        for n in range(1, n_layers):\n            nf_mult_prev = nf_mult\n            nf_mult = min(2 ** n, 8)\n            sequence += [\n                spectral_norm(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kernel_size, stride=2, padding=padding,\n                          bias=use_bias), n_power_iterations=2),\n                #norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, True)\n            ]\n\n        nf_mult_prev = nf_mult\n        nf_mult = min(2 ** n_layers, 8)\n        sequence += [\n            spectral_norm(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kernel_size, stride=1, padding=padding,\n                      bias=use_bias), n_power_iterations=2),\n            #norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        sequence += [\n            nn.Conv2d(ndf * nf_mult, 1, kernel_size=kernel_size, stride=1, padding=padding)\n        ]\n        if use_sigmoid:\n            sequence += [nn.Sigmoid()]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = self.model(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:05:26.917371Z","iopub.execute_input":"2022-04-14T06:05:26.917631Z","iopub.status.idle":"2022-04-14T06:05:26.942353Z","shell.execute_reply.started":"2022-04-14T06:05:26.917601Z","shell.execute_reply":"2022-04-14T06:05:26.941649Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"generator = Generator(3, 3, n_blocks=9).apply(init_weights).to(device)\ndiscriminator = Discriminator(3).apply(init_weights).to(device)\n\nCONV3_3_IN_VGG_19 = torchvision.models.vgg19(pretrained=True, progress=False).features[:15].to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:05:31.967508Z","iopub.execute_input":"2022-04-14T06:05:31.968078Z","iopub.status.idle":"2022-04-14T06:06:27.060900Z","shell.execute_reply.started":"2022-04-14T06:05:31.968036Z","shell.execute_reply":"2022-04-14T06:06:27.060103Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"summary(generator, (3, IMAGE_WIDTH, IMAGE_HEIGHT))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:08:40.963941Z","iopub.execute_input":"2022-04-13T21:08:40.964227Z","iopub.status.idle":"2022-04-13T21:08:45.775483Z","shell.execute_reply.started":"2022-04-13T21:08:40.964197Z","shell.execute_reply":"2022-04-13T21:08:45.774479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(discriminator, (3, IMAGE_WIDTH, IMAGE_HEIGHT))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:08:49.914976Z","iopub.execute_input":"2022-04-13T21:08:49.915501Z","iopub.status.idle":"2022-04-13T21:08:50.719581Z","shell.execute_reply.started":"2022-04-13T21:08:49.915463Z","shell.execute_reply":"2022-04-13T21:08:50.718718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(CONV3_3_IN_VGG_19, (3, IMAGE_WIDTH, IMAGE_HEIGHT))","metadata":{"execution":{"iopub.status.busy":"2022-04-13T21:08:57.274757Z","iopub.execute_input":"2022-04-13T21:08:57.27502Z","iopub.status.idle":"2022-04-13T21:08:57.306338Z","shell.execute_reply.started":"2022-04-13T21:08:57.27499Z","shell.execute_reply":"2022-04-13T21:08:57.305123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_model(path, device=device):\n    if device == 'cuda':\n        checkpoint = torch.load(path)\n    else:\n        checkpoint = torch.load(path, map_location=torch.device('cpu'))\n    epoch = checkpoint['epoch']\n    generator = checkpoint['G']\n    discriminator = checkpoint['D']\n    optimizerG = checkpoint['optimizerG']\n    optimizerD = checkpoint['optimizerD']\n    return generator, discriminator, optimizerG, optimizerD, epoch\n\ndef PSNR(deblurred, sharp):\n    mse = torch.mean((deblurred - sharp) ** 2)\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1\n    return 10 * np.log10(PIXEL_MAX ** 2 / mse)\n\nclass WGANLoss(nn.Module):\n    def forward(self, mtype, **kwargs):\n        if mtype == 'G':\n            deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n            return -deblurred_discriminator_out.mean()\n\n        elif mtype == 'D':  \n            gp_lambda = kwargs['gp_lambda']\n            interpolates = kwargs['interpolates']\n            interpolates_discriminator_out = kwargs['interpolates_discriminator_out']\n            sharp_discriminator_out = kwargs['sharp_discriminator_out']\n            deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n\n            wgan_loss = deblurred_discriminator_out.mean() - sharp_discriminator_out.mean()\n\n            gradients = autograd.grad(outputs=interpolates_discriminator_out, inputs=interpolates,\n                                      grad_outputs=torch.ones(interpolates_discriminator_out.size()).to(device),\n                                      retain_graph=True,\n                                      create_graph=True)[0]\n            gradient_penalty = ((gradients.view(gradients.size(0), -1).norm(2, dim=1) - 1) ** 2).mean()\n\n            return wgan_loss, gp_lambda * gradient_penalty\n\nclass ContentLoss(nn.Module):\n    def forward(self, deblurred, sharp, model=CONV3_3_IN_VGG_19):\n        deblurred_feature_map = model.forward(deblurred)\n        sharp_feature_map = model.forward(sharp).detach()\n        loss = nn.functional.mse_loss(deblurred_feature_map, sharp_feature_map)\n        return loss\n    \ndef simple_gan_loss(mtype, **kwargs):\n    if mtype == 'G':\n        deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n        return nn.functional.binary_cross_entropy(deblurred_discriminator_out, torch.ones_like(deblurred_discriminator_out))\n\n    elif mtype == 'D':\n        sharp_discriminator_out = kwargs['sharp_discriminator_out']\n        deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n        real_loss = nn.functional.binary_cross_entropy(sharp_discriminator_out, torch.ones_like(sharp_discriminator_out))\n        fake_loss = nn.functional.binary_cross_entropy(deblurred_discriminator_out, torch.zeros_like(deblurred_discriminator_out))\n        return (real_loss + fake_loss) / 2.0","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:06:27.062527Z","iopub.execute_input":"2022-04-14T06:06:27.062811Z","iopub.status.idle":"2022-04-14T06:06:27.080342Z","shell.execute_reply.started":"2022-04-14T06:06:27.062776Z","shell.execute_reply":"2022-04-14T06:06:27.079632Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"criterion_wgan = WGANLoss()\ncriterion_content = ContentLoss()\n\noptimizerG = torch.optim.AdamW(generator.parameters(), lr=0.00001, betas=(0.5, 0.999), amsgrad=True, weight_decay=1e-6)\noptimizerD = torch.optim.AdamW(discriminator.parameters(), lr=0.00001, betas=(0.5, 0.999), amsgrad=True, weight_decay=1e-6)\n\nlr_lambda = lambda epoch: (1 - (epoch - 150) / 150) if epoch > 150 else 1\nschedulerG = torch.optim.lr_scheduler.LambdaLR(optimizerG, lr_lambda=lr_lambda)\nschedulerD = torch.optim.lr_scheduler.LambdaLR(optimizerD, lr_lambda=lr_lambda)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:06:46.949663Z","iopub.execute_input":"2022-04-14T06:06:46.950182Z","iopub.status.idle":"2022-04-14T06:06:46.958560Z","shell.execute_reply.started":"2022-04-14T06:06:46.950142Z","shell.execute_reply":"2022-04-14T06:06:46.957847Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def denormalize(image_tensor):\n    return (image_tensor + 1) / 2.0\n\ndef train_one_batch(generator, discriminator, data, criterionW, criterionC, optimizerG, optimizerD, critic_updates=5):\n    generator.train()\n    discriminator.train()\n\n    blur, sharp = data\n\n    discriminator_loss = 0\n    for i in range(critic_updates):\n\n        deblur = generator(blur) # before loop initially, deblur_ = deblur.clone()\n\n        d_sharp_out = discriminator(sharp) # before loop initially\n        d_deblur_out = discriminator(deblur) # before loop initially\n\n        optimizerD.zero_grad()\n        alpha = np.random.random()\n        interpolates = alpha * sharp + (1 - alpha) * deblur\n        interpolates_discriminator_out = discriminator(interpolates)\n        kwargs = {\n                  'gp_lambda': gp_lambda,\n                  'interpolates': interpolates, \n                  'interpolates_discriminator_out': interpolates_discriminator_out, \n                  'sharp_discriminator_out': d_sharp_out, \n                  'deblurred_discriminator_out': d_deblur_out,  \n                  }\n        wgan_loss_d, gp_d = criterionW('D', **kwargs)\n        discriminator_loss_per_update = wgan_loss_d + gp_d\n        discriminator_loss_per_update.backward(retain_graph=True)\n        optimizerD.step()\n        discriminator_loss += discriminator_loss_per_update.item()\n    discriminator_loss /= critic_updates\n\n    optimizerG.zero_grad()\n    \n    deblur = generator(blur) ###\n    d_deblur_out = discriminator(deblur) ###\n    kwargs = {\n              'deblurred_discriminator_out': d_deblur_out, \n              }    \n    wgan_loss_g = criterionW('G', **kwargs)\n    content_loss_g = criterionC(deblur, sharp) * content_loss_lambda\n    generator_loss = wgan_loss_g + content_loss_g\n    generator_loss.backward()\n    optimizerG.step()\n\n    with torch.no_grad():\n        denormalized_sharp = denormalize(sharp).cpu().detach()\n        denormalized_deblurred = denormalize(deblur).cpu().detach()\n\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    torch.nn.utils.clip_grad_norm_(generator.parameters(), 10.0)\n    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 10.0)\n\n    #if device == 'cuda':\n    #    torch.cuda.empty_cache()\n    return discriminator_loss, generator_loss.item(), metric\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterionW, criterionC):\n    generator.eval()\n    discriminator.eval()\n\n    blur, sharp = data\n    deblur = generator(blur)\n    d_deblur = discriminator(deblur)\n\n    kwargs = {\n              'deblurred_discriminator_out': d_deblur, }\n    adversarial_loss_g = criterionW('G', **kwargs)\n    content_loss_g = criterionC(deblur, sharp) * content_loss_lambda\n    loss_g = adversarial_loss_g + content_loss_g\n\n    denormalized_sharp = denormalize(sharp).cpu().detach()\n    denormalized_deblurred = denormalize(deblur).cpu().detach()\n\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    return loss_g.item(), metric\n\n@torch.no_grad()\ndef visual_validate(data, model):\n    img, tar = data\n    model.eval()\n    out = model(img)\n    out, img, tar = [denormalize(tensor) for tensor in [out, img, tar]]\n    out, img, tar = [tensor.squeeze().cpu().detach().numpy().transpose(1,2,0) for tensor in [out, img, tar]]\n    plt.figure(figsize=(12,14))\n    plt.subplot(131)\n    plt.title('Blurred')\n    plt.imshow(img)\n    plt.subplot(132)\n    plt.title('Target')\n    plt.imshow(tar)\n    plt.subplot(133)\n    plt.title('Deblurred')\n    plt.imshow(out)\n    plt.show()\n    plt.pause(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:07:03.226376Z","iopub.execute_input":"2022-04-14T06:07:03.226645Z","iopub.status.idle":"2022-04-14T06:07:03.247246Z","shell.execute_reply.started":"2022-04-14T06:07:03.226614Z","shell.execute_reply":"2022-04-14T06:07:03.246463Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_d_losses, train_g_losses, valid_g_losses = [], [], []\ntrain_metric_total, valid_metric_total = [], []\n\ntry:\n    generator, discriminator, optimizerG, optimizerD, ep = load_model(PATH)\nexcept FileNotFoundError:\n    ep = 0\n\nfor epoch in range(ep, epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n\n    train_epoch_d_loss, train_epoch_g_loss, train_epoch_metric = [],[],[]\n    for i, data in enumerate(tqdm(train_dataloader, leave=False)): \n        with autograd.set_detect_anomaly(True): \n            d_loss, g_loss, metric = train_one_batch(generator, discriminator, data, criterion_wgan, criterion_content,\n                                                 optimizerG, optimizerD, critic_updates=5)\n        train_epoch_d_loss.append(d_loss)\n        train_epoch_g_loss.append(g_loss)\n        train_epoch_metric.append(metric)\n    epoch_d_loss = np.array(train_epoch_d_loss).mean()\n    epoch_g_loss = np.array(train_epoch_g_loss).mean()\n    train_metric = np.array(train_epoch_metric).mean()\n    train_d_losses.append(epoch_d_loss)\n    train_g_losses.append(epoch_g_loss)\n    train_metric_total.append(train_metric)\n    print(f'Train D loss: {epoch_d_loss:.4f}, train G loss: {epoch_g_loss:.4f}')\n    print(f'Train metric: {train_metric:.4f}')\n\n    valid_epoch_g_loss, valid_epoch_metric = [],[]\n    for i, data in enumerate(tqdm(valid_dataloader, leave=False)):\n        g_loss, metric = validate(generator, discriminator, data, criterion_wgan, criterion_content)\n        valid_epoch_g_loss.append(g_loss)\n        valid_epoch_metric.append(metric)\n    epoch_g_loss = np.array(valid_epoch_g_loss).mean()\n    valid_metric = np.array(valid_epoch_metric).mean()\n    valid_g_losses.append(epoch_g_loss)\n    valid_metric_total.append(valid_metric)\n    print(f'Valid G loss: {epoch_g_loss:.4f}')\n    print(f'Valid metric: {valid_metric:.4f}')\n    print('-'*50)    \n    schedulerD.step()\n    schedulerG.step()\n    if (epoch + 1) % 2 == 0:\n        checkpoint = {\n                      'epoch': epoch,     \n                      'G': generator,\n                      'D': discriminator,\n                      'optimizerG': optimizerG,\n                      'optimizerD': optimizerD,\n                      }\n        torch.save(checkpoint, PATH)\n        data = next(iter(valid_dataloader))\n        visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T06:07:13.416442Z","iopub.execute_input":"2022-04-14T06:07:13.416808Z","iopub.status.idle":"2022-04-14T15:25:18.387787Z","shell.execute_reply.started":"2022-04-14T06:07:13.416767Z","shell.execute_reply":"2022-04-14T15:25:18.386362Z"},"trusted":true},"execution_count":17,"outputs":[]}]}