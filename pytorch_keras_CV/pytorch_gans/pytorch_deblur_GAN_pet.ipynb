{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torchvision import transforms as T\nimport torch.autograd as autograd\n\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nimport functools\nfrom functools import partial","metadata":{"id":"hTiW5Yl9uJov","execution":{"iopub.status.busy":"2022-06-18T21:02:04.615684Z","iopub.execute_input":"2022-06-18T21:02:04.616096Z","iopub.status.idle":"2022-06-18T21:02:07.405023Z","shell.execute_reply.started":"2022-06-18T21:02:04.616015Z","shell.execute_reply":"2022-06-18T21:02:07.404233Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"blurred = glob('../input/hideblur/HIDE_dataset/train' + '/*.png')\nsharp = glob('../input/hideblur/HIDE_dataset/GT' + '/*.png')\n\nblurred_name = sorted([str(x) for x in blurred])\nsharp_name = sorted([str(x) for x in sharp])\n\nblurred_idx = [int(str(x).replace('.MP4', '').split('fromGOPR')[-1].split('.')[0]) for x in blurred_name]\nsharp_idx = [int(str(x).replace('.MP4', '').split('fromGOPR')[-1].split('.')[0]) for x in sharp_name]\n\nexisting_idx = np.nonzero(np.isin(sharp_idx, blurred_idx))[0]\nsharp_name = np.array(sharp_name)\n\ndf = pd.DataFrame(data={'blur': blurred_name, 'sharp': sharp_name[existing_idx]})\ndf.sample(5)","metadata":{"id":"zsfrYNKQuRdD","outputId":"beef3b08-5272-4901-b138-7ce6c37e0b3e","execution":{"iopub.status.busy":"2022-06-18T21:02:07.406459Z","iopub.execute_input":"2022-06-18T21:02:07.407490Z","iopub.status.idle":"2022-06-18T21:02:07.934433Z","shell.execute_reply.started":"2022-06-18T21:02:07.407461Z","shell.execute_reply":"2022-06-18T21:02:07.933621Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df, test_size=500, shuffle=True, random_state=123)\ntrain.shape, valid.shape","metadata":{"id":"wzcJPPR6pliw","outputId":"273122bd-e241-4586-9d73-1158d03e6081","execution":{"iopub.status.busy":"2022-06-18T21:02:10.152134Z","iopub.execute_input":"2022-06-18T21:02:10.152478Z","iopub.status.idle":"2022-06-18T21:02:10.161138Z","shell.execute_reply.started":"2022-06-18T21:02:10.152449Z","shell.execute_reply":"2022-06-18T21:02:10.160383Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"torch.random.manual_seed(123)\ntorch.cuda.manual_seed(123)\nnp.random.seed(123)\n\nBATCH_SIZE = 16  # when batch_size is not very small use batch_norm instead instance_norm\nIMAGE_HEIGHT = 640\nIMAGE_WIDTH = 360\nepochs = 10  # 50 from scratch\nFINE_SIZE = 256\ngp_lambda = 10\ncontent_loss_lambda = 100\n\nPATH = r'deblur_model.pth'\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"id":"Hq3ec4xNhEYr","outputId":"40096f6f-307b-4f4c-806e-1b672b8f13bc","execution":{"iopub.status.busy":"2022-06-18T21:02:18.272076Z","iopub.execute_input":"2022-06-18T21:02:18.272433Z","iopub.status.idle":"2022-06-18T21:02:18.338469Z","shell.execute_reply.started":"2022-06-18T21:02:18.272404Z","shell.execute_reply":"2022-06-18T21:02:18.337690Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((FINE_SIZE, FINE_SIZE)), #, Image.BICUBIC),\n                              T.RandomHorizontalFlip(p=0.2),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])\nvalid_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((FINE_SIZE, FINE_SIZE)), # Image.BICUBIC),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])","metadata":{"id":"r4J5fqq3kD9L","execution":{"iopub.status.busy":"2022-06-18T21:02:19.598256Z","iopub.execute_input":"2022-06-18T21:02:19.599143Z","iopub.status.idle":"2022-06-18T21:02:19.605725Z","shell.execute_reply.started":"2022-06-18T21:02:19.599098Z","shell.execute_reply":"2022-06-18T21:02:19.604937Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BlurDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, ix):\n        row = self.df.iloc[ix].squeeze()\n        blurred_img = cv2.imread(row['blur'])\n        blurred_img = cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB)\n        sharp_img = cv2.imread(row['sharp'])\n        sharp_img = cv2.cvtColor(sharp_img, cv2.COLOR_BGR2RGB)\n        return blurred_img, sharp_img\n\n    def collate_fn(self, batch):\n        blurs, sharps = list(zip(*batch))\n        blurs = [self.transforms(img)[None] for img in blurs]\n        sharps = [self.transforms(img)[None] for img in sharps]\n        blurs, sharps = [torch.cat(i).to(device) for i in [blurs, sharps]]\n        return blurs, sharps","metadata":{"id":"gcvvOrWylyOq","execution":{"iopub.status.busy":"2022-06-18T21:02:20.413242Z","iopub.execute_input":"2022-06-18T21:02:20.413881Z","iopub.status.idle":"2022-06-18T21:02:20.422540Z","shell.execute_reply.started":"2022-06-18T21:02:20.413843Z","shell.execute_reply":"2022-06-18T21:02:20.421394Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dataset = BlurDataset(train, transforms=train_transforms)\nvalid_dataset = BlurDataset(valid, transforms=valid_transforms)\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn)\nvalid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=True, collate_fn=valid_dataset.collate_fn)","metadata":{"id":"tNANTOeEoS94","execution":{"iopub.status.busy":"2022-06-18T21:02:21.163932Z","iopub.execute_input":"2022-06-18T21:02:21.164545Z","iopub.status.idle":"2022-06-18T21:02:21.169882Z","shell.execute_reply.started":"2022-06-18T21:02:21.164509Z","shell.execute_reply":"2022-06-18T21:02:21.168968Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_norm_layer(layer_type='batch'):\n    if layer_type == 'batch':\n        return nn.BatchNorm2d\n    else:\n        return partial(nn.InstanceNorm2d, track_running_stats=False)\n\ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)\n\nclass ResNetBlock(nn.Module):\n    def __init__(self, dim, norm_layer, use_bias, dropout=False):\n        super(ResNetBlock, self).__init__()\n        sequence = list()\n\n        sequence += [nn.ReflectionPad2d(1)]\n\n        sequence += [\n            nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=0, bias=use_bias),\n            norm_layer(dim),\n            nn.ReLU(True)\n        ]\n        if dropout:\n            sequence += [nn.Dropout(0.5)]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = x + self.model(x)\n        return out\n\nclass Generator(nn.Module):\n\n    def __init__(self, input_nc, output_nc, ngf=64, n_blocks=9, norm_type='batch'):\n        super(Generator, self).__init__()\n\n        norm_layer = get_norm_layer(norm_type)\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func != nn.BatchNorm2d\n        else:\n            use_bias = norm_layer != nn.BatchNorm2d\n\n        sequence = [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(input_nc, ngf, kernel_size=7, stride=1, padding=0, bias=use_bias),\n            norm_layer(ngf),\n            nn.ReLU(True)\n        ]\n\n        n_downsampling = 2\n        for i in range(n_downsampling):\n            mult = 2 ** i\n            sequence += [\n                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n                norm_layer(ngf * mult * 2),\n                nn.ReLU(True)\n            ]\n\n        for i in range(n_blocks):\n            sequence += [\n                ResNetBlock(ngf * 2 ** n_downsampling, norm_layer, use_bias)\n            ]\n\n        for i in range(n_downsampling):\n            mult = 2 ** (n_downsampling - i)\n            sequence += [\n                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1,\n                                   output_padding=1, bias=use_bias),\n                norm_layer(int(ngf * mult / 2)),\n                nn.ReLU(True)\n            ]\n        sequence += [\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(ngf, output_nc, kernel_size=7, stride=1, padding=0),\n            nn.Tanh()\n        ]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = self.model(x)\n        out = x + out\n        out = torch.clamp(out, min=-1, max=1)\n        return out\n\nclass Discriminator(nn.Module):\n\n    def __init__(self, input_nc, ndf=64, n_layers=3, use_sigmoid=False, norm_type='batch'):\n        super(Discriminator, self).__init__()\n\n        norm_layer = get_norm_layer(norm_type)\n        if type(norm_layer) == functools.partial:\n            use_bias = norm_layer.func != nn.BatchNorm2d\n        else:\n            use_bias = norm_layer != nn.BatchNorm2d\n\n        kernel_size = 4\n        padding = 1\n        sequence = [\n            nn.Conv2d(input_nc, ndf, kernel_size=kernel_size, stride=2, padding=padding),\n            nn.LeakyReLU(0.2, True)\n        ]\n\n        nf_mult = 1\n        for n in range(1, n_layers):\n            nf_mult_prev = nf_mult\n            nf_mult = min(2 ** n, 8)\n            sequence += [\n                nn.utils.spectral_norm(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kernel_size, stride=2, padding=padding,\n                          bias=use_bias), n_power_iterations=2),\n                norm_layer(ndf * nf_mult),\n                nn.LeakyReLU(0.2, True),\n                nn.Dropout(0.5)\n            ]\n\n        nf_mult_prev = nf_mult\n        nf_mult = min(2 ** n_layers, 8)\n        sequence += [\n            nn.utils.spectral_norm(nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kernel_size, stride=1, padding=padding,\n                      bias=use_bias), n_power_iterations=2),\n            norm_layer(ndf * nf_mult),\n            nn.LeakyReLU(0.2, True),\n            nn.Dropout(0.5)\n        ]\n\n        sequence += [\n            nn.Conv2d(ndf * nf_mult, 1, kernel_size=kernel_size, stride=1, padding=padding)\n        ]\n\n        if use_sigmoid:\n            sequence += [nn.Sigmoid()]\n\n        self.model = nn.Sequential(*sequence)\n\n    def forward(self, x):\n        out = self.model(x)\n        return out","metadata":{"id":"y1ZsWy34q9mM","execution":{"iopub.status.busy":"2022-06-18T21:02:22.019857Z","iopub.execute_input":"2022-06-18T21:02:22.020470Z","iopub.status.idle":"2022-06-18T21:02:22.056498Z","shell.execute_reply.started":"2022-06-18T21:02:22.020437Z","shell.execute_reply":"2022-06-18T21:02:22.055580Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Image colorizing analogue","metadata":{}},{"cell_type":"code","source":"from fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet\n\n\ndef build_res_unet(n_input=3, n_output=3, size=256, pretrained=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    body = create_body(resnet18, pretrained=pretrained, n_in=n_input)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n\nclass Generator(nn.Module):\n    def __init__(self, pretrained=False):\n        super(Generator, self).__init__()\n        self.backbone = build_res_unet(pretrained=pretrained)\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        out = self.tanh(self.backbone(x))\n        out = x + out\n        out = torch.clamp(out, min=-1, max=1)\n        return out\n\ndef pretrain_generator(model, train_dl, opt, criterion, epochs):\n    for e in tqdm(range(epochs), total=epochs, leave=False):\n        for data in tqdm(train_dl, total=len(train_dl), leave=False):\n            blur, sharp = data\n            deblur = model(blur)\n            loss = criterion(deblur, sharp)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n\ngenerator = Generator(pretrained=True)\n#optimizer = torch.optim.AdamW(generator.parameters(), lr=0.0001, betas=(0.5, 0.999), amsgrad=True, weight_decay=0.)\n#criterion = ContentLoss()\n#pretrain_generator(generator, train_dataloader, optimizer, criterion, 20)\n\n#torch.save(generator.state_dict(), 'generator.pth')\ngenerator.load_state_dict(torch.load('../input/deblur-gen-weights/generator.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T21:02:24.322707Z","iopub.execute_input":"2022-06-18T21:02:24.323340Z","iopub.status.idle":"2022-06-18T21:02:32.892496Z","shell.execute_reply.started":"2022-06-18T21:02:24.323302Z","shell.execute_reply":"2022-06-18T21:02:32.891683Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# generator = Generator(3, 3, n_blocks=9).apply(init_weights).to(device)\ndiscriminator = Discriminator(3).apply(init_weights).to(device)\n\nCONV3_3_IN_VGG_19 = torchvision.models.vgg19(pretrained=True, progress=False).features[:15].to(device)","metadata":{"id":"YdVrXi4Ku2am","execution":{"iopub.status.busy":"2022-06-18T21:02:32.893976Z","iopub.execute_input":"2022-06-18T21:02:32.894604Z","iopub.status.idle":"2022-06-18T21:02:52.971834Z","shell.execute_reply.started":"2022-06-18T21:02:32.894566Z","shell.execute_reply":"2022-06-18T21:02:52.970989Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!pip install -qq torchsummary\nfrom torchsummary import summary\n\nsummary(generator, (3, FINE_SIZE, FINE_SIZE))","metadata":{"id":"OM5HuhAxusbZ","outputId":"499f299c-195a-45d3-dadf-08eb82ae111b","execution":{"iopub.status.busy":"2022-06-18T19:02:49.597916Z","iopub.execute_input":"2022-06-18T19:02:49.598268Z","iopub.status.idle":"2022-06-18T19:03:05.268421Z","shell.execute_reply.started":"2022-06-18T19:02:49.598239Z","shell.execute_reply":"2022-06-18T19:03:05.267441Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"summary(discriminator, (3, FINE_SIZE, FINE_SIZE))","metadata":{"id":"vz5Evdj9wQvm","outputId":"3d98ecda-ae47-42d9-b2cc-a8f84561be4b","execution":{"iopub.status.busy":"2022-06-18T19:03:05.270446Z","iopub.execute_input":"2022-06-18T19:03:05.270980Z","iopub.status.idle":"2022-06-18T19:03:06.243944Z","shell.execute_reply.started":"2022-06-18T19:03:05.270939Z","shell.execute_reply":"2022-06-18T19:03:06.242416Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"summary(CONV3_3_IN_VGG_19, (3, FINE_SIZE, FINE_SIZE))","metadata":{"id":"64-9FgHPFzJ4","outputId":"4f8f3b16-6980-4a6e-b0d3-3dfe4f1d71d8","execution":{"iopub.status.busy":"2022-06-18T19:03:06.245454Z","iopub.execute_input":"2022-06-18T19:03:06.246122Z","iopub.status.idle":"2022-06-18T19:03:06.550647Z","shell.execute_reply.started":"2022-06-18T19:03:06.246074Z","shell.execute_reply":"2022-06-18T19:03:06.549694Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def load_model(path, device=device):\n    if device == 'cuda':\n        checkpoint = torch.load(path)\n    else:\n        checkpoint = torch.load(path, map_location=torch.device('cpu'))\n    epoch = checkpoint['epoch']\n    generator = checkpoint['G']\n    discriminator = checkpoint['D']\n    optimizerG = checkpoint['optimizerG']\n    optimizerD = checkpoint['optimizerD']\n    return generator, discriminator, optimizerG, optimizerD, epoch\n\ndef PSNR(deblurred, sharp):\n    mse = torch.mean((deblurred - sharp) ** 2)\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1\n    return 10 * np.log10(PIXEL_MAX ** 2 / mse)\n\nclass WGANLoss(nn.Module):\n    def forward(self, mtype, **kwargs):\n        if mtype == 'G':\n            deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n            return -deblurred_discriminator_out.mean()\n\n        elif mtype == 'D':  \n            gp_lambda = kwargs['gp_lambda']\n            interpolates = kwargs['interpolates']\n            interpolates_discriminator_out = kwargs['interpolates_discriminator_out']\n            sharp_discriminator_out = kwargs['sharp_discriminator_out']\n            deblurred_discriminator_out = kwargs['deblurred_discriminator_out']\n\n            wgan_loss = deblurred_discriminator_out.mean() - sharp_discriminator_out.mean()\n\n            gradients = autograd.grad(outputs=interpolates_discriminator_out, inputs=interpolates,\n                                      grad_outputs=torch.ones(interpolates_discriminator_out.size()).to(device),\n                                      retain_graph=True,\n                                      create_graph=True)[0]\n            gradient_penalty = ((gradients.view(gradients.size(0), -1).norm(2, dim=1) - 1) ** 2).mean()\n\n            return wgan_loss, gp_lambda * gradient_penalty\n\nclass ContentLoss(nn.Module):\n    def __init__(self):\n        super(ContentLoss, self).__init__()\n        self.normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n\n    def forward(self, deblurred, sharp, model=CONV3_3_IN_VGG_19):\n        model.eval()\n        deblurred = (deblurred + 1) * 0.5\n        sharp = (sharp + 1) * 0.5\n\n        deblurred = nn.functional.interpolate(deblurred, mode='bilinear', size=(224, 224), align_corners=False)\n        sharp = nn.functional.interpolate(sharp, mode='bilinear', size=(224, 224), align_corners=False)\n\n        deblurred, sharp = [[self.normalize(img)[None] for img in imgs] for imgs in [deblurred, sharp]]\n        deblurred, sharp = [torch.cat(i) for i in [deblurred, sharp]]\n\n        deblurred_feature_map = model.forward(deblurred)\n        sharp_feature_map = model.forward(sharp).detach()\n        loss = nn.functional.mse_loss(deblurred_feature_map, sharp_feature_map)\n\n        return loss\n    \ndef gan_logit_loss(model_type, smoothing=False, func=nn.functional.mse_loss, smooth_real_value=1.02, **kwargs):\n    if model_type == 'G':\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        return func(recon_discriminator_out, torch.ones_like(recon_discriminator_out))\n\n    elif model_type == 'D':\n        sharp_discriminator_out = kwargs['sharp_discriminator_out']\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        if smoothing:\n            smooth_real_value = np.random.uniform(0.8, 1.0) if smooth_real_value == 'soft' else smooth_real_value\n            real_loss = func(sharp_discriminator_out, torch.full_like(sharp_discriminator_out, smooth_real_value))\n        else:\n            real_loss = func(sharp_discriminator_out, torch.ones_like(sharp_discriminator_out))\n        fake_loss = func(recon_discriminator_out, torch.zeros_like(recon_discriminator_out))\n        return (real_loss + fake_loss) / 2.0","metadata":{"id":"rZ1gLaJWxBk3","execution":{"iopub.status.busy":"2022-06-18T21:02:52.973754Z","iopub.execute_input":"2022-06-18T21:02:52.974153Z","iopub.status.idle":"2022-06-18T21:02:52.998052Z","shell.execute_reply.started":"2022-06-18T21:02:52.974117Z","shell.execute_reply":"2022-06-18T21:02:52.997109Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"criterion_wgan = WGANLoss()\ncriterion_content = ContentLoss()\n# criterion_content = nn.L1Loss()\n\n# mse\noptimizerG = torch.optim.AdamW(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizerD = torch.optim.AdamW(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n# WGAN actual\n#optimizerG = torch.optim.AdamW(generator.parameters(), lr=0.0001, betas=(0.5, 0.999), amsgrad=True, weight_decay=0.)\n#optimizerD = torch.optim.AdamW(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999), amsgrad=True, weight_decay=0.)\n\n# WGAN paper\n#optimizerG = torch.optim.AdamW(generator.parameters(), lr=1e-4, betas=(0., 0.9))\n#optimizerD = torch.optim.AdamW(discriminator.parameters(), lr=1e-4, betas=(0., 0.9), weight_decay=1e-3)\n\n#lr_lambda = lambda epoch: (1 - (epoch - 150) / 150) if epoch > 150 else 1\n#schedulerG = torch.optim.lr_scheduler.LambdaLR(optimizerG, lr_lambda=lr_lambda)\n#schedulerD = torch.optim.lr_scheduler.LambdaLR(optimizerD, lr_lambda=lr_lambda)","metadata":{"id":"VfwAckSRy9G0","execution":{"iopub.status.busy":"2022-06-18T21:02:52.999671Z","iopub.execute_input":"2022-06-18T21:02:53.000444Z","iopub.status.idle":"2022-06-18T21:02:54.734717Z","shell.execute_reply.started":"2022-06-18T21:02:53.000407Z","shell.execute_reply":"2022-06-18T21:02:54.733567Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def denormalize(image_tensor):\n    return (image_tensor + 1) / 2.0\n# updates from paper = 5\ndef train_one_batch(generator, discriminator, data, criterionW, criterionC, optimizerG, optimizerD, critic_updates=3):\n    generator.train()\n    discriminator.train()\n\n    blur, sharp = data\n\n    discriminator_loss = 0\n    for param in discriminator.parameters():\n        param.requires_grad = True\n\n    for _ in range(critic_updates):\n\n        deblur = generator(blur)\n\n        d_sharp_out = discriminator(sharp)\n        d_deblur_out = discriminator(deblur)\n\n        optimizerD.zero_grad()\n        alpha = np.random.random()\n        interpolates = alpha * sharp + (1 - alpha) * deblur\n        interpolates_discriminator_out = discriminator(interpolates)\n        kwargs = {\n                  'gp_lambda': gp_lambda,\n                  'interpolates': interpolates, \n                  'interpolates_discriminator_out': interpolates_discriminator_out, \n                  'sharp_discriminator_out': d_sharp_out, \n                  'deblurred_discriminator_out': d_deblur_out,  \n                  }\n        wgan_loss_d, gp_d = criterionW('D', **kwargs)\n        discriminator_loss_per_update = wgan_loss_d + gp_d\n        discriminator_loss_per_update.backward(retain_graph=critic_updates>1)\n        optimizerD.step()\n        discriminator_loss += discriminator_loss_per_update.item()\n    discriminator_loss /= critic_updates\n\n    for param in discriminator.parameters():\n        param.requires_grad = False\n    optimizerG.zero_grad()\n    \n    deblur = generator(blur)\n    d_deblur_out = discriminator(deblur)\n    \n    kwargs = {\n              'deblurred_discriminator_out': d_deblur_out, \n              }    \n    wgan_loss_g = criterionW('G', **kwargs)\n    content_loss_g = criterionC(deblur, sharp) * content_loss_lambda\n    generator_loss = wgan_loss_g + content_loss_g\n    generator_loss.backward()\n    optimizerG.step()\n\n    with torch.no_grad():\n        denormalized_sharp = denormalize(sharp).cpu().detach()\n        denormalized_deblurred = denormalize(deblur).cpu().detach()\n\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    return discriminator_loss, generator_loss.item(), metric\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterionW, criterionC):\n    generator.eval()\n    discriminator.eval()\n\n    blur, sharp = data\n    deblur = generator(blur)\n    d_deblur = discriminator(deblur)\n\n    kwargs = {\n              'deblurred_discriminator_out': d_deblur, }\n    adversarial_loss_g = criterionW('G', **kwargs)\n    content_loss_g = criterionC(deblur, sharp) * content_loss_lambda\n    loss_g = adversarial_loss_g + content_loss_g\n\n    denormalized_sharp = denormalize(sharp).cpu().detach()\n    denormalized_deblurred = denormalize(deblur).cpu().detach()\n\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    return loss_g.item(), metric\n\n@torch.no_grad()\ndef visual_validate(data, model):\n    img, tar = data\n    model.eval()\n    out = model(img)\n    out, img, tar = [denormalize(tensor) for tensor in [out, img, tar]]\n    out, img, tar = [tensor.squeeze().cpu().detach().numpy().transpose(1,2,0) for tensor in [out, img, tar]]\n    plt.figure(figsize=(12,14))\n    plt.subplot(131)\n    plt.title('Blurred')\n    plt.imshow(img)\n    plt.subplot(132)\n    plt.title('Target')\n    plt.imshow(tar)\n    plt.subplot(133)\n    plt.title('Deblurred')\n    plt.imshow(out)\n    plt.tight_layout()\n    plt.show()\n    plt.pause(0.001)","metadata":{"id":"_WoaCwuH1xXa","execution":{"iopub.status.busy":"2022-06-18T21:02:54.737234Z","iopub.execute_input":"2022-06-18T21:02:54.737908Z","iopub.status.idle":"2022-06-18T21:02:54.766260Z","shell.execute_reply.started":"2022-06-18T21:02:54.737870Z","shell.execute_reply":"2022-06-18T21:02:54.765228Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"##### alternative functions (mse or bce)","metadata":{}},{"cell_type":"code","source":"def grad_req(model, is_required=True):\n    for param in model.parameters():\n        param.requires_grad = is_required\n        \ndef train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD, \n                    critic_updates=1, noise=False, std=1):\n    if std <= 1e-4:\n        noise=False\n        \n    generator.train()\n    discriminator.train()\n\n    grad_req(discriminator, True)\n    blur, sharp = data\n    \n    tot_d_loss = 0.\n    for _ in range(critic_updates):\n        deblur = generator(blur)\n        \n        if noise:  # make discriminator training more complex to help generator\n            alpha = torch.empty_like(deblur, device=device).normal_(mean=0., std=std)\n            deblur = (deblur + alpha).clamp_(min=-1., max=1.)\n            beta = torch.empty_like(sharp, device=device).normal_(mean=0., std=std)\n            sharp = torch.clamp(sharp + beta, min=-1., max=1.)\n        \n        real_preds = discriminator(sharp)\n        fake_preds = discriminator(deblur.detach())\n    \n        optimizerD.zero_grad()\n\n        kwargs = {\n                  'sharp_discriminator_out': real_preds, \n                  'recon_discriminator_out': fake_preds,  \n                 }\n        d_loss = gan_logit_loss('D', \n                                #smoothing=True, # set to True to apply one-sided label smoothing (only in 'D' step)\n                                #smooth_real_value=0.9,  # hard smoothing = const value, to randomize [0.8, 1.) set 'soft'\n                                #func=nn.functional.binary_cross_entropy_with_logits,  # set Loss function for D_model\n                                **kwargs)\n        d_loss.backward(retain_graph=critic_updates>1)\n        tot_d_loss += d_loss.item()\n        optimizerD.step()\n    tot_d_loss /= critic_updates\n    \n    grad_req(discriminator, False)\n    optimizerG.zero_grad()\n    \n    deblur = generator(blur)\n    fake_preds = discriminator(deblur)\n    \n    kwargs = {\n              'recon_discriminator_out': fake_preds, \n              }    \n    g_loss_gan = gan_logit_loss('G', \n                                #smoothing=False, \n                                #func=nn.functional.binary_cross_entropy_with_logits,\n                                **kwargs)\n    loss_G = criterion_content_loss(deblur, sharp) * content_loss_lambda\n    g_loss = g_loss_gan + loss_G\n    g_loss.backward()\n    optimizerG.step()\n\n    torch.nn.utils.clip_grad_norm_(generator.parameters(), 10.0)  # the weights may increase we set (ep<1000): 1.0 - 10.0\n    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 10.0) # prevents from exploding grads\n    \n    with torch.no_grad():\n        denormalized_sharp = denormalize(sharp).cpu().detach()\n        denormalized_deblurred = denormalize(deblur).cpu().detach()\n\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    return tot_d_loss, g_loss.item(), metric\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterion_content_loss):\n    generator.eval()\n    discriminator.eval()\n\n    blur, sharp = data\n    \n    deblur = generator(blur)\n    \n    sharp_discriminator_out = discriminator(sharp)\n    recon_discriminator_out = discriminator(deblur)\n    kwargs = {\n              'sharp_discriminator_out': sharp_discriminator_out, \n              'recon_discriminator_out': recon_discriminator_out,  \n             }\n    d_loss = gan_logit_loss('D', \n                            #smoothing=False,\n                            #func=nn.functional.binary_cross_entropy_with_logits,\n                            **kwargs)\n    \n    kwargs = {\n              'recon_discriminator_out': recon_discriminator_out, \n              }    \n    g_loss_gan = gan_logit_loss('G', \n                                #smoothing=False,\n                                #func=nn.functional.binary_cross_entropy_with_logits,\n                                **kwargs)\n    loss_G = criterion_content_loss(deblur, sharp) * content_loss_lambda \n    g_loss = g_loss_gan + loss_G\n    \n    denormalized_sharp = denormalize(sharp).cpu().detach()\n    denormalized_deblurred = denormalize(deblur).cpu().detach()\n    metric = PSNR(denormalized_deblurred, denormalized_sharp)\n\n    return d_loss.item(), g_loss.item(), metric","metadata":{"execution":{"iopub.status.busy":"2022-06-18T21:02:54.768217Z","iopub.execute_input":"2022-06-18T21:02:54.769041Z","iopub.status.idle":"2022-06-18T21:02:54.795995Z","shell.execute_reply.started":"2022-06-18T21:02:54.769007Z","shell.execute_reply":"2022-06-18T21:02:54.795266Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_d_losses, train_g_losses, valid_g_losses, valid_d_losses = [], [], [], []\ntrain_metric_total, valid_metric_total = [], []\n\ntry:\n    ep += 1\nexcept NameError:\n    ep = 0\n\nfor epoch in range(ep, epochs):\n    break  # to eval version\n    print(f'Epoch {epoch + 1}/{epochs}')\n\n    train_epoch_d_loss, train_epoch_g_loss, train_epoch_metric = [],[],[]\n    for i, data in enumerate(tqdm(train_dataloader, leave=False)): \n        with autograd.set_detect_anomaly(True): \n            d_loss, g_loss, metric = train_one_batch(generator, \n                                                     discriminator, \n                                                     data, \n                                                     #criterion_wgan, \n                                                     criterion_content,\n                                                     optimizerG, \n                                                     optimizerD)\n        train_epoch_d_loss.append(d_loss)\n        train_epoch_g_loss.append(g_loss)\n        train_epoch_metric.append(metric)\n    epoch_d_loss = np.array(train_epoch_d_loss).mean()\n    epoch_g_loss = np.array(train_epoch_g_loss).mean()\n    train_metric = np.array(train_epoch_metric).mean()\n    train_d_losses.append(epoch_d_loss)\n    train_g_losses.append(epoch_g_loss)\n    train_metric_total.append(train_metric)\n    print(f'Train D loss: {epoch_d_loss:.4f}, train G loss: {epoch_g_loss:.4f}')\n    print(f'Train metric: {train_metric:.4f}')\n\n    valid_epoch_g_loss, valid_epoch_d_loss = [],[]\n    for _, data in enumerate(tqdm(valid_dataloader, leave=False)):\n        d_loss, g_loss, metric = validate(generator, \n                                          discriminator, \n                                          data, \n                                          #criterion_wgan\n                                          criterion_content)\n        valid_epoch_g_loss.append(g_loss)\n        valid_epoch_d_loss.append(d_loss)\n    epoch_g_loss = np.array(valid_epoch_g_loss).mean()\n    epoch_d_loss = np.array(valid_epoch_d_loss).mean()\n    valid_g_losses.append(epoch_g_loss)\n    valid_d_losses.append(epoch_d_loss)\n    print(f'Validation D loss: {epoch_d_loss:.4f}, validation G loss: {epoch_g_loss:.4f}, PSNR: {metric:.4f}')\n    print('-'*50)    \n\n    #schedulerD.step()\n    #schedulerG.step()\n    if (epoch + 1) % 2 == 0:\n        checkpoint = {\n                      'epoch': epoch,     \n                      'G': generator,\n                      'D': discriminator,\n                      'optimizerG': optimizerG,\n                      'optimizerD': optimizerD,\n                      }\n        torch.save(checkpoint, PATH)\n        data = next(iter(valid_dataloader))\n        visual_validate(data, generator)","metadata":{"id":"sfNzeLp1aggs","outputId":"a7c02774-bcfe-4125-ef47-46f4d2f58d57","execution":{"iopub.status.busy":"2022-06-18T21:03:01.796999Z","iopub.execute_input":"2022-06-18T21:03:01.797648Z","iopub.status.idle":"2022-06-18T23:41:36.375581Z","shell.execute_reply.started":"2022-06-18T21:03:01.797613Z","shell.execute_reply":"2022-06-18T23:41:36.373653Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"##### WGAN-GP\n* critic updates = 3 -> set 2 (or use mse with higher LR)\n* pretrained generator\n* lrD=lrG = 1e-4\n* D norm = batch\n##### MSE\n* lrD = lrG = 2e-4\n* pretrained G","metadata":{}},{"cell_type":"code","source":"# WGAN-GP\ngenerator, discriminator, optimizerG, optimizerD, ep = load_model('../input/deblur-wgan-weights/deblur_model.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, data in enumerate(valid_dataloader, 1):\n    if i % 25 == 0:\n        visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:29:16.154304Z","iopub.execute_input":"2022-06-18T19:29:16.155128Z","iopub.status.idle":"2022-06-18T19:30:18.067982Z","shell.execute_reply.started":"2022-06-18T19:29:16.155092Z","shell.execute_reply":"2022-06-18T19:30:18.067182Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"generator, discriminator, optimizerG, optimizerD, ep = load_model('../input/deblur-mse-model/deblur_model.pth')\nfor i, data in enumerate(valid_dataloader, 1):\n    if i % 25 == 0:\n        visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:44:06.528715Z","iopub.execute_input":"2022-06-18T23:44:06.529498Z","iopub.status.idle":"2022-06-18T23:45:01.373440Z","shell.execute_reply.started":"2022-06-18T23:44:06.529459Z","shell.execute_reply":"2022-06-18T23:45:01.372163Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import os\nos.chdir(r'../working')\nfrom IPython.display import FileLink\nFileLink(r'deblur_model.pth')","metadata":{"execution":{"iopub.status.busy":"2022-06-18T23:41:52.422350Z","iopub.execute_input":"2022-06-18T23:41:52.422720Z","iopub.status.idle":"2022-06-18T23:41:52.429984Z","shell.execute_reply.started":"2022-06-18T23:41:52.422690Z","shell.execute_reply":"2022-06-18T23:41:52.429232Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"[Link to the validation outputs](https://www.kaggle.com/code/pankratozzi/pytorch-deblur?scriptVersionId=98724970)","metadata":{}}]}