{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport cv2\nimport os\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport torchvision.transforms as T\n\nfrom tqdm.notebook import tqdm\n\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:08:57.465654Z","iopub.execute_input":"2022-11-05T06:08:57.466075Z","iopub.status.idle":"2022-11-05T06:08:59.880031Z","shell.execute_reply.started":"2022-11-05T06:08:57.465990Z","shell.execute_reply":"2022-11-05T06:08:59.879044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Link to great advanced inpainting models**\n\n* [lama](https://github.com/saic-mdal/lama)\n* [nipponjo](https://github.com/nipponjo/deepfillv2-pytorch)","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:04.978409Z","iopub.execute_input":"2022-11-05T06:09:04.978920Z","iopub.status.idle":"2022-11-05T06:09:04.987963Z","shell.execute_reply.started":"2022-11-05T06:09:04.978889Z","shell.execute_reply":"2022-11-05T06:09:04.987094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 40\nbatch_size = 16\nlr = 8e-5\nimage_size = 128\nmask_size = 64\npath = r'painting_model.pth'\nb1 = 0.5\nb2 = 0.999\n\npatch_h, patch_w = int(mask_size / 2 ** 3), int(mask_size / 2 ** 3)\npatch = (1, patch_h, patch_w)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Currently using \"{device.upper()}\" device.')","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:08.373361Z","iopub.execute_input":"2022-11-05T06:09:08.373745Z","iopub.status.idle":"2022-11-05T06:09:08.445757Z","shell.execute_reply.started":"2022-11-05T06:09:08.373713Z","shell.execute_reply":"2022-11-05T06:09:08.444576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforms = T.Compose([\n    T.Resize((image_size, image_size), Image.BICUBIC),\n    T.ToTensor(),\n    T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # to scale [-1,1] with tanh activation\n])\n\ninverse_transforms = T.Compose([\n    T.Normalize(-1, 2),\n    T.ToPILImage()\n])","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:10.869172Z","iopub.execute_input":"2022-11-05T06:09:10.870097Z","iopub.status.idle":"2022-11-05T06:09:10.876856Z","shell.execute_reply.started":"2022-11-05T06:09:10.870048Z","shell.execute_reply":"2022-11-05T06:09:10.875776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = sorted([str(p) for p in glob('../input/celebahq-resized-256x256/celeba_hq_256' + '/*.jpg')])\n\ntrain, valid = train_test_split(image_paths, test_size=5000, shuffle=True, random_state=seed)\nvalid, test = train_test_split(valid, test_size=1000, shuffle=True, random_state=seed)\nprint(f'Train size: {len(train)}, validation size: {len(valid)}, test size: {len(test)}.')","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:12.549051Z","iopub.execute_input":"2022-11-05T06:09:12.549819Z","iopub.status.idle":"2022-11-05T06:09:13.104064Z","shell.execute_reply.started":"2022-11-05T06:09:12.549778Z","shell.execute_reply":"2022-11-05T06:09:13.102891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CelebaDataset(Dataset):\n    def __init__(self, images_paths, transforms=transforms, train=True):\n        self.images_paths = images_paths\n        self.transforms = transforms\n        self.train = train\n        \n    def __len__(self):\n        return len(self.images_paths)\n    \n    def apply_center_mask(self, image):\n        idx = (image_size - mask_size) // 2\n        masked_image = image.clone()\n        masked_image[:, idx:idx+mask_size, idx:idx+mask_size] = 1\n        masked_part = image[:, idx:idx+mask_size, idx:idx+mask_size]\n        return masked_image, idx\n    \n    def apply_random_mask(self, image):\n        y1, x1 = np.random.randint(0, image_size-mask_size, 2)\n        y2, x2 = y1 + mask_size, x1 + mask_size\n        masked_part = image[:, y1:y2, x1:x2]\n        masked_image = image.clone()\n        masked_image[:, y1:y2, x1:x2] = 1\n        return masked_image, masked_part\n    \n    def __getitem__(self, ix):\n        path = self.images_paths[ix]\n        image = Image.open(path)\n        image = self.transforms(image)\n        \n        if self.train:\n            masked_image, masked_part = self.apply_random_mask(image)\n        else:\n            masked_image, masked_part = self.apply_center_mask(image)\n            \n        return image, masked_image, masked_part\n    \n    def collate_fn(self, batch):\n        images, masked_images, masked_parts = list(zip(*batch))\n        images, masked_images, masked_parts = [[tensor[None].to(device) for tensor in ims] for ims in [images, masked_images, masked_parts]]\n        images, masked_images, masked_parts = [torch.cat(ims) for ims in [images, masked_images, masked_parts]]\n        return images, masked_images, masked_parts","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:14.070260Z","iopub.execute_input":"2022-11-05T06:09:14.070995Z","iopub.status.idle":"2022-11-05T06:09:14.084712Z","shell.execute_reply.started":"2022-11-05T06:09:14.070957Z","shell.execute_reply":"2022-11-05T06:09:14.083296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = CelebaDataset(train)\nvalid_dataset = CelebaDataset(valid, train=True)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=valid_dataset.collate_fn, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:15.627227Z","iopub.execute_input":"2022-11-05T06:09:15.628187Z","iopub.status.idle":"2022-11-05T06:09:15.633955Z","shell.execute_reply.started":"2022-11-05T06:09:15.628140Z","shell.execute_reply":"2022-11-05T06:09:15.632603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)\n        \ndef set_params(model, unfreeze):\n    for param in model.parameters():\n        param.requires_grad = unfreeze","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:17.023226Z","iopub.execute_input":"2022-11-05T06:09:17.023604Z","iopub.status.idle":"2022-11-05T06:09:17.030440Z","shell.execute_reply.started":"2022-11-05T06:09:17.023573Z","shell.execute_reply":"2022-11-05T06:09:17.029283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -qq torchsummary\nfrom torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:09:19.215637Z","iopub.execute_input":"2022-11-05T06:09:19.216834Z","iopub.status.idle":"2022-11-05T06:09:30.413553Z","shell.execute_reply.started":"2022-11-05T06:09:19.216789Z","shell.execute_reply":"2022-11-05T06:09:30.412081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KLDLoss(nn.Module):\n    def forward(self, mu, logvar, beta=1.0):  # beta = 0.1\n        kld = -0.5 * torch.sum(1 + logvar - torch.pow(mu, 2) - torch.exp(logvar))\n        return beta * kld  \n\n# reconstruction_loss = nn.functional.binary_cross_entropy_with_logits\nreconstruction_loss = nn.functional.mse_loss  # see https://stats.stackexchange.com/questions/409377/why-is-vae-reconstruction-loss-equal-to-mse-loss\n\nkld_loss = KLDLoss()\n\nkld_criterion = lambda x, y, mu, logvar: reconstruction_loss(y, x, reduction=\"sum\") + kld_loss(mu, logvar, beta=0.1)  # reduction sum here + weigth for kld_loss","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:57:44.672981Z","iopub.execute_input":"2022-11-05T06:57:44.673343Z","iopub.status.idle":"2022-11-05T06:57:44.680485Z","shell.execute_reply.started":"2022-11-05T06:57:44.673310Z","shell.execute_reply":"2022-11-05T06:57:44.679288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Reshape(nn.Module):\n    def __init__(self, shape=(512, 2, 2)):\n        self.shape = shape\n        super(Reshape, self).__init__()\n        \n    def forward(self, x):\n        return x.view(-1, *self.shape)\n    \n\nclass Generator(nn.Module):\n    def __init__(self, channels=3):\n        super(Generator, self).__init__()\n\n        def downsample(in_feat, out_feat, normalize=True):\n            layers = [nn.Conv2d(in_feat, out_feat, 4, stride=2, padding=1)]\n            if normalize:\n                layers.append(nn.BatchNorm2d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2))\n            return layers\n\n        def upsample(in_feat, out_feat, normalize=True):\n            layers = [nn.ConvTranspose2d(in_feat, out_feat, 4, stride=2, padding=1)]\n            if normalize:\n                layers.append(nn.BatchNorm2d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2))\n            return layers\n        \n        self.mean = nn.Linear(2048, 1024)\n        self.std = nn.Linear(2048, 1024)\n\n        self.encoder = nn.Sequential(\n                                    *downsample(channels, 64, normalize=False),\n                                    *downsample(64, 64),\n                                    *downsample(64, 128),\n                                    *downsample(128, 256),\n                                    *downsample(256, 512),\n                                    *downsample(512, 512),\n                                    nn.Flatten(),\n                                    nn.Linear(2048, 2048),\n                                    nn.LeakyReLU(0.2)\n                                    )\n            \n        self.decoder = nn.Sequential(\n                                    nn.Linear(1024, 2048),\n                                    # nn.Tanh(),  # decide whether to scale inputs\n                                    Reshape(),\n                                    *upsample(512, 512),\n                                    *upsample(512, 256),\n                                    *upsample(256, 128),\n                                    *upsample(128, 64),\n                                    *upsample(64, 32),\n                                    nn.Conv2d(32, channels, 3, 1, 1),\n                                    nn.Tanh()  # sigmoid if scale [0,1]\n                                )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        mu, logvar = self.mean(x), self.std(x)\n        z = self.reparameterize(mu, logvar)\n        y = self.decoder(z)\n        \n        return y, mu, logvar\n    \n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5*logvar)\n        eps = torch.randn_like(std)\n        sample = mu + (eps * std) \n        return sample","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:57:29.539509Z","iopub.execute_input":"2022-11-05T06:57:29.539886Z","iopub.status.idle":"2022-11-05T06:57:29.556612Z","shell.execute_reply.started":"2022-11-05T06:57:29.539855Z","shell.execute_reply":"2022-11-05T06:57:29.555685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Fully convolutional generator**","metadata":{}},{"cell_type":"code","source":"class ResDown(nn.Module):\n\n    def __init__(self, channel_in, channel_out, scale=2):\n        super(ResDown, self).__init__()\n        \n        self.conv1 = nn.Conv2d(channel_in, channel_out//2, 3, 1, 1)\n        self.batch_norm1 = nn.BatchNorm2d(channel_out//2, 0.8)\n        self.conv2 = nn.Conv2d(channel_out//2, channel_out, 3, scale, 1)\n        self.batch_norm2 = nn.BatchNorm2d(channel_out, 0.8)\n        \n        self.conv3 = nn.Conv2d(channel_in, channel_out, 3, scale, 1)\n        self.activation = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        skip = self.conv3(x)\n        \n        x = self.conv1(x)\n        x = self.batch_norm1(x)\n        x = self.activation(x)\n        \n        x = self.conv2(x)\n        x = self.batch_norm2(x)\n        x = self.activation(x + skip)\n        \n        return x\n    \nclass ResUp(nn.Module):\n    \n    def __init__(self, channel_in, channel_out, scale=2):\n        super(ResUp, self).__init__()\n        \n        self.conv1 = nn.Conv2d(channel_in, channel_out//2, 3, 1, 1)\n        self.batch_norm1 = nn.BatchNorm2d(channel_out//2, 0.8)\n        self.conv2 = nn.Conv2d(channel_out//2, channel_out, 3, 1, 1)\n        self.batch_norm2 = nn.BatchNorm2d(channel_out, 0.8)\n        \n        self.upscale = nn.Upsample(scale_factor=scale, mode=\"nearest\")\n        self.conv3 = nn.Conv2d(channel_in, channel_out, 3, 1, 1)\n        \n        self.activation = nn.LeakyReLU(0.2)\n        \n    def forward(self, x):\n        skip = self.conv3(self.upscale(x))\n        \n        x = self.conv1(x)\n        x = self.batch_norm1(x)\n        x = self.activation(x)\n\n        x = self.conv2(self.upscale(x))\n        x = self.batch_norm2(x)\n\n        x = self.activation(x + skip)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2022-11-05T08:52:49.901607Z","iopub.execute_input":"2022-11-05T08:52:49.901971Z","iopub.status.idle":"2022-11-05T08:52:49.915660Z","shell.execute_reply.started":"2022-11-05T08:52:49.901942Z","shell.execute_reply":"2022-11-05T08:52:49.914504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n\n    def __init__(self, channels, ch=64, z=512):\n        super(Encoder, self).__init__()\n        self.conv1 = ResDown(channels, ch)  \n        self.conv2 = ResDown(ch, 2*ch)  \n        self.conv3 = ResDown(2*ch, 4*ch)  \n        self.conv4 = ResDown(4*ch, 8*ch) \n        self.conv5 = ResDown(8*ch, 8*ch)  \n        self.conv_mu = nn.Conv2d(8*ch, z, 2, 2) \n        self.conv_log_var = nn.Conv2d(8*ch, z, 2, 2) \n\n    def sample(self, mu, log_var):\n        std = torch.exp(0.5*log_var)\n        eps = torch.randn_like(std)\n        return mu + eps*std\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n\n        mu = self.conv_mu(x)\n        log_var = self.conv_log_var(x)\n        x = self.sample(mu, log_var)\n\n        return x, mu, log_var\n    \nclass Decoder(nn.Module):\n\n    def __init__(self, channels, ch=64, z=512):\n        super(Decoder, self).__init__()\n        self.conv1 = ResUp(z, ch*8)\n        self.conv2 = ResUp(ch*8, ch*4)\n        self.conv3 = ResUp(ch*4, ch*2)\n        self.conv4 = ResUp(ch*2, ch)\n        self.conv5 = ResUp(ch, ch//2)\n        self.conv6 = nn.Conv2d(ch//2, channels, 3, 1, 1)\n        self.activation = nn.Tanh()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n\n        return self.activation(x) ","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:08:37.712948Z","iopub.execute_input":"2022-11-05T09:08:37.713323Z","iopub.status.idle":"2022-11-05T09:08:37.727631Z","shell.execute_reply.started":"2022-11-05T09:08:37.713292Z","shell.execute_reply":"2022-11-05T09:08:37.726422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResnetGenerator(nn.Module):\n    \n    def __init__(self, channel_in=3, ch=64, z=512):\n        super(ResnetGenerator, self).__init__()\n        \n        self.encoder = Encoder(channel_in, ch=ch, z=z)\n        self.decoder = Decoder(channel_in, ch=ch, z=z)\n\n    def forward(self, x):\n        encoding, mu, log_var = self.encoder(x)\n        recon = self.decoder(encoding)\n        return recon, mu, log_var","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:08:43.989018Z","iopub.execute_input":"2022-11-05T09:08:43.989392Z","iopub.status.idle":"2022-11-05T09:08:43.995977Z","shell.execute_reply.started":"2022-11-05T09:08:43.989347Z","shell.execute_reply":"2022-11-05T09:08:43.994866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, channels=3):\n        super(Discriminator, self).__init__()\n\n        def discriminator_block(in_filters, out_filters, stride, normalize, dropout, spectral):\n            \"\"\"Returns layers of each discriminator block\"\"\"\n            if spectral:\n                layers = [nn.utils.spectral_norm(nn.Conv2d(in_filters, out_filters, 3, stride, 1), n_power_iterations=2)]\n            else:\n                layers = [nn.Conv2d(in_filters, out_filters, 3, stride, 1)]\n            if normalize:\n                layers.append(nn.InstanceNorm2d(out_filters))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            if dropout:\n                layers.append(nn.Dropout(p=0.5))\n            return layers\n\n        layers = []\n        in_filters = channels\n        for out_filters, stride, normalize, dropout, spectral in [(64, 2, False, 0, 0), (128, 2, True, 0, 0), (256, 2, True, 0, 0), (512, 1, True, 0, 0)]:\n            layers.extend(discriminator_block(in_filters, out_filters, stride, normalize, dropout, spectral))\n            in_filters = out_filters\n\n        layers.append(nn.Conv2d(out_filters, 1, 3, 1, 1))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, img):\n        return self.model(img)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T06:10:07.315719Z","iopub.execute_input":"2022-11-05T06:10:07.316072Z","iopub.status.idle":"2022-11-05T06:10:07.327215Z","shell.execute_reply.started":"2022-11-05T06:10:07.316043Z","shell.execute_reply":"2022-11-05T06:10:07.326045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = ResnetGenerator().apply(init_weights).to(device)\ndiscriminator = Discriminator().apply(init_weights).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:08:43.998190Z","iopub.execute_input":"2022-11-05T09:08:43.998550Z","iopub.status.idle":"2022-11-05T09:08:44.305365Z","shell.execute_reply.started":"2022-11-05T09:08:43.998516Z","shell.execute_reply":"2022-11-05T09:08:44.304416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(generator, (3, 128, 128))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:08:44.307511Z","iopub.execute_input":"2022-11-05T09:08:44.307890Z","iopub.status.idle":"2022-11-05T09:08:44.333281Z","shell.execute_reply.started":"2022-11-05T09:08:44.307854Z","shell.execute_reply":"2022-11-05T09:08:44.332417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(discriminator, (3, 64, 64))","metadata":{"execution":{"iopub.status.busy":"2022-11-04T17:08:13.754110Z","iopub.execute_input":"2022-11-04T17:08:13.754523Z","iopub.status.idle":"2022-11-04T17:08:13.781608Z","shell.execute_reply.started":"2022-11-04T17:08:13.754491Z","shell.execute_reply":"2022-11-04T17:08:13.780713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Losses: wgan, perceptual, mse, l1, smoothl1","metadata":{}},{"cell_type":"code","source":"adversarial_loss = nn.MSELoss()  # instead of bce loss\n# pixelwise_loss = nn.L1Loss()\n\noptimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))  # AdamW weight_decay=1e-3, eps=1e-2\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:08:50.202871Z","iopub.execute_input":"2022-11-05T09:08:50.203235Z","iopub.status.idle":"2022-11-05T09:08:50.210203Z","shell.execute_reply.started":"2022-11-05T09:08:50.203204Z","shell.execute_reply":"2022-11-05T09:08:50.209250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_batch(batch, generator, discriminator, criterion_adv, criterion_pix, optimizer_G, optimizer_D):\n    generator.train()\n    discriminator.train()\n    \n    images, masked_images, masked_parts = batch\n    real = torch.FloatTensor(batch_size, *patch).fill_(1.0).requires_grad_(False).to(device)  # (1.0 - lambda)\n    fake = torch.FloatTensor(batch_size, *patch).fill_(0.0).requires_grad_(False).to(device)  # (lambda)\n    \n    set_params(discriminator, False)\n    optimizer_G.zero_grad()\n    gen_parts, mu, logvar = generator(masked_images)\n    \n    gan_loss = criterion_adv(discriminator(gen_parts), real)\n    pix_loss = criterion_pix(masked_parts, gen_parts, mu, logvar)\n    \n    loss_g = 0.001 * gan_loss + 0.999 * pix_loss\n    loss_g.backward()\n    optimizer_G.step()\n    \n    set_params(discriminator, True)\n    optimizer_D.zero_grad()\n\n    real_loss = criterion_adv(discriminator(masked_parts), real)\n    fake_loss = criterion_adv(discriminator(gen_parts.detach()), fake)\n    \n    loss_d = (real_loss + fake_loss) / 2\n    loss_d.backward()\n    optimizer_D.step()\n    \n    return loss_g.item(), loss_d.item()\n\n@torch.no_grad()\ndef validate_one_batch(batch, generator, discriminator, criterion_adv, criterion_pix):\n    generator.eval()\n    discriminator.eval()\n    \n    images, masked_images, masked_parts = batch\n    real = torch.FloatTensor(batch_size, *patch).fill_(1.0).requires_grad_(False).to(device)\n    fake = torch.FloatTensor(batch_size, *patch).fill_(0.0).requires_grad_(False).to(device)\n    \n    gen_parts, mu, logvar = generator(masked_images)\n    \n    gan_loss = criterion_adv(discriminator(gen_parts), real)  # smooth 0.1 for logloss?\n    pix_loss = criterion_pix(masked_parts, gen_parts, mu, logvar)\n    \n    loss_g = 0.001 * gan_loss + 0.999 * pix_loss\n    \n    real_loss = criterion_adv(discriminator(masked_parts), real)\n    fake_loss = criterion_adv(discriminator(gen_parts.detach()), fake)\n    \n    loss_d = (real_loss + fake_loss) / 2\n    \n    return loss_g.item(), loss_d.item()\n\n@torch.no_grad()\ndef test_plot(test, generator, scale=1):\n    idx = np.random.randint(len(test))\n    random_path = test[idx]\n    \n    image = Image.open(random_path)\n    image = transforms(image)\n    \n    masked_image, idx = train_dataset.apply_center_mask(image)\n    \n    generator.eval()\n    gen_part = generator(masked_image.unsqueeze(0).to(device))[0].squeeze(0).cpu().detach()\n    gen_image = masked_image.clone()\n    gen_image[:, idx:idx+mask_size, idx:idx+mask_size] = gen_part\n    \n    # scale [-1,1] or [0,1]\n    if scale:\n        run_transforms = inverse_transforms\n    else:\n        run_transforms = T.ToPILImage()\n    image = run_transforms(image)\n    masked_image = run_transforms(masked_image)\n    gen_image = run_transforms(gen_image)\n    \n    plt.figure(figsize=(10, 5))\n    plt.subplot(131)\n    plt.title('Original Image')\n    plt.imshow(image)\n    \n    plt.subplot(132)\n    plt.title('Masked Image')\n    plt.imshow(masked_image)\n    \n    plt.subplot(133)\n    plt.title('Inpainted Image')\n    plt.imshow(gen_image)\n    \n    plt.tight_layout()\n    plt.show()\n    plt.pause(0.01)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:08:51.729315Z","iopub.execute_input":"2022-11-05T09:08:51.729700Z","iopub.status.idle":"2022-11-05T09:08:51.747251Z","shell.execute_reply.started":"2022-11-05T09:08:51.729668Z","shell.execute_reply":"2022-11-05T09:08:51.745934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_d_losses, valid_d_losses = [], []\ntrain_g_losses, valid_g_losses = [], []\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch+1}/{epochs}')\n    tq_bar = tqdm(train_dataloader, total=len(train_dataloader), desc=f'Train step {epoch+1}')\n    epoch_d_losses, epoch_g_losses = [], []\n    for _, batch in enumerate(tq_bar):\n        g_loss, d_loss = train_one_batch(batch, generator, discriminator, adversarial_loss, \n                                         kld_criterion, optimizer_G, optimizer_D)\n        epoch_g_losses.append(g_loss)\n        epoch_d_losses.append(d_loss)\n        tq_bar.set_postfix(g_loss=np.mean(epoch_g_losses), d_loss=np.mean(epoch_d_losses))\n    train_d_losses.append(np.mean(epoch_d_losses))\n    train_g_losses.append(np.mean(epoch_g_losses))\n    \n    tq_bar = tqdm(valid_dataloader, total=len(valid_dataloader), desc=f'Validation step {epoch+1}')\n    epoch_d_losses, epoch_g_losses = [], []\n    for _, batch in enumerate(tq_bar):\n        g_loss, d_loss = validate_one_batch(batch, generator, discriminator, adversarial_loss, kld_criterion)\n        epoch_d_losses.append(d_loss)\n        epoch_g_losses.append(g_loss)\n        tq_bar.set_postfix(g_loss=np.mean(epoch_g_losses), d_loss=np.mean(epoch_d_losses))\n    valid_d_losses.append(np.mean(epoch_d_losses))\n    valid_g_losses.append(np.mean(epoch_g_losses))\n    \n    if (epoch+1) % 2 == 0 or (epoch+1) == epochs:\n        test_plot(test, generator)\n        checkpoint = {\n            'discriminator': discriminator,\n            'generator': generator,\n        }\n        torch.save(checkpoint, path)\n        \nplt.figure(figsize=(8, 4))\nx_axis = np.arange(1,epochs+1)\nplt.subplot(121)\nplt.title('Discriminator train/valid losses')\nplt.plot(x_axis, train_d_losses, label='train d_loss')\nplt.plot(x_axis, valid_d_losses, label='valid d_loss')\nplt.grid()\nplt.legend()\n\nplt.subplot(122)\nplt.title('Genrator train/valid losses')\nplt.plot(x_axis, train_g_losses, label='train g_loss')\nplt.plot(x_axis, valid_g_losses, label='valid_g_loss')\nplt.grid()\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-05T09:08:52.714357Z","iopub.execute_input":"2022-11-05T09:08:52.715051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_plot(test, generator)","metadata":{"execution":{"iopub.status.busy":"2022-11-05T11:49:25.550996Z","iopub.execute_input":"2022-11-05T11:49:25.552234Z","iopub.status.idle":"2022-11-05T11:49:26.008934Z","shell.execute_reply.started":"2022-11-05T11:49:25.552191Z","shell.execute_reply":"2022-11-05T11:49:26.008060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### [Kernel outputs visualization V1 vanilla CNN AE.](https://www.kaggle.com/code/pankratozzi/pytorch-vaegan-face-inpainting?scriptVersionId=102242524)\n#### [Kernel ouputs visualization V2 - CNN VAE with reparametrization](https://www.kaggle.com/code/pankratozzi/pytorch-vaegan-face-inpainting?scriptVersionId=110137217)","metadata":{}},{"cell_type":"markdown","source":"* for non-fixed masked area (when mask_size is not defined) + upsample(64,64) [3, 128, 128] -> [3, 64->128,64->128]\n* OR try UNET architecture with residual connections [3, 128, 128] -> [3, 128, 128]\n* OR maybe CycleGAN or Pix2PixGAN\n* OR, for example, this great paper: https://arxiv.org/pdf/1806.03589.pdf; [Fine&easy to understand implementation](https://github.com/nipponjo/deepfillv2-pytorch)","metadata":{}}]}