{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\n\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nfrom tqdm.autonotebook import tqdm\nfrom skimage.color import rgb2lab, lab2rgb\n\nfrom sklearn.model_selection import train_test_split\n\n#!pip install -q torchsummary\n#from torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-20T21:23:03.230462Z","iopub.execute_input":"2022-04-20T21:23:03.231801Z","iopub.status.idle":"2022-04-20T21:23:03.238467Z","shell.execute_reply.started":"2022-04-20T21:23:03.231747Z","shell.execute_reply":"2022-04-20T21:23:03.237646Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"seed = 42\ntorch.random.manual_seed(seed)\nnp.random.seed(seed)\n\nBATCH_SIZE = 4\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nepochs = 100\nloss_lambda = 100\n\nPATH = 'model.pth'\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Currently using {device.upper()} device.')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:05.427817Z","iopub.execute_input":"2022-04-20T21:23:05.428906Z","iopub.status.idle":"2022-04-20T21:23:05.436885Z","shell.execute_reply.started":"2022-04-20T21:23:05.428849Z","shell.execute_reply":"2022-04-20T21:23:05.436174Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"path = r'../input/image-colorization-dataset/data/'\n\ngrays = glob(path + 'train_black' + '/*.jpg')\ncolored = glob(path + 'train_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ndf_train = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:07.376371Z","iopub.execute_input":"2022-04-20T21:23:07.376724Z","iopub.status.idle":"2022-04-20T21:23:07.417989Z","shell.execute_reply.started":"2022-04-20T21:23:07.376686Z","shell.execute_reply":"2022-04-20T21:23:07.416977Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"grays = glob(path + 'test_black' + '/*.jpg')\ncolored = glob(path + 'test_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ntest = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:09.361800Z","iopub.execute_input":"2022-04-20T21:23:09.362533Z","iopub.status.idle":"2022-04-20T21:23:09.376618Z","shell.execute_reply.started":"2022-04-20T21:23:09.362471Z","shell.execute_reply":"2022-04-20T21:23:09.375564Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df_train, test_size=0.25, shuffle=True, random_state=seed)\nprint(f'Train size: {len(train)}, valid size: {len(valid)}, test size: {len(test)}.')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:11.445715Z","iopub.execute_input":"2022-04-20T21:23:11.446564Z","iopub.status.idle":"2022-04-20T21:23:11.457725Z","shell.execute_reply.started":"2022-04-20T21:23:11.446512Z","shell.execute_reply":"2022-04-20T21:23:11.456819Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n                              T.RandomHorizontalFlip(p=0.1),\n])\nfinal_transforms = T.Compose([\n                        T.ToTensor(),\n])\nvalid_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:20.463275Z","iopub.execute_input":"2022-04-20T21:23:20.463638Z","iopub.status.idle":"2022-04-20T21:23:20.469938Z","shell.execute_reply.started":"2022-04-20T21:23:20.463597Z","shell.execute_reply":"2022-04-20T21:23:20.469169Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"class ColorDataset(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, ix):\n        row = self.df.iloc[ix].squeeze()\n        color_image = cv2.imread(row['color'])\n        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n        color_image = self.transforms(color_image)\n        color_image = np.array(color_image)\n        img_lab = rgb2lab(color_image).astype(\"float32\")\n        img_lab = final_transforms(img_lab)\n        L = img_lab[[0], ...] / 50. - 1.\n        ab = img_lab[[1, 2], ...] / 110.\n        return L, ab\n    \n    def collate_fn(self, batch):\n        L, ab = list(zip(*batch))\n        L = [l[None].to(device) for l in L]\n        ab = [a_b[None].to(device) for a_b in ab]\n        L, ab = [torch.cat(i) for i in [L, ab]]\n        return L, ab","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:22.663399Z","iopub.execute_input":"2022-04-20T21:23:22.664055Z","iopub.status.idle":"2022-04-20T21:23:22.673546Z","shell.execute_reply.started":"2022-04-20T21:23:22.664001Z","shell.execute_reply":"2022-04-20T21:23:22.672480Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"train_dataset = ColorDataset(train, train_transforms)\nvalid_dataset = ColorDataset(valid, valid_transforms)\ntest_dataset = ColorDataset(test, valid_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=valid_dataset.collate_fn, drop_last=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE//4, shuffle=False, collate_fn=test_dataset.collate_fn, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:24.818273Z","iopub.execute_input":"2022-04-20T21:23:24.818613Z","iopub.status.idle":"2022-04-20T21:23:24.828819Z","shell.execute_reply.started":"2022-04-20T21:23:24.818580Z","shell.execute_reply":"2022-04-20T21:23:24.828027Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"class UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n            out_filters //= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:27.449187Z","iopub.execute_input":"2022-04-20T21:23:27.450039Z","iopub.status.idle":"2022-04-20T21:23:27.464620Z","shell.execute_reply.started":"2022-04-20T21:23:27.449996Z","shell.execute_reply":"2022-04-20T21:23:27.463569Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.discriminator = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.discriminator(input)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:30.216494Z","iopub.execute_input":"2022-04-20T21:23:30.216855Z","iopub.status.idle":"2022-04-20T21:23:30.225431Z","shell.execute_reply.started":"2022-04-20T21:23:30.216817Z","shell.execute_reply":"2022-04-20T21:23:30.224635Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"criterion_content_loss = nn.L1Loss()\n\ndef gan_loss(model_type, **kwargs):\n    if model_type == 'G':\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        return nn.functional.binary_cross_entropy(recon_discriminator_out, torch.ones_like(recon_discriminator_out))\n\n    elif model_type == 'D':\n        color_discriminator_out = kwargs['color_discriminator_out']\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        real_loss = nn.functional.binary_cross_entropy(color_discriminator_out, torch.ones_like(color_discriminator_out))\n        fake_loss = nn.functional.binary_cross_entropy(recon_discriminator_out, torch.zeros_like(recon_discriminator_out))\n        return (real_loss + fake_loss) / 2.0\n    \ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:32.503136Z","iopub.execute_input":"2022-04-20T21:23:32.503906Z","iopub.status.idle":"2022-04-20T21:23:32.512939Z","shell.execute_reply.started":"2022-04-20T21:23:32.503854Z","shell.execute_reply":"2022-04-20T21:23:32.511926Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"generator = Unet(input_c=1, output_c=2, n_down=8, num_filters=64).apply(init_weights).to(device)\ndiscriminator = Discriminator().apply(init_weights).to(device)\n\noptimizerG = torch.optim.AdamW(generator.parameters(), lr=1e-4, betas=(0.5, 0.999), amsgrad=True, weight_decay=1e-6)\noptimizerD = torch.optim.AdamW(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999), amsgrad=True, weight_decay=1e-6)\n\nlr_lambda = lambda epoch: (1 - (epoch - 20) / 100) if epoch > 20 else 1\nschedulerG = torch.optim.lr_scheduler.LambdaLR(optimizerG, lr_lambda=lr_lambda)\nschedulerD = torch.optim.lr_scheduler.LambdaLR(optimizerD, lr_lambda=lr_lambda)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:36.237429Z","iopub.execute_input":"2022-04-20T21:23:36.237727Z","iopub.status.idle":"2022-04-20T21:23:37.331761Z","shell.execute_reply.started":"2022-04-20T21:23:36.237698Z","shell.execute_reply":"2022-04-20T21:23:37.331055Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"summary(generator, (1,256,256))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:16:11.279659Z","iopub.execute_input":"2022-04-20T21:16:11.280070Z","iopub.status.idle":"2022-04-20T21:16:11.657314Z","shell.execute_reply.started":"2022-04-20T21:16:11.280035Z","shell.execute_reply":"2022-04-20T21:16:11.656303Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"summary(discriminator, (3,256,256))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T20:18:33.295646Z","iopub.execute_input":"2022-04-20T20:18:33.296648Z","iopub.status.idle":"2022-04-20T20:18:33.389249Z","shell.execute_reply.started":"2022-04-20T20:18:33.296590Z","shell.execute_reply":"2022-04-20T20:18:33.388299Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def grad_req(model, is_required=True):\n    for param in model.parameters():\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:44.274858Z","iopub.execute_input":"2022-04-20T21:23:44.275333Z","iopub.status.idle":"2022-04-20T21:23:44.280052Z","shell.execute_reply.started":"2022-04-20T21:23:44.275274Z","shell.execute_reply":"2022-04-20T21:23:44.279334Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"def train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD):\n    generator.train()\n    discriminator.train()\n\n    L, ab = data\n\n    fake_color = generator(L)\n    grad_req(discriminator, True)\n    \n    fake_image = torch.cat([L, fake_color], dim=1)\n    fake_preds = discriminator(fake_image.detach())\n    \n    optimizerD.zero_grad()\n\n    real_image = torch.cat([L, ab], dim=1)\n    real_preds = discriminator(real_image)\n    kwargs = {\n              'color_discriminator_out': real_preds, \n              'recon_discriminator_out': fake_preds,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    d_loss.backward()\n    optimizerD.step()\n\n    grad_req(discriminator, False)\n    optimizerG.zero_grad()\n    \n    fake_image = torch.cat([L, fake_color], dim=1)\n    fake_preds = discriminator(fake_image)\n    \n    kwargs = {\n              'recon_discriminator_out': fake_preds, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs)\n    loss_G_L1 = criterion_content_loss(fake_color, ab) * loss_lambda\n    g_loss = g_loss_gan + loss_G_L1\n    g_loss.backward()\n    optimizerG.step()\n\n    torch.nn.utils.clip_grad_norm_(generator.parameters(), 10.0)\n    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 10.0)\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterion_content_loss):\n    generator.eval()\n    discriminator.eval()\n\n    L, ab = data\n    \n    fake_color = generator(L)\n    fake_image = torch.cat([L, fake_color], dim=1)\n    real_image = torch.cat([L, ab], dim=1)\n    \n    color_discriminator_out = discriminator(real_image)\n    recon_discriminator_out = discriminator(fake_image)\n    kwargs = {\n              'color_discriminator_out': color_discriminator_out, \n              'recon_discriminator_out': recon_discriminator_out,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    \n    kwargs = {\n              'recon_discriminator_out': recon_discriminator_out, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs) \n    loss_G_L1 = criterion_content_loss(fake_color, ab) * loss_lambda \n    g_loss = g_loss_gan + loss_G_L1\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef visual_validate(data, generator):\n    L, ab = data\n    model.eval()\n    out = generator(L)\n    i = np.random.randint(0, BATCH_SIZE-1)\n    out, L, ab = out[i], L[i], ab[i]\n    L = (L + 1) * 50\n    ab = ab * 110\n    out = out * 110\n    true_image = lab2rgb(torch.cat([L, ab]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0)\n    black_image = L.detach().cpu().numpy().squeeze()\n    out_image = lab2rgb(torch.cat([L, out]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0)\n    plt.figure(figsize=(12,14))\n    plt.subplot(131)\n    plt.title('Black')\n    plt.imshow(black_image, cmap='gray')\n    plt.subplot(132)\n    plt.title('Colored')\n    plt.imshow(true_image)\n    plt.subplot(133)\n    plt.title('Black Colored')\n    plt.imshow(out_image)\n    plt.show()\n    plt.pause(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:46.157385Z","iopub.execute_input":"2022-04-20T21:23:46.158065Z","iopub.status.idle":"2022-04-20T21:23:46.176929Z","shell.execute_reply.started":"2022-04-20T21:23:46.158019Z","shell.execute_reply":"2022-04-20T21:23:46.175901Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"train_d_losses, train_g_losses, valid_d_losses, valid_g_losses = [], [], [], []\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n\n    train_epoch_d_loss, train_epoch_g_loss = [],[]\n    for _, data in enumerate(tqdm(train_dataloader, leave=False)): \n        d_loss, g_loss = train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD)\n        train_epoch_d_loss.append(d_loss)\n        train_epoch_g_loss.append(g_loss)\n    epoch_d_loss = np.array(train_epoch_d_loss).mean()\n    epoch_g_loss = np.array(train_epoch_g_loss).mean()\n    train_d_losses.append(epoch_d_loss)\n    train_g_losses.append(epoch_g_loss)\n    print(f'Train D loss: {epoch_d_loss:.4f}, train G loss: {epoch_g_loss:.4f}')\n\n    valid_epoch_g_loss, valid_epoch_d_loss = [],[]\n    for _, data in enumerate(tqdm(valid_dataloader, leave=False)):\n        d_loss, g_loss = validate(generator, discriminator, data, criterion_content_loss)\n        valid_epoch_g_loss.append(g_loss)\n        valid_epoch_d_loss.append(d_loss)\n    epoch_g_loss = np.array(valid_epoch_g_loss).mean()\n    epoch_d_loss = np.array(valid_epoch_d_loss).mean()\n    valid_g_losses.append(epoch_g_loss)\n    valid_d_losses.append(epoch_d_loss)\n    print(f'Validation D loss: {epoch_d_loss:.4f}, validation G loss: {epoch_g_loss:.4f}')\n    print('-'*50)    \n\n    schedulerD.step()\n    schedulerG.step()\n    if (epoch + 1) % 2 == 0:\n        checkpoint = {\n                      'epoch': epoch,     \n                      'G': generator,\n                      'D': discriminator,\n                      'optimizerG': optimizerG,\n                      'optimizerD': optimizerD,\n                      }\n        torch.save(checkpoint, PATH)\n        data = next(iter(valid_dataloader))\n        visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:23:52.148427Z","iopub.execute_input":"2022-04-20T21:23:52.148787Z","iopub.status.idle":"2022-04-20T21:24:03.276772Z","shell.execute_reply.started":"2022-04-20T21:23:52.148747Z","shell.execute_reply":"2022-04-20T21:24:03.274998Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = ColorDataset(train, valid_transforms)\ndl = DataLoader(ds, batch_size=2, shuffle=True, collate_fn=ds.collate_fn, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:22:08.202423Z","iopub.execute_input":"2022-04-20T21:22:08.202968Z","iopub.status.idle":"2022-04-20T21:22:08.209703Z","shell.execute_reply.started":"2022-04-20T21:22:08.202921Z","shell.execute_reply":"2022-04-20T21:22:08.208839Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"L, ab = ds[10]\nL = (L + 1) * 50\nab = ab * 110\nplt.imshow(lab2rgb(torch.cat([L, ab]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0))\nplt.imshow(L.detach().cpu().numpy().squeeze(), cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:22:11.602507Z","iopub.execute_input":"2022-04-20T21:22:11.603052Z","iopub.status.idle":"2022-04-20T21:22:11.837741Z","shell.execute_reply.started":"2022-04-20T21:22:11.603011Z","shell.execute_reply":"2022-04-20T21:22:11.836608Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"p = next(iter(dl))\nL, ab = p\n#images = torch.cat([L, ab], dim=1)\nL, ab = L[0], ab[0]\nL = (L + 1) * 50\nab = ab * 110\nimage = lab2rgb(torch.cat([L, ab]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0)\nplt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:32:02.163789Z","iopub.execute_input":"2022-04-20T21:32:02.164147Z","iopub.status.idle":"2022-04-20T21:32:02.453409Z","shell.execute_reply.started":"2022-04-20T21:32:02.164109Z","shell.execute_reply":"2022-04-20T21:32:02.452220Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"p = next(iter(dl))\nL, ab = p\nL.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-20T21:22:18.583653Z","iopub.execute_input":"2022-04-20T21:22:18.583970Z","iopub.status.idle":"2022-04-20T21:22:18.657089Z","shell.execute_reply.started":"2022-04-20T21:22:18.583923Z","shell.execute_reply":"2022-04-20T21:22:18.656139Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}