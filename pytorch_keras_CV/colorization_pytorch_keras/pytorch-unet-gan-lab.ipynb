{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\n\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nfrom tqdm.autonotebook import tqdm\nfrom skimage.color import rgb2lab, lab2rgb\n\nfrom sklearn.model_selection import train_test_split\n\n!pip install -q torchsummary\nfrom torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T15:28:23.047265Z","iopub.execute_input":"2022-04-21T15:28:23.047591Z","iopub.status.idle":"2022-04-21T15:28:34.858284Z","shell.execute_reply.started":"2022-04-21T15:28:23.047509Z","shell.execute_reply":"2022-04-21T15:28:34.857388Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Try:\n\n* batch_size = 8\n* lr_G = 1e-4\n* lr_D = 1e-4\n* Dropout_D?","metadata":{}},{"cell_type":"code","source":"seed = 42\ntorch.random.manual_seed(seed)\nnp.random.seed(seed)\n\nBATCH_SIZE = 8  # initially 4\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nepochs = 100\nloss_lambda = 100\n\nPATH = 'model.pth'\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Currently using {device.upper()} device.')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:28:42.929763Z","iopub.execute_input":"2022-04-21T15:28:42.930478Z","iopub.status.idle":"2022-04-21T15:28:42.992089Z","shell.execute_reply.started":"2022-04-21T15:28:42.930440Z","shell.execute_reply":"2022-04-21T15:28:42.991347Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = r'../input/image-colorization-dataset/data/'\n\ngrays = glob(path + 'train_black' + '/*.jpg')\ncolored = glob(path + 'train_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ndf_train = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:28:55.434010Z","iopub.execute_input":"2022-04-21T15:28:55.434282Z","iopub.status.idle":"2022-04-21T15:28:56.453354Z","shell.execute_reply.started":"2022-04-21T15:28:55.434255Z","shell.execute_reply":"2022-04-21T15:28:56.452657Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"grays = glob(path + 'test_black' + '/*.jpg')\ncolored = glob(path + 'test_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ntest = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:28:57.953563Z","iopub.execute_input":"2022-04-21T15:28:57.954137Z","iopub.status.idle":"2022-04-21T15:28:58.521537Z","shell.execute_reply.started":"2022-04-21T15:28:57.954099Z","shell.execute_reply":"2022-04-21T15:28:58.520797Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df_train, test_size=0.25, shuffle=True, random_state=seed)\nprint(f'Train size: {len(train)}, valid size: {len(valid)}, test size: {len(test)}.')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:29:00.118617Z","iopub.execute_input":"2022-04-21T15:29:00.119144Z","iopub.status.idle":"2022-04-21T15:29:00.131639Z","shell.execute_reply.started":"2022-04-21T15:29:00.119104Z","shell.execute_reply":"2022-04-21T15:29:00.130969Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n                              T.RandomHorizontalFlip(p=0.1),\n])\nfinal_transforms = T.Compose([\n                        T.ToTensor(),\n])\nvalid_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:29:02.534727Z","iopub.execute_input":"2022-04-21T15:29:02.535291Z","iopub.status.idle":"2022-04-21T15:29:02.540588Z","shell.execute_reply.started":"2022-04-21T15:29:02.535250Z","shell.execute_reply":"2022-04-21T15:29:02.539922Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ColorDataset(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, ix):\n        row = self.df.iloc[ix].squeeze()\n        color_image = cv2.imread(row['color'])\n        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n        color_image = self.transforms(color_image)\n        color_image = np.array(color_image)\n        img_lab = rgb2lab(color_image).astype(\"float32\")\n        img_lab = final_transforms(img_lab)\n        L = img_lab[[0], ...] / 50. - 1.\n        ab = img_lab[[1, 2], ...] / 110.\n        return L, ab\n    \n    def collate_fn(self, batch):\n        L, ab = list(zip(*batch))\n        L = [l[None].to(device) for l in L]\n        ab = [a_b[None].to(device) for a_b in ab]\n        L, ab = [torch.cat(i) for i in [L, ab]]\n        return L, ab","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:29:04.655713Z","iopub.execute_input":"2022-04-21T15:29:04.656388Z","iopub.status.idle":"2022-04-21T15:29:04.668189Z","shell.execute_reply.started":"2022-04-21T15:29:04.656350Z","shell.execute_reply":"2022-04-21T15:29:04.667498Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset = ColorDataset(train, train_transforms)\nvalid_dataset = ColorDataset(valid, valid_transforms)\ntest_dataset = ColorDataset(test, valid_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=valid_dataset.collate_fn, drop_last=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=test_dataset.collate_fn, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:04:07.540105Z","iopub.execute_input":"2022-04-21T16:04:07.540384Z","iopub.status.idle":"2022-04-21T16:04:07.547754Z","shell.execute_reply.started":"2022-04-21T16:04:07.540353Z","shell.execute_reply":"2022-04-21T16:04:07.546805Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# initially batchnorm2d\nclass UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False, instance=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni) if not instance else nn.InstanceNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf) if not instance else nn.InstanceNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64, instance=False):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True, instance=instance)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True, instance=instance)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block, instance=instance)\n            out_filters //= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True, instance=instance)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:30:46.633105Z","iopub.execute_input":"2022-04-21T15:30:46.633828Z","iopub.status.idle":"2022-04-21T15:30:46.650479Z","shell.execute_reply.started":"2022-04-21T15:30:46.633788Z","shell.execute_reply":"2022-04-21T15:30:46.649696Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# initially no dropout and batchnorm2d\n# instance norm computes learnable parameters for every instance in batch, it is better when instances have diff. distributions\n# Conv > Normalization > Activation > Dropout > Pooling\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        # spectral or instance norms? Dropout?\n        self.discriminator = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128), # nn.InstanceNorm2d(128), \n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2),\n            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256), # nn.InstanceNorm2d(256), \n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(512), # nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2),\n            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.discriminator(input)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:16:29.799787Z","iopub.execute_input":"2022-04-21T16:16:29.800044Z","iopub.status.idle":"2022-04-21T16:16:29.810402Z","shell.execute_reply.started":"2022-04-21T16:16:29.800016Z","shell.execute_reply":"2022-04-21T16:16:29.809587Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"criterion_content_loss = nn.L1Loss()  # nn.MSELoss?\n\ndef gan_loss(model_type, **kwargs):\n    if model_type == 'G':\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        return nn.functional.binary_cross_entropy(recon_discriminator_out, torch.ones_like(recon_discriminator_out))\n\n    elif model_type == 'D':\n        color_discriminator_out = kwargs['color_discriminator_out']\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        real_loss = nn.functional.binary_cross_entropy(color_discriminator_out, torch.ones_like(color_discriminator_out))\n        fake_loss = nn.functional.binary_cross_entropy(recon_discriminator_out, torch.zeros_like(recon_discriminator_out))\n        return (real_loss + fake_loss) / 2.0\n    \ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:15:32.166742Z","iopub.execute_input":"2022-04-21T16:15:32.167406Z","iopub.status.idle":"2022-04-21T16:15:32.176257Z","shell.execute_reply.started":"2022-04-21T16:15:32.167370Z","shell.execute_reply":"2022-04-21T16:15:32.175535Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"generator = Unet(input_c=1, output_c=2, n_down=8, num_filters=64, instance=False).apply(init_weights).to(device)\ndiscriminator = Discriminator().apply(init_weights).to(device)\n\n# initially lr_G = 1e-4, lr_D = 2e-4, lr_decay_G = lr_decay_D = 1e-6\n# the bigger batch_size the bigger learning rate\noptimizerG = torch.optim.AdamW(generator.parameters(), lr=5e-5, betas=(0.5, 0.999), amsgrad=True, weight_decay=1.5e-6)\noptimizerD = torch.optim.AdamW(discriminator.parameters(), lr=5e-5, betas=(0.5, 0.999), amsgrad=True, weight_decay=1.5e-6)\n\nschedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=20, gamma=0.5)\nschedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=20, gamma=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:16:40.546983Z","iopub.execute_input":"2022-04-21T16:16:40.547236Z","iopub.status.idle":"2022-04-21T16:16:41.519961Z","shell.execute_reply.started":"2022-04-21T16:16:40.547207Z","shell.execute_reply":"2022-04-21T16:16:41.519213Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"summary(generator, (1,256,256))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:16:45.972087Z","iopub.execute_input":"2022-04-21T16:16:45.972342Z","iopub.status.idle":"2022-04-21T16:16:46.108780Z","shell.execute_reply.started":"2022-04-21T16:16:45.972314Z","shell.execute_reply":"2022-04-21T16:16:46.108067Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"summary(discriminator, (3,256,256))","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:16:49.533466Z","iopub.execute_input":"2022-04-21T16:16:49.534319Z","iopub.status.idle":"2022-04-21T16:16:49.552620Z","shell.execute_reply.started":"2022-04-21T16:16:49.534281Z","shell.execute_reply":"2022-04-21T16:16:49.551734Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def grad_req(model, is_required=True):\n    for param in model.parameters():\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:31:39.798519Z","iopub.execute_input":"2022-04-21T15:31:39.798785Z","iopub.status.idle":"2022-04-21T15:31:39.802548Z","shell.execute_reply.started":"2022-04-21T15:31:39.798756Z","shell.execute_reply":"2022-04-21T15:31:39.801887Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD):\n    generator.train()\n    discriminator.train()\n\n    L, ab = data\n\n    fake_color = generator(L)\n    grad_req(discriminator, True)\n    \n    fake_image = torch.cat([L, fake_color], dim=1)\n    fake_preds = discriminator(fake_image.detach())\n    \n    optimizerD.zero_grad()\n\n    real_image = torch.cat([L, ab], dim=1)\n    real_preds = discriminator(real_image)\n    kwargs = {\n              'color_discriminator_out': real_preds, \n              'recon_discriminator_out': fake_preds,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    d_loss.backward()\n    optimizerD.step()\n\n    grad_req(discriminator, False)\n    optimizerG.zero_grad()\n    \n    fake_image = torch.cat([L, fake_color], dim=1)\n    fake_preds = discriminator(fake_image)\n    \n    kwargs = {\n              'recon_discriminator_out': fake_preds, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs)\n    loss_G_L1 = criterion_content_loss(fake_color, ab) * loss_lambda\n    g_loss = g_loss_gan + loss_G_L1\n    g_loss.backward()\n    optimizerG.step()\n\n    torch.nn.utils.clip_grad_norm_(generator.parameters(), 10.0)\n    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 10.0)\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterion_content_loss):\n    generator.eval()\n    discriminator.eval()\n\n    L, ab = data\n    \n    fake_color = generator(L)\n    fake_image = torch.cat([L, fake_color], dim=1)\n    real_image = torch.cat([L, ab], dim=1)\n    \n    color_discriminator_out = discriminator(real_image)\n    recon_discriminator_out = discriminator(fake_image)\n    kwargs = {\n              'color_discriminator_out': color_discriminator_out, \n              'recon_discriminator_out': recon_discriminator_out,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    \n    kwargs = {\n              'recon_discriminator_out': recon_discriminator_out, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs) \n    loss_G_L1 = criterion_content_loss(fake_color, ab) * loss_lambda \n    g_loss = g_loss_gan + loss_G_L1\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef visual_validate(data, generator):\n    L, ab = data\n    generator.eval()\n    out = generator(L)\n    i = np.random.randint(0, BATCH_SIZE)\n    out, L, ab = out[i], L[i], ab[i]\n    L = (L + 1) * 50\n    ab = ab * 110\n    out = out * 110\n    true_image = lab2rgb(torch.cat([L, ab]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0)\n    black_image = L.detach().cpu().numpy().squeeze()\n    out_image = lab2rgb(torch.cat([L, out]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0)\n    plt.figure(figsize=(12,14))\n    plt.subplot(131)\n    plt.title('Black')\n    plt.imshow(black_image, cmap='gray')\n    plt.subplot(132)\n    plt.title('Colored')\n    plt.imshow(true_image)\n    plt.subplot(133)\n    plt.title('Black Colored')\n    plt.imshow(out_image)\n    plt.show()\n    plt.pause(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T15:31:41.284946Z","iopub.execute_input":"2022-04-21T15:31:41.285511Z","iopub.status.idle":"2022-04-21T15:31:41.305357Z","shell.execute_reply.started":"2022-04-21T15:31:41.285476Z","shell.execute_reply":"2022-04-21T15:31:41.304621Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_d_losses, train_g_losses, valid_d_losses, valid_g_losses = [], [], [], []\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n\n    train_epoch_d_loss, train_epoch_g_loss = [],[]\n    for _, data in enumerate(tqdm(train_dataloader, leave=False)): \n        d_loss, g_loss = train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD)\n        train_epoch_d_loss.append(d_loss)\n        train_epoch_g_loss.append(g_loss)\n    epoch_d_loss = np.array(train_epoch_d_loss).mean()\n    epoch_g_loss = np.array(train_epoch_g_loss).mean()\n    train_d_losses.append(epoch_d_loss)\n    train_g_losses.append(epoch_g_loss)\n    print(f'Train D loss: {epoch_d_loss:.4f}, train G loss: {epoch_g_loss:.4f}')\n\n    valid_epoch_g_loss, valid_epoch_d_loss = [],[]\n    for _, data in enumerate(tqdm(valid_dataloader, leave=False)):\n        d_loss, g_loss = validate(generator, discriminator, data, criterion_content_loss)\n        valid_epoch_g_loss.append(g_loss)\n        valid_epoch_d_loss.append(d_loss)\n    epoch_g_loss = np.array(valid_epoch_g_loss).mean()\n    epoch_d_loss = np.array(valid_epoch_d_loss).mean()\n    valid_g_losses.append(epoch_g_loss)\n    valid_d_losses.append(epoch_d_loss)\n    print(f'Validation D loss: {epoch_d_loss:.4f}, validation G loss: {epoch_g_loss:.4f}')\n    print('-'*50)    \n\n    schedulerD.step()\n    schedulerG.step()\n    if (epoch + 1) % 2 == 0:\n        checkpoint = {\n                      'epoch': epoch,     \n                      'G': generator,\n                      'D': discriminator,\n                      'optimizerG': optimizerG,\n                      'optimizerD': optimizerD,\n                      }\n        torch.save(checkpoint, PATH)\n        data = next(iter(valid_dataloader))\n        visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:16:57.492591Z","iopub.execute_input":"2022-04-21T16:16:57.493139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_dataloader","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As the author suggests we may use pretrained Unet model to retrain it on colorization task and only then use it in our above Unet-GAN implementation (just pass it to the train_one_batch, validate functions), which significantly improves the quality of colorization results\n```\nfrom fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet\n\n\ndef build_res_unet(n_input=1, n_output=2, size=256):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n    \ndef pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n    for e in range(epochs):\n        for data in train_dalaloader:\n            L, ab = data\n            preds = net_G(L)\n            loss = criterion(preds, ab)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \nnet_G = build_res_unet(n_input=1, n_output=2, size=256)\nopt = optim.Adam(net_G.parameters(), lr=1e-4)\ncriterion = nn.L1Loss()        \npretrain_generator(net_G, train_dl, opt, criterion, 20)\ntorch.save(net_G.state_dict(), \"res18-unet.pth\")\n```\n[https://towardsdatascience.com/colorizing-black-white-images-with-u-net-and-conditional-gan-a-tutorial-81b2df111cd8](http://)","metadata":{}},{"cell_type":"markdown","source":"##### Tests","metadata":{}},{"cell_type":"code","source":"data = next(iter(test_dataloader))\nvisual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:02:40.999944Z","iopub.execute_input":"2022-04-21T10:02:41.000191Z","iopub.status.idle":"2022-04-21T10:02:41.580842Z","shell.execute_reply.started":"2022-04-21T10:02:41.000163Z","shell.execute_reply":"2022-04-21T10:02:41.580183Z"},"trusted":true},"execution_count":null,"outputs":[]}]}