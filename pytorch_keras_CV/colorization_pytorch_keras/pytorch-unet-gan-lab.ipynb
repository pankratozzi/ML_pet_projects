{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torch.autograd as autograd\n\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nfrom tqdm.autonotebook import tqdm\nfrom skimage.color import rgb2lab, lab2rgb\n\nfrom sklearn.model_selection import train_test_split\n\n#!pip install -q torchsummary\n#from torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-24T23:11:44.198792Z","iopub.execute_input":"2022-04-24T23:11:44.200041Z","iopub.status.idle":"2022-04-24T23:11:46.978054Z","shell.execute_reply.started":"2022-04-24T23:11:44.199715Z","shell.execute_reply":"2022-04-24T23:11:46.977334Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"seed = 42\ntorch.random.manual_seed(seed)\nnp.random.seed(seed)\n\nBATCH_SIZE = 4  # initially 4, then 8\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nepochs = 100\nloss_lambda = 100\ngp_lambda = 10 # for alt. version\n\nPATH = 'model.pth'\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Currently using {device.upper()} device.')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:11:46.979672Z","iopub.execute_input":"2022-04-24T23:11:46.979994Z","iopub.status.idle":"2022-04-24T23:11:47.050884Z","shell.execute_reply.started":"2022-04-24T23:11:46.979956Z","shell.execute_reply":"2022-04-24T23:11:47.050105Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = r'../input/image-colorization-dataset/data/'\n\ngrays = glob(path + 'train_black' + '/*.jpg')\ncolored = glob(path + 'train_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ndf_train = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:11:49.463896Z","iopub.execute_input":"2022-04-24T23:11:49.464575Z","iopub.status.idle":"2022-04-24T23:11:50.113591Z","shell.execute_reply.started":"2022-04-24T23:11:49.464537Z","shell.execute_reply":"2022-04-24T23:11:50.112872Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"grays = glob(path + 'test_black' + '/*.jpg')\ncolored = glob(path + 'test_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ntest = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:11:51.664080Z","iopub.execute_input":"2022-04-24T23:11:51.664616Z","iopub.status.idle":"2022-04-24T23:11:52.077888Z","shell.execute_reply.started":"2022-04-24T23:11:51.664577Z","shell.execute_reply":"2022-04-24T23:11:52.077064Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df_train, test_size=0.25, shuffle=True, random_state=seed)\nprint(f'Train size: {len(train)}, valid size: {len(valid)}, test size: {len(test)}.')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:11:53.882247Z","iopub.execute_input":"2022-04-24T23:11:53.883045Z","iopub.status.idle":"2022-04-24T23:11:53.895273Z","shell.execute_reply.started":"2022-04-24T23:11:53.883002Z","shell.execute_reply":"2022-04-24T23:11:53.894349Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n                              T.RandomHorizontalFlip(p=0.2),\n])\nfinal_transforms = T.Compose([\n                        T.ToTensor(),\n])\nvalid_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n])","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:11:56.122566Z","iopub.execute_input":"2022-04-24T23:11:56.123189Z","iopub.status.idle":"2022-04-24T23:11:56.130494Z","shell.execute_reply.started":"2022-04-24T23:11:56.123148Z","shell.execute_reply":"2022-04-24T23:11:56.128674Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ColorDataset(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, ix):\n        row = self.df.iloc[ix].squeeze()\n        color_image = cv2.imread(row['color'])\n        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n        color_image = self.transforms(color_image)\n        color_image = np.array(color_image)\n        img_lab = rgb2lab(color_image).astype(\"float32\")\n        img_lab = final_transforms(img_lab)\n        L = img_lab[[0], ...] / 50. - 1.\n        ab = img_lab[[1, 2], ...] / 110.\n        return L, ab\n    \n    def collate_fn(self, batch):\n        L, ab = list(zip(*batch))\n        L = [l[None].to(device) for l in L]\n        ab = [a_b[None].to(device) for a_b in ab]\n        L, ab = [torch.cat(i) for i in [L, ab]]\n        return L, ab","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:11:58.867786Z","iopub.execute_input":"2022-04-24T23:11:58.868329Z","iopub.status.idle":"2022-04-24T23:11:58.879987Z","shell.execute_reply.started":"2022-04-24T23:11:58.868287Z","shell.execute_reply":"2022-04-24T23:11:58.879086Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset = ColorDataset(train, train_transforms)\nvalid_dataset = ColorDataset(valid, valid_transforms)\ntest_dataset = ColorDataset(test, valid_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=valid_dataset.collate_fn, drop_last=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=test_dataset.collate_fn, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:12:01.893030Z","iopub.execute_input":"2022-04-24T23:12:01.893285Z","iopub.status.idle":"2022-04-24T23:12:01.899150Z","shell.execute_reply.started":"2022-04-24T23:12:01.893257Z","shell.execute_reply":"2022-04-24T23:12:01.898467Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# initially batchnorm2d\nclass UnetBlock(nn.Module):\n    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n                 innermost=False, outermost=False, instance=False):\n        super().__init__()\n        self.outermost = outermost\n        if input_c is None: input_c = nf\n        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n                             stride=2, padding=1, bias=False)\n        downrelu = nn.LeakyReLU(0.2, True)\n        downnorm = nn.BatchNorm2d(ni) if not instance else nn.InstanceNorm2d(ni)\n        uprelu = nn.ReLU(True)\n        upnorm = nn.BatchNorm2d(nf) if not instance else nn.InstanceNorm2d(nf)\n        \n        if outermost:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1)\n            down = [downconv]\n            up = [uprelu, upconv, nn.Tanh()]\n            model = down + [submodule] + up\n        elif innermost:\n            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv]\n            up = [uprelu, upconv, upnorm]\n            model = down + up\n        else:\n            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n                                        stride=2, padding=1, bias=False)\n            down = [downrelu, downconv, downnorm]\n            up = [uprelu, upconv, upnorm]\n            if dropout: up += [nn.Dropout(0.5)]\n            model = down + [submodule] + up\n        self.model = nn.Sequential(*model)\n    \n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], 1)\n\nclass Unet(nn.Module):\n    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64, instance=False):\n        super().__init__()\n        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True, instance=instance)\n        for _ in range(n_down - 5):\n            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True, instance=instance)\n        out_filters = num_filters * 8\n        for _ in range(3):\n            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block, instance=instance)\n            out_filters //= 2\n        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True, instance=instance)\n    \n    def forward(self, x):\n        return self.model(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T22:53:50.925803Z","iopub.execute_input":"2022-04-24T22:53:50.926332Z","iopub.status.idle":"2022-04-24T22:53:50.943664Z","shell.execute_reply.started":"2022-04-24T22:53:50.926295Z","shell.execute_reply":"2022-04-24T22:53:50.942793Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# initially no dropout and batchnorm2d\n# instance norm computes learnable parameters for every instance in batch, it is better when instances have diff. distributions\n# Conv > Normalization > Activation > Dropout > Pooling\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        # spectral or instance norms? Dropout?\n        self.discriminator = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # nn.utils.spectral_norm(nn.Conv2d(64, 128, 4, 2, 1, bias=False), n_power_iterations=2),\n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(128), # nn.InstanceNorm2d(128), \n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2),\n            # nn.utils.spectral_norm(nn.Conv2d(128, 256, 4, 2, 1, bias=False), n_power_iterations=2),\n            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(256), # nn.InstanceNorm2d(256), \n            nn.LeakyReLU(0.2, inplace=True),\n            # nn.utils.spectral_norm(nn.Conv2d(256, 512, 4, 2, 1, bias=False), n_power_iterations=2),\n            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(512), # nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2),\n            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.discriminator(input)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:20:12.597291Z","iopub.execute_input":"2022-04-24T23:20:12.597958Z","iopub.status.idle":"2022-04-24T23:20:12.608929Z","shell.execute_reply.started":"2022-04-24T23:20:12.597923Z","shell.execute_reply":"2022-04-24T23:20:12.608195Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"criterion_content_loss = nn.L1Loss()  # nn.MSELoss?\n\ndef gan_loss(model_type, **kwargs):\n    if model_type == 'G':\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        return nn.functional.binary_cross_entropy(recon_discriminator_out, torch.ones_like(recon_discriminator_out))\n\n    elif model_type == 'D':\n        color_discriminator_out = kwargs['color_discriminator_out']\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        real_loss = nn.functional.binary_cross_entropy(color_discriminator_out, torch.ones_like(color_discriminator_out))\n        fake_loss = nn.functional.binary_cross_entropy(recon_discriminator_out, torch.zeros_like(recon_discriminator_out))\n        return (real_loss + fake_loss) / 2.0\n    \ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:12:06.914663Z","iopub.execute_input":"2022-04-24T23:12:06.915382Z","iopub.status.idle":"2022-04-24T23:12:06.925864Z","shell.execute_reply.started":"2022-04-24T23:12:06.915334Z","shell.execute_reply":"2022-04-24T23:12:06.924890Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# if using generator from scratch - uncomment\n#generator = Unet(input_c=1, output_c=2, n_down=8, num_filters=64, instance=False).apply(init_weights).to(device)\ndiscriminator = Discriminator().apply(init_weights).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:48:10.894014Z","iopub.execute_input":"2022-04-24T23:48:10.894271Z","iopub.status.idle":"2022-04-24T23:48:10.944818Z","shell.execute_reply.started":"2022-04-24T23:48:10.894243Z","shell.execute_reply":"2022-04-24T23:48:10.944056Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# initially lr_G = 1e-4, lr_D = 2e-4, lr_decay_G = lr_decay_D = 1e-6\n# the bigger batch_size the bigger learning rate\noptimizerG = torch.optim.AdamW(generator.parameters(), lr=1e-4, betas=(0.5, 0.999), amsgrad=True, weight_decay=6e-6)\noptimizerD = torch.optim.AdamW(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999), amsgrad=True, weight_decay=6e-6)\n\nschedulerG = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=20, gamma=0.5)\nschedulerD = torch.optim.lr_scheduler.StepLR(optimizerD, step_size=20, gamma=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:48:12.692611Z","iopub.execute_input":"2022-04-24T23:48:12.693362Z","iopub.status.idle":"2022-04-24T23:48:12.700893Z","shell.execute_reply.started":"2022-04-24T23:48:12.693328Z","shell.execute_reply":"2022-04-24T23:48:12.699776Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"summary(generator, (1,256,256))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T14:54:39.983528Z","iopub.execute_input":"2022-04-23T14:54:39.984176Z","iopub.status.idle":"2022-04-23T14:54:44.967723Z","shell.execute_reply.started":"2022-04-23T14:54:39.984136Z","shell.execute_reply":"2022-04-23T14:54:44.966992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(discriminator, (3,256,256))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T14:54:44.969269Z","iopub.execute_input":"2022-04-23T14:54:44.969504Z","iopub.status.idle":"2022-04-23T14:54:45.848982Z","shell.execute_reply.started":"2022-04-23T14:54:44.969474Z","shell.execute_reply":"2022-04-23T14:54:45.848333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grad_req(model, is_required=True):\n    for param in model.parameters():\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:12:11.795011Z","iopub.execute_input":"2022-04-24T23:12:11.795261Z","iopub.status.idle":"2022-04-24T23:12:11.800396Z","shell.execute_reply.started":"2022-04-24T23:12:11.795233Z","shell.execute_reply":"2022-04-24T23:12:11.799715Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD):\n    generator.train()\n    discriminator.train()\n\n    L, ab = data\n\n    fake_color = generator(L)\n    grad_req(discriminator, True)\n    \n    fake_image = torch.cat([L, fake_color], dim=1)\n    fake_preds = discriminator(fake_image.detach())\n    \n    optimizerD.zero_grad()\n\n    real_image = torch.cat([L, ab], dim=1)\n    real_preds = discriminator(real_image)\n    kwargs = {\n              'color_discriminator_out': real_preds, \n              'recon_discriminator_out': fake_preds,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    d_loss.backward()\n    optimizerD.step()\n\n    grad_req(discriminator, False)\n    optimizerG.zero_grad()\n    \n    fake_image = torch.cat([L, fake_color], dim=1)\n    fake_preds = discriminator(fake_image)\n    \n    kwargs = {\n              'recon_discriminator_out': fake_preds, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs)\n    loss_G_L1 = criterion_content_loss(fake_color, ab) * loss_lambda\n    g_loss = g_loss_gan + loss_G_L1\n    g_loss.backward()\n    optimizerG.step()\n\n    torch.nn.utils.clip_grad_norm_(generator.parameters(), 10.0)\n    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 10.0)\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterion_content_loss):\n    generator.eval()\n    discriminator.eval()\n\n    L, ab = data\n    \n    fake_color = generator(L)\n    fake_image = torch.cat([L, fake_color], dim=1)\n    real_image = torch.cat([L, ab], dim=1)\n    \n    color_discriminator_out = discriminator(real_image)\n    recon_discriminator_out = discriminator(fake_image)\n    kwargs = {\n              'color_discriminator_out': color_discriminator_out, \n              'recon_discriminator_out': recon_discriminator_out,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    \n    kwargs = {\n              'recon_discriminator_out': recon_discriminator_out, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs) \n    loss_G_L1 = criterion_content_loss(fake_color, ab) * loss_lambda \n    g_loss = g_loss_gan + loss_G_L1\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef visual_validate(data, generator):\n    L, ab = data\n    generator.eval()\n    out = generator(L)\n    i = np.random.randint(0, BATCH_SIZE)\n    out, L, ab = out[i], L[i], ab[i]\n    L = (L + 1) * 50\n    ab = ab * 110\n    out = out * 110\n    true_image = lab2rgb(torch.cat([L, ab]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0)\n    black_image = L.detach().cpu().numpy().squeeze()\n    out_image = lab2rgb(torch.cat([L, out]).detach().cpu().numpy(), channel_axis=0).transpose(1,2,0)\n    plt.figure(figsize=(12,14))\n    plt.subplot(131)\n    plt.title('Black')\n    plt.imshow(black_image, cmap='gray')\n    plt.subplot(132)\n    plt.title('Colored')\n    plt.imshow(true_image)\n    plt.subplot(133)\n    plt.title('Black Colored')\n    plt.imshow(out_image)\n    plt.show()\n    plt.pause(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:12:13.960246Z","iopub.execute_input":"2022-04-24T23:12:13.960513Z","iopub.status.idle":"2022-04-24T23:12:13.981051Z","shell.execute_reply.started":"2022-04-24T23:12:13.960481Z","shell.execute_reply":"2022-04-24T23:12:13.980213Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### Alternative: WGAN Loss, PSNR metric","metadata":{}},{"cell_type":"code","source":"CONV3_3_IN_VGG_19 = torchvision.models.vgg19(pretrained=True, progress=False).features[:15].to(device)\n\ndef PSNR(fake_image, real_image):\n    mse = torch.mean((fake_image - real_image) ** 2)\n    if mse == 0:\n        return 100\n    PIXEL_MAX = 1\n    return 10 * np.log10(PIXEL_MAX ** 2 / mse)\n\nclass WGANLoss(nn.Module):\n    def forward(self, mtype, **kwargs):\n        if mtype == 'G':\n            fake_preds = kwargs['fake_preds']\n            return -fake_preds.mean()\n\n        elif mtype == 'D':  \n            gp_lambda = kwargs['gp_lambda']\n            interpolates = kwargs['interpolates']\n            interpolates_discriminator_out = kwargs['interpolates_discriminator_out']\n            real_discriminator_out = kwargs['real_discriminator_out']\n            fake_discriminator_out = kwargs['fake_discriminator_out']\n\n            wgan_loss = fake_discriminator_out.mean() - real_discriminator_out.mean()\n\n            gradients = autograd.grad(outputs=interpolates_discriminator_out, inputs=interpolates,\n                                      grad_outputs=torch.ones(interpolates_discriminator_out.size()).to(device),\n                                      retain_graph=True,\n                                      create_graph=True)[0]\n            gradient_penalty = ((gradients.view(gradients.size(0), -1).norm(2, dim=1) - 1) ** 2).mean()\n\n            return wgan_loss, gp_lambda * gradient_penalty\n\nclass ContentLoss(nn.Module):\n    def forward(self, fake_image, real_image, model=CONV3_3_IN_VGG_19):\n        fake_feature_map = model.forward(fake_image)\n        real_feature_map = model.forward(real_image).detach()\n        loss = nn.functional.mse_loss(fake_feature_map, real_feature_map)\n        return loss\n    \ncriterion_wgan = WGANLoss()\ncriterion_content = ContentLoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:12:18.595805Z","iopub.execute_input":"2022-04-24T23:12:18.596448Z","iopub.status.idle":"2022-04-24T23:12:57.366316Z","shell.execute_reply.started":"2022-04-24T23:12:18.596393Z","shell.execute_reply":"2022-04-24T23:12:57.365578Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_one_batch(generator, discriminator, data, criterion_content, optimizerG, optimizerD, critic_updates=3):\n    generator.train()\n    discriminator.train()\n\n    L, ab = data\n\n    fake_color = generator(L)\n    grad_req(discriminator, True)\n    \n    fake_image = torch.cat([L, fake_color], dim=1)\n    #fake_preds = discriminator(fake_image.detach())\n\n    real_image = torch.cat([L, ab], dim=1)\n    #real_preds = discriminator(real_image.detach())\n    \n    d_loss = 0\n    for i in range(critic_updates):    \n        fake_preds = discriminator(fake_image.detach())\n        real_preds = discriminator(real_image.detach())\n        \n        optimizerD.zero_grad()\n\n        alpha = np.random.random()\n        interpolates = alpha * real_image + (1 - alpha) * fake_image\n        #interpolates = (alpha * real_image.detach() + (1 - alpha) * fake_image.detach()).requires_grad_(True)\n        interpolates_discriminator_out = discriminator(interpolates)\n        \n        kwargs = {\n                  'gp_lambda': gp_lambda,\n                  'interpolates': interpolates, \n                  'interpolates_discriminator_out': interpolates_discriminator_out, \n                  'real_discriminator_out': real_preds, \n                  'fake_discriminator_out': fake_preds,  \n                  }\n        wgan_loss_d, gp_d = criterion_wgan('D', **kwargs)\n        discriminator_loss_per_update = wgan_loss_d + gp_d\n        discriminator_loss_per_update.backward(retain_graph=True)\n        optimizerD.step()\n        d_loss += discriminator_loss_per_update.item()\n    d_loss /= critic_updates\n\n    grad_req(discriminator, False)\n    optimizerG.zero_grad()\n\n    fake_image = torch.cat([L, fake_color], dim=1)\n    fake_preds = discriminator(fake_image)\n    \n    kwargs = {\n              'fake_preds': fake_preds, \n              }    \n    g_loss_gan = criterion_wgan('G', **kwargs)\n    loss_G_L1 = criterion_content(fake_image, real_image) * loss_lambda\n    g_loss = g_loss_gan + loss_G_L1\n    g_loss.backward()\n    optimizerG.step()\n\n    torch.nn.utils.clip_grad_norm_(generator.parameters(), 10.0)\n    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 10.0)\n    \n    with torch.no_grad():\n        denorm_fake_color = fake_color.detach().cpu() * 110\n        denorm_real_color = ab.detach().cpu() * 110\n    metric = PSNR(denorm_fake_color, denorm_real_color)\n\n    return d_loss, g_loss.item(), metric\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterion_content_loss):\n    generator.eval()\n    discriminator.eval()\n\n    L, ab = data\n    \n    fake_color = generator(L)\n    fake_image = torch.cat([L, fake_color], dim=1)\n    real_image = torch.cat([L, ab], dim=1)\n    \n    color_discriminator_out = discriminator(real_image)\n    recon_discriminator_out = discriminator(fake_image)\n    kwargs = {\n              'color_discriminator_out': color_discriminator_out, \n              'recon_discriminator_out': recon_discriminator_out,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    \n    kwargs = {\n              'fake_preds': recon_discriminator_out, \n              }    \n    g_loss_gan = criterion_wgan('G', **kwargs)\n    loss_G_L1 = criterion_content(fake_image, real_image) * loss_lambda\n    g_loss = g_loss_gan + loss_G_L1\n    \n    denorm_fake_color = fake_color.detach().cpu() * 110\n    denorm_real_color = ab.detach().cpu() * 110\n    metric = PSNR(denorm_fake_color, denorm_real_color)\n\n    return d_loss.item(), g_loss.item(), metric","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:47:51.384772Z","iopub.execute_input":"2022-04-24T23:47:51.385032Z","iopub.status.idle":"2022-04-24T23:47:51.402052Z","shell.execute_reply.started":"2022-04-24T23:47:51.385004Z","shell.execute_reply":"2022-04-24T23:47:51.401350Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"#### end alternatve part","metadata":{}},{"cell_type":"markdown","source":"Init\n* batch_size=4\n* dropout true both, BatchNorm2d\n* lr_G = 1e-4, lr_D = 2e-4\n* schedulers LambdaLR after 20 epochs\n\nNot the best result, but model learns, nevertheless over incr. epochs the quality decreased  \n\nPrevious\n* batch_size=8\n* dropout in generator = False and discriminator = True, BatchNorm2d\n* lr_G = 1e-4 lr_D = 2e-4\n* no schedulers\n\nPoor result\n\nPrevious\n* batch_size=4\n* dropout in generator = True + BN2d and discriminator dropout = True + spectral_norm\n* lr_G = 1e-4 lr_D = 2e-4\n* no schedulers\n* generator grad clip norm off\n* epochs >= 200?\n\nBetter than previous obviously, but worse than init and generator overfits (and overtakes discriminator)\n\nCurrent\n* batch_size=4\n* trainned generator from fastai (load weights), custom discriminator OR **from torchvision.models**\n* init only optimizers\n* no lr decay\n* lr_G = 1e-4 lr_D = 2e-4\n* ! option: **pretrain custom discriminator** for 20 epochs to classify black and colored images\n\nNext\n* batch_size = 8\n* generator (BN2d) and discriminator (spectral norm) with dropouts OR if some improvement in previous try - take pretrained\n* lr_G = 1e-4, lr_D = 2e-4\n* LambdaLR schedulers\n* grad clips on\n* WGAN Loss with multiple critic updates instead of classic gan_loss function\n* epochs >= 200\n\nTo UPD:\n* more epochs, >=200\n* more train images, >= x3","metadata":{}},{"cell_type":"code","source":"train_d_losses, train_g_losses, valid_d_losses, valid_g_losses = [], [], [], []\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n\n    train_epoch_d_loss, train_epoch_g_loss = [],[]\n    for _, data in enumerate(tqdm(train_dataloader, leave=False)):\n        with torch.autograd.set_detect_anomaly(True):\n            d_loss, g_loss, metric = train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD)\n        train_epoch_d_loss.append(d_loss)\n        train_epoch_g_loss.append(g_loss)\n    epoch_d_loss = np.array(train_epoch_d_loss).mean()\n    epoch_g_loss = np.array(train_epoch_g_loss).mean()\n    train_d_losses.append(epoch_d_loss)\n    train_g_losses.append(epoch_g_loss)\n    print(f'Train D loss: {epoch_d_loss:.4f}, train G loss: {epoch_g_loss:.4f}')\n\n    valid_epoch_g_loss, valid_epoch_d_loss = [],[]\n    for _, data in enumerate(tqdm(valid_dataloader, leave=False)):\n        d_loss, g_loss, metric = validate(generator, discriminator, data, criterion_content_loss)\n        valid_epoch_g_loss.append(g_loss)\n        valid_epoch_d_loss.append(d_loss)\n    epoch_g_loss = np.array(valid_epoch_g_loss).mean()\n    epoch_d_loss = np.array(valid_epoch_d_loss).mean()\n    valid_g_losses.append(epoch_g_loss)\n    valid_d_losses.append(epoch_d_loss)\n    print(f'Validation D loss: {epoch_d_loss:.4f}, validation G loss: {epoch_g_loss:.4f}')\n    print('-'*50)    \n\n    #schedulerD.step()  #\n    #schedulerG.step()  #\n    if (epoch + 1) % 2 == 0:\n        checkpoint = {\n                      'epoch': epoch,     \n                      'G': generator,\n                      'D': discriminator,\n                      'optimizerG': optimizerG,\n                      'optimizerD': optimizerD,\n                      }\n        torch.save(checkpoint, PATH)\n        data = next(iter(valid_dataloader))\n        visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:48:23.086312Z","iopub.execute_input":"2022-04-24T23:48:23.087028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_dataloader","metadata":{"execution":{"iopub.status.busy":"2022-04-24T20:19:03.457438Z","iopub.execute_input":"2022-04-24T20:19:03.457720Z","iopub.status.idle":"2022-04-24T20:19:03.465057Z","shell.execute_reply.started":"2022-04-24T20:19:03.457690Z","shell.execute_reply":"2022-04-24T20:19:03.464310Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"#### As the author suggests we may use pretrained Unet model to retrain it on colorization task and only then use it in our above Unet-GAN implementation (just pass it to the train_one_batch, validate functions), which significantly improves the quality of colorization results\n```\nfrom fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet\n\n\ndef build_res_unet(n_input=1, n_output=2, size=256):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n    \ndef pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n    for e in range(epochs):\n        for data in train_dalaloader:\n            L, ab = data\n            preds = net_G(L)\n            loss = criterion(preds, ab)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            \ngenerator = build_res_unet(n_input=1, n_output=2, size=256)\nopt = optim.Adam(generator.parameters(), lr=1e-4)\ncriterion = nn.L1Loss()        \npretrain_generator(generator, train_dataloader, opt, criterion, 20)\ntorch.save(generator.state_dict(), \"res18-unet.pth\")\n```\n[https://towardsdatascience.com/colorizing-black-white-images-with-u-net-and-conditional-gan-a-tutorial-81b2df111cd8](http://)\n\n#### For discriminator we also may use pretrained model, e.i. from torch.models., such as vgg16, resnet18, efficient_b0, etc.\n#### or pretrain custom discriminator to classify black and colored images\n```\ndef get_d_model():\n    model = torchvision.models.efficient_b0(pretrained=True, progress=False)\n    for param in model.parameters():\n        param.requires_grad = False\n    model.classifier = nn.Sequential(\n        nn.Linear(1280, 625),\n        nn.ReLU(True),\n        nn.Dropout(0.4),\n        nn.Linear(625, 256),\n        nn.ReLU(True),\n        nn.Dropout(0.4),\n        nn.Linear(256, 1),\n        nn.Sigmoid(),\n    )\n    return model.to(device)\n```","metadata":{}},{"cell_type":"code","source":"from fastai.vision.learner import create_body\nfrom torchvision.models.resnet import resnet18\nfrom fastai.vision.models.unet import DynamicUnet\n\n\ndef build_res_unet(n_input=1, n_output=2, size=256):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n    return net_G\n\ndef pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n    for e in tqdm(range(epochs), total=epochs, leave=False):\n        for data in train_dl:\n            L, ab = data\n            preds = net_G(L)\n            loss = criterion(preds, ab)\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n\ngenerator = build_res_unet(n_input=1, n_output=2, size=256)\n\n# Alredy trained\n#opt = torch.optim.Adam(generator.parameters(), lr=1e-4)\n#criterion = nn.L1Loss()        \n#pretrain_generator(generator, train_dataloader, opt, criterion, 20)\n#torch.save(generator.state_dict(), 'generator.pth')","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:12:57.388163Z","iopub.execute_input":"2022-04-24T23:12:57.388460Z","iopub.status.idle":"2022-04-24T23:13:03.180233Z","shell.execute_reply.started":"2022-04-24T23:12:57.388420Z","shell.execute_reply":"2022-04-24T23:13:03.179510Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"generator.load_state_dict(torch.load('../input/resnetunetweights/generator.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:48:03.147343Z","iopub.execute_input":"2022-04-24T23:48:03.148081Z","iopub.status.idle":"2022-04-24T23:48:03.245993Z","shell.execute_reply.started":"2022-04-24T23:48:03.148041Z","shell.execute_reply":"2022-04-24T23:48:03.245239Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"!pip install -q efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:13:09.188006Z","iopub.execute_input":"2022-04-24T23:13:09.188703Z","iopub.status.idle":"2022-04-24T23:13:20.597902Z","shell.execute_reply.started":"2022-04-24T23:13:09.188664Z","shell.execute_reply":"2022-04-24T23:13:20.597043Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from efficientnet_pytorch import EfficientNet\n\ndef get_d_model():\n    model = EfficientNet.from_name('efficientnet-b0')\n    for param in model.parameters():\n        param.requires_grad = False\n    num_ftrs = model._fc.in_features\n    model._fc = nn.Sequential(nn.Linear(num_ftrs, 1),\n                              nn.Sigmoid())\n    return model.to(device)\n\ndiscriminator = get_d_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-24T23:16:02.374795Z","iopub.execute_input":"2022-04-24T23:16:02.375544Z","iopub.status.idle":"2022-04-24T23:16:02.455751Z","shell.execute_reply.started":"2022-04-24T23:16:02.375506Z","shell.execute_reply":"2022-04-24T23:16:02.455048Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"##### Tests","metadata":{}},{"cell_type":"code","source":"data = next(iter(test_dataloader))\nvisual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T10:02:40.999944Z","iopub.execute_input":"2022-04-21T10:02:41.000191Z","iopub.status.idle":"2022-04-21T10:02:41.580842Z","shell.execute_reply.started":"2022-04-21T10:02:41.000163Z","shell.execute_reply":"2022-04-21T10:02:41.580183Z"},"trusted":true},"execution_count":null,"outputs":[]}]}