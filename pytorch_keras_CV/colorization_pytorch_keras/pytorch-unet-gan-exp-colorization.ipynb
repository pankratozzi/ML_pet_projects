{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms as T\nimport torch.autograd as autograd\n\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom glob import glob\nfrom tqdm.autonotebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\n#!pip install -q torchsummary\n#from torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-20T18:44:43.753739Z","iopub.execute_input":"2022-04-20T18:44:43.753999Z","iopub.status.idle":"2022-04-20T18:44:52.974657Z","shell.execute_reply.started":"2022-04-20T18:44:43.753971Z","shell.execute_reply":"2022-04-20T18:44:52.973753Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"seed = 42\ntorch.random.manual_seed(seed)\nnp.random.seed(seed)\n\nBATCH_SIZE = 8\nIMAGE_HEIGHT = 224\nIMAGE_WIDTH = 224\nepochs = 100\nmse_loss_lambda = 100\n\nPATH = 'model.pth'\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Currently using {device.upper()} device.')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:51:34.174712Z","iopub.execute_input":"2022-04-20T12:51:34.175275Z","iopub.status.idle":"2022-04-20T12:51:34.244952Z","shell.execute_reply.started":"2022-04-20T12:51:34.175238Z","shell.execute_reply":"2022-04-20T12:51:34.244178Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = r'../input/image-colorization-dataset/data/'\n\ngrays = glob(path + 'train_black' + '/*.jpg')\ncolored = glob(path + 'train_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ndf_train = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:51:39.623196Z","iopub.execute_input":"2022-04-20T12:51:39.623923Z","iopub.status.idle":"2022-04-20T12:51:39.955825Z","shell.execute_reply.started":"2022-04-20T12:51:39.623884Z","shell.execute_reply":"2022-04-20T12:51:39.954816Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"grays = glob(path + 'test_black' + '/*.jpg')\ncolored = glob(path + 'test_color' + '/*.jpg')\n\ngrays = sorted([str(x) for x in grays])\ncolored = sorted([str(x) for x in colored])\n\ntest = pd.DataFrame(data={'gray': grays, 'color': colored})","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:51:42.696429Z","iopub.execute_input":"2022-04-20T12:51:42.696983Z","iopub.status.idle":"2022-04-20T12:51:42.866624Z","shell.execute_reply.started":"2022-04-20T12:51:42.696946Z","shell.execute_reply":"2022-04-20T12:51:42.865879Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df_train, test_size=0.25, shuffle=True, random_state=seed)\nprint(f'Train size: {len(train)}, valid size: {len(valid)}, test size: {len(test)}.')","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:51:54.180104Z","iopub.execute_input":"2022-04-20T12:51:54.180368Z","iopub.status.idle":"2022-04-20T12:51:54.193000Z","shell.execute_reply.started":"2022-04-20T12:51:54.180339Z","shell.execute_reply":"2022-04-20T12:51:54.192165Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n                              T.RandomHorizontalFlip(p=0.1),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])\nvalid_transforms = T.Compose([\n                              T.ToPILImage(),\n                              T.Resize((IMAGE_WIDTH, IMAGE_HEIGHT)),\n                              T.ToTensor(),\n                              T.Normalize(0.5, 0.5),\n])\n\ndef denormalize(image_tensor):\n    return (image_tensor + 1) / 2.0","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:52:00.253772Z","iopub.execute_input":"2022-04-20T12:52:00.254318Z","iopub.status.idle":"2022-04-20T12:52:00.260376Z","shell.execute_reply.started":"2022-04-20T12:52:00.254278Z","shell.execute_reply":"2022-04-20T12:52:00.259430Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ColorDataset(Dataset):\n    def __init__(self, df, transforms):\n        self.df = df\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, ix):\n        row = self.df.iloc[ix].squeeze()\n        gray_image = cv2.imread(row['gray'])\n        gray_image = cv2.cvtColor(gray_image, cv2.COLOR_BGR2RGB)\n        color_image = cv2.imread(row['color'])\n        color_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n        return gray_image, color_image\n    \n    def collate_fn(self, batch):\n        grays, colored = list(zip(*batch))\n        grays = [self.transforms(img)[None] for img in grays]\n        colored = [self.transforms(img)[None] for img in colored]\n        grays, colored = [torch.cat(i).to(device) for i in [grays, colored]]\n        return grays, colored","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:52:03.898556Z","iopub.execute_input":"2022-04-20T12:52:03.898885Z","iopub.status.idle":"2022-04-20T12:52:03.914905Z","shell.execute_reply.started":"2022-04-20T12:52:03.898849Z","shell.execute_reply":"2022-04-20T12:52:03.913985Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset = ColorDataset(train, train_transforms)\nvalid_dataset = ColorDataset(valid, valid_transforms)\ntest_dataset = ColorDataset(test, valid_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\nvalid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=valid_dataset.collate_fn, drop_last=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE//4, shuffle=False, collate_fn=test_dataset.collate_fn, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:52:06.901166Z","iopub.execute_input":"2022-04-20T12:52:06.901421Z","iopub.status.idle":"2022-04-20T12:52:06.908058Z","shell.execute_reply.started":"2022-04-20T12:52:06.901392Z","shell.execute_reply":"2022-04-20T12:52:06.907016Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Identity(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        return x\n\nclass DownConv(nn.Module):\n    def __init__(self, ni, no, maxpool=True):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.MaxPool2d(2) if maxpool else Identity(),\n            nn.Conv2d(ni, no, 3, padding=1),\n            nn.BatchNorm2d(no),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(no, no, 3, padding=1),\n            nn.BatchNorm2d(no),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n    def forward(self, x):\n        return self.model(x)\n    \nclass UpConv(nn.Module):\n    def __init__(self, ni, no, maxpool=True):\n        super().__init__()\n        self.convtranspose = nn.ConvTranspose2d(ni, no, 2, stride=2)\n        self.convlayers = nn.Sequential(\n            nn.Conv2d(no+no, no, 3, padding=1),\n            nn.BatchNorm2d(no),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(no, no, 3, padding=1),\n            nn.BatchNorm2d(no),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n        \n    def forward(self, x, y):\n        x = self.convtranspose(x)\n        x = torch.cat([x,y], axis=1)\n        x = self.convlayers(x)\n        return x\n    \nclass UNet(nn.Module):\n    def __init__(self, maxpool=False):\n        super().__init__()\n        self.d1 = DownConv( 3, 64, maxpool=maxpool)\n        self.d2 = DownConv( 64, 128)\n        self.d3 = DownConv( 128, 256)\n        self.d4 = DownConv( 256, 512)\n        self.d5 = DownConv( 512, 1024)\n        self.u5 = UpConv (1024, 512)\n        self.u4 = UpConv ( 512, 256)\n        self.u3 = UpConv ( 256, 128)\n        self.u2 = UpConv ( 128, 64)\n        self.u1 = nn.Conv2d(64, 3, kernel_size=1, stride=1)\n\n    def forward(self, x):\n        x0 = self.d1(x)\n        x1 = self.d2(x0)\n        x2 = self.d3(x1)\n        x3 = self.d4(x2)\n        x4 = self.d5(x3)\n        X4 = self.u5(x4, x3)\n        X3 = self.u4(X4, x2)\n        X2 = self.u3(X3, x1)\n        X1 = self.u2(X2, x0)\n        X0 = self.u1(X1)\n        return X0","metadata":{"execution":{"iopub.status.busy":"2022-04-20T12:52:10.965465Z","iopub.execute_input":"2022-04-20T12:52:10.966263Z","iopub.status.idle":"2022-04-20T12:52:10.983628Z","shell.execute_reply.started":"2022-04-20T12:52:10.966227Z","shell.execute_reply":"2022-04-20T12:52:10.982661Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"summary(UNet(maxpool=False), (3,224,224))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T11:23:35.864737Z","iopub.execute_input":"2022-04-20T11:23:35.865089Z","iopub.status.idle":"2022-04-20T11:23:37.640785Z","shell.execute_reply.started":"2022-04-20T11:23:35.865054Z","shell.execute_reply":"2022-04-20T11:23:37.639853Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.discriminator = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n            nn.InstanceNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n            nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.discriminator(input)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:26:22.480926Z","iopub.execute_input":"2022-04-20T19:26:22.481199Z","iopub.status.idle":"2022-04-20T19:26:22.489653Z","shell.execute_reply.started":"2022-04-20T19:26:22.481171Z","shell.execute_reply":"2022-04-20T19:26:22.488932Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"summary(Discriminator().to(device), (3,224,224))","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:26:25.117350Z","iopub.execute_input":"2022-04-20T19:26:25.117713Z","iopub.status.idle":"2022-04-20T19:26:25.170851Z","shell.execute_reply.started":"2022-04-20T19:26:25.117673Z","shell.execute_reply":"2022-04-20T19:26:25.169977Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"criterion_content_loss = nn.MSELoss()\n\ndef gan_loss(model_type, **kwargs):\n    if model_type == 'G':\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        return nn.functional.binary_cross_entropy(recon_discriminator_out, torch.ones_like(recon_discriminator_out))\n\n    elif model_type == 'D':\n        color_discriminator_out = kwargs['color_discriminator_out']\n        recon_discriminator_out = kwargs['recon_discriminator_out']\n        real_loss = nn.functional.binary_cross_entropy(color_discriminator_out, torch.ones_like(color_discriminator_out))\n        fake_loss = nn.functional.binary_cross_entropy(recon_discriminator_out, torch.zeros_like(recon_discriminator_out))\n        return (real_loss + fake_loss) / 2.0\n    \ndef init_weights(m):\n    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n        nn.init.normal_(m.weight, 0, 0.02)\n        if m.bias is not None:\n            nn.init.zeros_(m.bias)\n    if isinstance(m, nn.BatchNorm2d):\n        nn.init.normal_(m.weight, 1, 0.02)\n        nn.init.zeros_(m.bias)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:36:16.965608Z","iopub.execute_input":"2022-04-20T19:36:16.965870Z","iopub.status.idle":"2022-04-20T19:36:16.985317Z","shell.execute_reply.started":"2022-04-20T19:36:16.965843Z","shell.execute_reply":"2022-04-20T19:36:16.983411Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"generator = UNet().apply(init_weights).to(device)\ndiscriminator = Discriminator().apply(init_weights).to(device)\n\noptimizerG = torch.optim.AdamW(generator.parameters(), lr=1e-4, betas=(0.5, 0.999), amsgrad=True, weight_decay=1e-6)\noptimizerD = torch.optim.AdamW(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999), amsgrad=True, weight_decay=1e-6)\n\nlr_lambda = lambda epoch: (1 - (epoch - 20) / 100) if epoch > 20 else 1\nschedulerG = torch.optim.lr_scheduler.LambdaLR(optimizerG, lr_lambda=lr_lambda)\nschedulerD = torch.optim.lr_scheduler.LambdaLR(optimizerD, lr_lambda=lr_lambda)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:36:20.435087Z","iopub.execute_input":"2022-04-20T19:36:20.435350Z","iopub.status.idle":"2022-04-20T19:36:21.000181Z","shell.execute_reply.started":"2022-04-20T19:36:20.435320Z","shell.execute_reply":"2022-04-20T19:36:20.999317Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD):\n    generator.train()\n    discriminator.train()\n\n    gray, colored = data\n\n    recon = generator(gray)\n    color_discriminator_out = discriminator(colored)\n    recon_discriminator_out = discriminator(recon)\n\n    optimizerD.zero_grad()\n    kwargs = {\n              'color_discriminator_out': color_discriminator_out, \n              'recon_discriminator_out': recon_discriminator_out,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    \n    d_loss.backward(retain_graph=True)\n    optimizerD.step()\n\n    optimizerG.zero_grad()\n    \n    recon = generator(gray)\n    recon_discriminator_out = discriminator(recon)\n    \n    kwargs = {\n              'recon_discriminator_out': recon_discriminator_out, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs) * mse_loss_lambda\n    content_loss_g = criterion_content_loss(recon, colored) \n    g_loss = g_loss_gan + content_loss_g\n    g_loss.backward()\n    optimizerG.step()\n\n    torch.nn.utils.clip_grad_norm_(generator.parameters(), 10.0)\n    torch.nn.utils.clip_grad_norm_(discriminator.parameters(), 10.0)\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef validate(generator, discriminator, data, criterion_content_loss):\n    generator.eval()\n    discriminator.eval()\n\n    gray, colored = data\n    recon = generator(gray)\n    color_discriminator_out = discriminator(colored)\n    recon_discriminator_out = discriminator(recon)\n    kwargs = {\n              'color_discriminator_out': color_discriminator_out, \n              'recon_discriminator_out': recon_discriminator_out,  \n             }\n    d_loss = gan_loss('D', **kwargs)\n    \n    kwargs = {\n              'recon_discriminator_out': recon_discriminator_out, \n              }    \n    g_loss_gan = gan_loss('G', **kwargs) * mse_loss_lambda\n    content_loss_g = criterion_content_loss(recon, colored) \n    g_loss = g_loss_gan + content_loss_g\n\n    return d_loss.item(), g_loss.item()\n\n@torch.no_grad()\ndef visual_validate(data, model):\n    img, tar = data\n    model.eval()\n    out = model(img)\n    i = np.random.randint(0, BATCH_SIZE-1)\n    out, img, tar = out[i], img[i], tar[i]\n    out, img, tar = [denormalize(tensor) for tensor in [out, img, tar]]\n    out, img, tar = [tensor.squeeze().cpu().detach().numpy().transpose(1,2,0) for tensor in [out, img, tar]]\n    plt.figure(figsize=(12,14))\n    plt.subplot(131)\n    plt.title('Black')\n    plt.imshow(img)\n    plt.subplot(132)\n    plt.title('Colored')\n    plt.imshow(tar)\n    plt.subplot(133)\n    plt.title('Black Colored')\n    plt.imshow(out)\n    plt.show()\n    plt.pause(0.001)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T13:23:08.588833Z","iopub.execute_input":"2022-04-20T13:23:08.589089Z","iopub.status.idle":"2022-04-20T13:23:08.605116Z","shell.execute_reply.started":"2022-04-20T13:23:08.589060Z","shell.execute_reply":"2022-04-20T13:23:08.604205Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_d_losses, train_g_losses, valid_d_losses, valid_g_losses = [], [], [], []\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch + 1}/{epochs}')\n\n    train_epoch_d_loss, train_epoch_g_loss = [],[]\n    for _, data in enumerate(tqdm(train_dataloader, leave=False)): \n        d_loss, g_loss = train_one_batch(generator, discriminator, data, criterion_content_loss, optimizerG, optimizerD)\n        train_epoch_d_loss.append(d_loss)\n        train_epoch_g_loss.append(g_loss)\n    epoch_d_loss = np.array(train_epoch_d_loss).mean()\n    epoch_g_loss = np.array(train_epoch_g_loss).mean()\n    train_d_losses.append(epoch_d_loss)\n    train_g_losses.append(epoch_g_loss)\n    print(f'Train D loss: {epoch_d_loss:.4f}, train G loss: {epoch_g_loss:.4f}')\n\n    valid_epoch_g_loss, valid_epoch_d_loss = [],[]\n    for _, data in enumerate(tqdm(valid_dataloader, leave=False)):\n        d_loss, g_loss = validate(generator, discriminator, data, criterion_content_loss)\n        valid_epoch_g_loss.append(g_loss)\n        valid_epoch_d_loss.append(d_loss)\n    epoch_g_loss = np.array(valid_epoch_g_loss).mean()\n    epoch_d_loss = np.array(valid_epoch_d_loss).mean()\n    valid_g_losses.append(epoch_g_loss)\n    valid_d_losses.append(epoch_d_loss)\n    print(f'Validation D loss: {epoch_d_loss:.4f}, validation G loss: {epoch_g_loss:.4f}')\n    print('-'*50)    \n\n    schedulerD.step()\n    schedulerG.step()\n    if (epoch + 1) % 2 == 0:\n        checkpoint = {\n                      'epoch': epoch,     \n                      'G': generator,\n                      'D': discriminator,\n                      'optimizerG': optimizerG,\n                      'optimizerD': optimizerD,\n                      }\n        torch.save(checkpoint, PATH)\n        data = next(iter(valid_dataloader))\n        visual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T19:36:25.628324Z","iopub.execute_input":"2022-04-20T19:36:25.628714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = next(iter(valid_dataloader))\nvisual_validate(data, generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-20T18:41:49.177624Z","iopub.execute_input":"2022-04-20T18:41:49.178374Z","iopub.status.idle":"2022-04-20T18:41:49.829233Z","shell.execute_reply.started":"2022-04-20T18:41:49.178333Z","shell.execute_reply":"2022-04-20T18:41:49.828560Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}