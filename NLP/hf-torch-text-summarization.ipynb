{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qq evaluate rouge_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-17T22:38:25.183778Z","iopub.execute_input":"2023-02-17T22:38:25.184376Z","iopub.status.idle":"2023-02-17T22:38:38.398919Z","shell.execute_reply.started":"2023-02-17T22:38:25.184339Z","shell.execute_reply":"2023-02-17T22:38:38.397525Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom datasets import Dataset, DatasetDict\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSeq2SeqLM\nfrom transformers import Seq2SeqTrainingArguments\nfrom transformers import DataCollatorForSeq2Seq\nfrom transformers import Seq2SeqTrainer\nfrom transformers import get_scheduler\n\nimport pandas as pd\nimport numpy as np\nimport re, os\n\nfrom sklearn.model_selection import train_test_split\n\nfrom nltk.tokenize import sent_tokenize\nimport nltk\nnltk.download(\"punkt\")\n\nimport evaluate\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:38.403387Z","iopub.execute_input":"2023-02-17T22:38:38.403709Z","iopub.status.idle":"2023-02-17T22:38:51.318151Z","shell.execute_reply.started":"2023-02-17T22:38:38.403676Z","shell.execute_reply":"2023-02-17T22:38:51.317055Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"model_checkpoint = \"sberbank-ai/ruT5-base\"\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\napi_key = \"56c1808ba8ff36c4a47631bc7ed7085928332d7b\"","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:51.319752Z","iopub.execute_input":"2023-02-17T22:38:51.320766Z","iopub.status.idle":"2023-02-17T22:38:51.331411Z","shell.execute_reply.started":"2023-02-17T22:38:51.320722Z","shell.execute_reply":"2023-02-17T22:38:51.329413Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/recipes-and-interpretation-dim/all_recepies_inter.csv\", sep=\"\\t\", usecols=[\"name\", \"Инструкции\"]).rename(columns={\"Инструкции\": \"Instructions\"})","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:51.335193Z","iopub.execute_input":"2023-02-17T22:38:51.336081Z","iopub.status.idle":"2023-02-17T22:38:53.193844Z","shell.execute_reply.started":"2023-02-17T22:38:51.336036Z","shell.execute_reply":"2023-02-17T22:38:53.192860Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df[\"name\"] = df[\"name\"].apply(lambda x: x.replace(u'\\xa0', u' '))\ndf[\"Instructions\"] = df[\"Instructions\"].apply(lambda x: x.replace(u'\\xa0', u' '))\ndf[\"Instructions\"] = df[\"Instructions\"].apply(lambda x: re.sub(\"\\n|\\r|\\t\", \" \",  x))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:53.195279Z","iopub.execute_input":"2023-02-17T22:38:53.195930Z","iopub.status.idle":"2023-02-17T22:38:53.206859Z","shell.execute_reply.started":"2023-02-17T22:38:53.195891Z","shell.execute_reply":"2023-02-17T22:38:53.205874Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train, valid = train_test_split(df, test_size=0.3, random_state=42)\ntrain.reset_index(drop=True, inplace=True)\nvalid.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:53.208320Z","iopub.execute_input":"2023-02-17T22:38:53.209383Z","iopub.status.idle":"2023-02-17T22:38:53.223548Z","shell.execute_reply.started":"2023-02-17T22:38:53.209347Z","shell.execute_reply":"2023-02-17T22:38:53.222316Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train)\nvalid_ds = Dataset.from_pandas(valid)\n\nds = DatasetDict()\n\nds['train'] = train_ds\nds['validation'] = valid_ds","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:53.225709Z","iopub.execute_input":"2023-02-17T22:38:53.226756Z","iopub.status.idle":"2023-02-17T22:38:53.251951Z","shell.execute_reply.started":"2023-02-17T22:38:53.226721Z","shell.execute_reply":"2023-02-17T22:38:53.251076Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:53.253374Z","iopub.execute_input":"2023-02-17T22:38:53.253795Z","iopub.status.idle":"2023-02-17T22:38:55.319843Z","shell.execute_reply.started":"2023-02-17T22:38:53.253755Z","shell.execute_reply":"2023-02-17T22:38:55.318852Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6353231154144390b1e22729dbfbf956"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/980k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60214704ce584440a991a26b49b45979"}},"metadata":{}}]},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 16\n\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"Instructions\"],\n        max_length=max_input_length,\n        truncation=True,\n    )\n    labels = tokenizer(\n        examples[\"name\"], max_length=max_target_length, truncation=True\n    )\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:55.323571Z","iopub.execute_input":"2023-02-17T22:38:55.323885Z","iopub.status.idle":"2023-02-17T22:38:55.331348Z","shell.execute_reply.started":"2023-02-17T22:38:55.323858Z","shell.execute_reply":"2023-02-17T22:38:55.329715Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = ds.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:55.335385Z","iopub.execute_input":"2023-02-17T22:38:55.337691Z","iopub.status.idle":"2023-02-17T22:38:55.540406Z","shell.execute_reply.started":"2023-02-17T22:38:55.337657Z","shell.execute_reply":"2023-02-17T22:38:55.539491Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4c0ff94c99042b195085cacdbf6734b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae1131e83a24c19a6c8271881bf169c"}},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:38:55.541782Z","iopub.execute_input":"2023-02-17T22:38:55.542925Z","iopub.status.idle":"2023-02-17T22:39:28.909948Z","shell.execute_reply.started":"2023-02-17T22:38:55.542880Z","shell.execute_reply":"2023-02-17T22:39:28.908865Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/850M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66397b5960cf461b802d3e474017d422"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 8\nnum_train_epochs = 3\n\nlogging_steps = len(tokenized_datasets[\"train\"]) // batch_size\nmodel_name = model_checkpoint.split(\"/\")[-1]\n\nargs = Seq2SeqTrainingArguments(\n    output_dir=f\"{model_name}-finetuned-sber-ai\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=5.6e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=num_train_epochs,\n    predict_with_generate=True,\n    logging_steps=logging_steps,\n    push_to_hub=False,\n    report_to=\"none\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:39:28.911465Z","iopub.execute_input":"2023-02-17T22:39:28.912161Z","iopub.status.idle":"2023-02-17T22:39:28.924956Z","shell.execute_reply.started":"2023-02-17T22:39:28.912123Z","shell.execute_reply":"2023-02-17T22:39:28.924039Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:39:28.939760Z","iopub.execute_input":"2023-02-17T22:39:28.940376Z","iopub.status.idle":"2023-02-17T22:39:28.949960Z","shell.execute_reply.started":"2023-02-17T22:39:28.940335Z","shell.execute_reply":"2023-02-17T22:39:28.949001Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = tokenized_datasets.remove_columns(\n    ds[\"train\"].column_names\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:39:28.951399Z","iopub.execute_input":"2023-02-17T22:39:28.951845Z","iopub.status.idle":"2023-02-17T22:39:28.964817Z","shell.execute_reply.started":"2023-02-17T22:39:28.951794Z","shell.execute_reply":"2023-02-17T22:39:28.963860Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"rouge_score = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    # Decode generated summaries into text\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    # Decode reference summaries into text\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    # ROUGE expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    # Compute ROUGE scores\n    result = rouge_score.compute(\n        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n    )\n    # Extract the median scores\n    # result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n    return {k: round(v * 100, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:39:28.966334Z","iopub.execute_input":"2023-02-17T22:39:28.966704Z","iopub.status.idle":"2023-02-17T22:39:29.389924Z","shell.execute_reply.started":"2023-02-17T22:39:28.966669Z","shell.execute_reply":"2023-02-17T22:39:29.389062Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cdef05baa26493eb3b16d0a670a0886"}},"metadata":{}}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:39:29.393409Z","iopub.execute_input":"2023-02-17T22:39:29.393728Z","iopub.status.idle":"2023-02-17T22:39:33.583889Z","shell.execute_reply.started":"2023-02-17T22:39:29.393702Z","shell.execute_reply":"2023-02-17T22:39:33.582863Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:39:33.585515Z","iopub.execute_input":"2023-02-17T22:39:33.585956Z","iopub.status.idle":"2023-02-17T22:39:52.465152Z","shell.execute_reply.started":"2023-02-17T22:39:33.585915Z","shell.execute_reply":"2023-02-17T22:39:52.464155Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 70\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 27\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27/27 00:16, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>7.658100</td>\n      <td>3.719550</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.144100</td>\n      <td>2.303535</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.186300</td>\n      <td>2.130424</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 30\n  Batch size = 8\n***** Running Evaluation *****\n  Num examples = 30\n  Batch size = 8\n***** Running Evaluation *****\n  Num examples = 30\n  Batch size = 8\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=27, training_loss=5.48429376107675, metrics={'train_runtime': 18.8287, 'train_samples_per_second': 11.153, 'train_steps_per_second': 1.434, 'total_flos': 85358769315840.0, 'train_loss': 5.48429376107675, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"def generate_title(model, text=None, verbose=True):\n    if text is None:\n        idx = np.random.randint(len(valid))\n        text = valid.iloc[idx][\"Instructions\"]\n        if verbose:\n            print(f\"GT: {text}\")\n    \n    inputs = tokenizer(text, return_tensors=\"pt\")\n    if torch.cuda.is_available():\n        inputs = {k: v.cuda() for k, v in inputs.items()}\n    \n    outputs = model.generate(\n                            **inputs, \n                            do_sample=False,\n                            max_length=max_target_length+15, \n                            repetition_penalty=5., \n                            temperature=0.5,\n                            num_beams=10,\n                        )\n    decoded = tokenizer.decode(outputs[0])\n    decoded = decoded.replace(\"<pad>\", \"\").replace(\"</s>\", \"\") \n    if verbose:\n        print(f\"Title: {decoded}\\n\")\n    return decoded","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:40:20.380397Z","iopub.execute_input":"2023-02-17T22:40:20.380827Z","iopub.status.idle":"2023-02-17T22:40:20.389351Z","shell.execute_reply.started":"2023-02-17T22:40:20.380780Z","shell.execute_reply":"2023-02-17T22:40:20.388166Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"for _ in range(5):\n    t = generate_title(model)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T22:40:21.135598Z","iopub.execute_input":"2023-02-17T22:40:21.135988Z","iopub.status.idle":"2023-02-17T22:40:22.997256Z","shell.execute_reply.started":"2023-02-17T22:40:21.135956Z","shell.execute_reply":"2023-02-17T22:40:22.996211Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"GT: 1. Вскипятите в кастрюле 1 литр слегка подсоленной воды, засыпать кускус и варить до готовности, около 10 минут. Если кускус готов, но не вся вода впиталась, то просто слейте ее.  2. Изюм промойте, залейте на несколько минут горячей водой. Затем слейте воду, добавьте изюм к кускусу и поставьте в теплое место.  3. Куриное филе нарежьте кубиками.  4. Стручки перца разрежьте на 4 части, удалите семена и разрежьте на квадратики.  5. Лук нарежьте тонкими кольцами.  6. Куриное филе обжарьте вместе с орехами в течение 2–3 минут, затем добавьте сладкий перец, лук и тушите еще 8 минут.  7. Смешайте все с кускусом, приправьте солью, тмином, карри и измельченным чесноком.\nTitle:  Куриное филе с кускусом и орехами\n\nGT: 1. Мелко нарезать лук, натереть на крупной тёрке морковь и нарезать небольшими кусочками весь чеснок.  2. Обжарить лук до полуготовности. Часть из него отложить на фарш.  3. В лук всыпать натертую морковь и чеснок — тушить на среднем огне минут 7, периодически помешивая. Нарезать кубиками помидоры и добавить в сковороду. Тушить ещё минуты 4 на медленном огне. Посолить, поперчить и тщательно перемешать.  4. Нарезать петрушку (корешки — в бульон, листья — на фарш).  5. В миске смешать фарш, яйцо, петрушку, лук. Посолить и поперчить. Сформировать из фарша тефтели.  6. В кипящую воду опустить тефтели и варить минут 7.  7. Затем опустить в бульон нарезанную кубиками картошку и варить её минут 10.  8. Добавить в суп тушеные овощи и варить до готовности.\nTitle:  Бульон с тефтелями и картофелем в бульоне\n\nGT: 1. Натрите лимонную цедру, отложите. Соедините в сотейнике гранатовый сок, сахар и цедру, поставьте на средний огонь и нагревайте, помешивая, до растворения сахара. Выжмите в сотейник сок целого лимона, перемешайте, снимите с огня, накройте крышкой и оставьте на 15–20 минут, после чего процедите.  2. Промойте чернику, загрузите в блендер и поочередно взбейте порциями, если за раз все ягоды не уместятся в комбайне. Добавьте в чернику немного лимонно-гранатового сиропа и взбейте до однородности. Добавьте оставшийся сироп и еще раз взбейте. Перелейте массу в кастрюлю, накройте крышкой и отправьте в холодильник до полного остывания или на ночь.  3. Перелейте получившийся мультифреш во фризер для мороженого и прокрутите в соответствии с инструкцией примерно 20–40 минут. Переложите получившуюся массу в контейнер и отправьте в морозильную камеру до застывания.  4. Если фризера нет, перелейте фреш в контейнер для мороженого и отправьте в морозилку. Доставайте и перемешивайте сорбет вилкой каждые 20 минут до окончательного застывания.\nTitle:  Фризер с фрешом для мороженого из черники и гранатового сиропа\n\nGT: 1. Яблоки натираем на терку. Смешиваем все в массу, лепим сырник. Не жарим!!  2. На противень кладем бумагу для выпечки, а на нее — сырники. Выпекаем при 180 градусах 45–50 минут.\nTitle:  Сырники из сырника с яблоками\n\nGT: 1. Застелите дно прямоугольной формы для кекса 24x10 см пищевой пленкой так, чтобы ее края с запасом свисали с бортиков формы.  2. Очистите спелые манго от кожуры, удалите твердые сердцевины, срежьте мякоть и взбейте ее в блендере в однородное пюре. Протрите пюре сквозь сито и оставьте.  3. Взбейте охлажденные сливки в пышный устойчивый крем и аккуратно смешайте его с манговым пюре. Оставьте.  4. Взбейте яичные желтки с половиной сахара в густой пастельно-желтый крем без ощутимых крупинок сахара. Аккуратно смешайте желтковый и сливочно-манговый крем в однородную массу. Оставьте.  5. Взбейте яичные белки комнатной температуры с щепоткой соли на небольшой скорости миксера до вспенивания, потом увеличьте скорость, и постепенно добавляя оставшийся сахар, взбивайте белки до состояния крепких глянцевых пиков. Аккуратно, по ложке за раз, вмешайте взбитые белки в манговый крем до однородности. Перелейте окончательный крем в форму поверх пищевой пленки, сверху выложите кубики засахаренного имбиря и накройте сверху пищевой пленкой. Защипните края верхнего и нижнего слоев пленки так, чтобы семифреддо не вылилось, и отправьте форму на ночь в морозильную камеру.  6. При подаче режьте семифреддо смоченным в теплой воде ножом на порции или формируйте традиционные шарики ложкой для мороженого. Или сформируйте мини-шарики ложкой для вырезания дыни и скрепите их между двух печений (например имбирных или шоколадных) на манер сэндвича. Или сделайте фруктовые шашлычки, произвольно поочередовав фрукты и шарики семифреддо на деревянных шпажках. В любом случае — угощайтесь и угощайте других!\nTitle:  С семифреддо из манго с дыней и шоколадом\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# [SEE RESULTS](https://www.kaggle.com/code/pankratozzi/hf-torch-text-summarization)","metadata":{}}]}