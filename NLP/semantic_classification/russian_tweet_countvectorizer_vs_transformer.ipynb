{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXKaGM0ntYBS",
        "outputId": "c6668677-4c95-453a-de94-66b119be34f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=16hd28VqzufDp8gpmIAC4UFAKAPbIrD4R\" -O negative.csv\n",
        "!wget -qq --no-check-certificate \"https://drive.google.com/uc?export=download&id=1NeluUImkZjwYTVZzK0RehtbWf3BKPike\" -O positive.csv"
      ],
      "metadata": {
        "id": "jiCfg1rktccR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1drd-UatLaT",
        "outputId": "153a39ce-dc61-4869-bd96-a4145dbd351e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import re\n",
        "from collections import Counter\n",
        "import string\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pymorphy2_analyzer = MorphAnalyzer()\n",
        "wp_tokenize = WordPunctTokenizer()\n",
        "punctuation = string.punctuation\n",
        "\n",
        "russian = stopwords.words(\"russian\")\n",
        "english = stopwords.words(\"english\")"
      ],
      "metadata": {
        "id": "5uwhPYjky7ha"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive = pd.read_csv(\"positive.csv\", sep=\";\", usecols=[3], header=None).rename(columns={3: \"text\"})\n",
        "negative = pd.read_csv(\"negative.csv\", sep=\";\", usecols=[3], header=None).rename(columns={3: \"text\"})\n",
        "positive[\"label\"] = 0\n",
        "negative[\"label\"] = 1\n",
        "df = pd.concat([positive, negative], axis=0).sample(frac=1)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yD0wims9ze6t",
        "outputId": "835c3d57-dd02-4325-8b14-6ab5f373751d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                               text  \\\n",
              "77898                                                               так привыкла за эти дни к @AnastasiaMurMur , что сейчас одной дома не по себе;(   \n",
              "3950   Если бы вы знали,как я устала.. постоянно жуткие головные боли и головокружения. Часто приходится спать сидя, так как таблетки не помогают((   \n",
              "76312                                                                                  В моей жизни появился такой классный человек, спасибо тебе:)   \n",
              "76933                                                           @ln_summer @964269 а сам ПУ нехай присоединяет к своему ТС КНДР и узбагаиваецца :-)   \n",
              "93625                                               \"@SmokyMo46: Аааааааа) http://t.co/FM1nyn9zlu \" эбать курица, овца явно иностранка с ЕС))))))))   \n",
              "\n",
              "       label  \n",
              "77898      1  \n",
              "3950       1  \n",
              "76312      0  \n",
              "76933      0  \n",
              "93625      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a7a8222-3f8b-44e9-9cc0-c31edc32f81a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77898</th>\n",
              "      <td>так привыкла за эти дни к @AnastasiaMurMur , что сейчас одной дома не по себе;(</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3950</th>\n",
              "      <td>Если бы вы знали,как я устала.. постоянно жуткие головные боли и головокружения. Часто приходится спать сидя, так как таблетки не помогают((</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76312</th>\n",
              "      <td>В моей жизни появился такой классный человек, спасибо тебе:)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76933</th>\n",
              "      <td>@ln_summer @964269 а сам ПУ нехай присоединяет к своему ТС КНДР и узбагаиваецца :-)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93625</th>\n",
              "      <td>\"@SmokyMo46: Аааааааа) http://t.co/FM1nyn9zlu \" эбать курица, овца явно иностранка с ЕС))))))))</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a7a8222-3f8b-44e9-9cc0-c31edc32f81a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a7a8222-3f8b-44e9-9cc0-c31edc32f81a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a7a8222-3f8b-44e9-9cc0-c31edc32f81a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "df[\"label\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANmJJCyq07LT",
        "outputId": "e039626c-1bd3-43b3-b817-389a35c579bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.506586\n",
              "1    0.493414\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoticon_dict = {\n",
        "                \":)\": \"счастье\",\n",
        "                \":))\": \"счастье\",\n",
        "                \":‑)\": \"счастье\",\n",
        "                \":-]\": \"счастье\",\n",
        "                \":-3\": \"счастье\",\n",
        "                \":->\": \"счастье\",\n",
        "                \"8-)\": \"счастье\",\n",
        "                \":-}\": \"счастье\",\n",
        "                \":o)\": \"счастье\",\n",
        "                \":c)\": \"счастье\",\n",
        "                \":^)\": \"счастье\",\n",
        "                \"=]\": \"счастье\",\n",
        "                \"=)\": \"счастье\",\n",
        "                \"<3\": \"счастье\",\n",
        "                \":D\": \"счастье\",\n",
        "                \":-D\": \"счастье\",\n",
        "                \"))\": \"счастье\",\n",
        "                \":-(\": \"плохо\",\n",
        "                \":(\": \"плохо\",\n",
        "                \":c\": \"плохо\",\n",
        "                \":<\": \"плохо\",\n",
        "                \":[\": \"плохо\",\n",
        "                \">:[\": \"плохо\",\n",
        "                \":{\": \"плохо\",\n",
        "                \">:(\": \"плохо\",\n",
        "                \":-c\": \"плохо\",\n",
        "                \":-< \": \"плохо\",\n",
        "                \":-[\": \"плохо\",\n",
        "                \"((\": \"плохо\",\n",
        "                \":((\": \"плохо\",\n",
        "                \":-||\": \"плохо\"\n",
        "        }\n",
        "\n",
        "emo_list = list(emoticon_dict.keys())"
      ],
      "metadata": {
        "id": "bq2JRRYR4tqK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text: str, \n",
        "               remove_punct: bool = False,\n",
        "               lemma: bool = True) -> list:\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "\n",
        "    text = re.sub(\"@[\\w]*\", ' ', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "    s = ''\n",
        "    for token in text.split():\n",
        "        if token in emo_list:\n",
        "            s += emoticon_dict[token] + \" \"\n",
        "        else:\n",
        "            s += token + \" \"\n",
        "    text = s.rstrip()\n",
        "\n",
        "    text = re.sub(\"\\s\\s+\", \" \", text)\n",
        "    if remove_punct:\n",
        "        text = re.sub(r\"[^a-zA-Zа-яА-Я0-9]\", \" \", text)\n",
        "        text = re.sub(r\"[^a-zA-Zа-яА-Я]\", \" \", text)\n",
        "        text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
        "    else:\n",
        "        text = re.sub(f\"[^a-zA-Zа-яА-Я{punctuation}]\", \" \", text)\n",
        "\n",
        "    text = text.lower().strip().replace(',', '')\n",
        "    text = [w for w in text.split() if len(w)>1]\n",
        "    text = ' '.join([w for w in text if w not in russian and w not in english])\n",
        "    \n",
        "    text = wp_tokenize.tokenize(text)\n",
        "    if lemma:\n",
        "        text = [pymorphy2_analyzer.parse(w)[0].normal_form for w in text]\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "LfQA3RvP1AK7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text_prep\"] = df[\"text\"].apply(preprocess)"
      ],
      "metadata": {
        "id": "LYmr8oGy1AIj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"text_prep\"].apply(len).hist()\n",
        "df[\"text_prep\"].apply(len).describe()  # 99.7 percentile = 24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "VrJ64KNg-eKd",
        "outputId": "6e67458f-28bf-4292-bbf6-079120fdaf31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    226834.000000\n",
              "mean          9.301763\n",
              "std           4.183685\n",
              "min           0.000000\n",
              "25%           6.000000\n",
              "50%           9.000000\n",
              "75%          12.000000\n",
              "max          72.000000\n",
              "Name: text_prep, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [token for tweet in df.text_prep for token in tweet if token not in punctuation]\n",
        "freq_dict = Counter(corpus)\n",
        "freq_dict_sorted = sorted(freq_dict.items(), key=lambda x: -x[1])"
      ],
      "metadata": {
        "id": "xJsYQC9t6yRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(freq_dict_sorted)\n",
        "\n",
        "high_freq_corpus = freq_dict_sorted[:vocab_size//3]\n",
        "middle_freq_corpus = freq_dict_sorted[vocab_size//3: 2*vocab_size//3]\n",
        "low_freq_corpus = freq_dict_sorted[2*vocab_size//3:]"
      ],
      "metadata": {
        "id": "iT6hdAm59f8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# too long and inefficient\n",
        "# df[\"high\"] = df[\"text_prep\"].apply(lambda x: [w for w in x if w in high_freq_corpus])"
      ],
      "metadata": {
        "id": "uYlRfjzyBxmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full corpus for not to miss out rare tokens (despite some data leakage)\n",
        "\n",
        "# max_df: \"ignore terms that appear in more than N documents\"\n",
        "# min_df: \"ignore terms that appear in less than N documents\"\n",
        "high_tf = CountVectorizer(lowercase=False, ngram_range=(1, 2), max_features=None, min_df=485).fit(df[\"text_prep\"].apply(' '.join))\n",
        "middle_tf = CountVectorizer(lowercase=False, ngram_range=(1, 2), max_features=500, min_df=220, max_df=485).fit(df[\"text_prep\"].apply(' '.join))\n",
        "low_tf = CountVectorizer(lowercase=False, ngram_range=(1, 2), max_features=500, max_df=100).fit(df[\"text_prep\"].apply(' '.join))"
      ],
      "metadata": {
        "id": "FjrwwaVmAk7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs_names = [\"high\", \"middle\", \"low\"]\n",
        "\n",
        "for vect, tst in zip((high_tf, middle_tf, low_tf), freqs_names):\n",
        "    print(f\"Experiment {tst}: {len(low_tf.get_feature_names())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb7Y-pJ7MYw6",
        "outputId": "7e530bf1-969a-44dc-8cfa-002dc2efc3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment high: 500\n",
            "Experiment middle: 500\n",
            "Experiment low: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df[\"text_prep\"], df[\"label\"], shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "btIqEJJNKPor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vect, tst in zip((high_tf, middle_tf, low_tf), freqs_names):\n",
        "    train_x = vect.transform(x_train.apply(' '.join))\n",
        "    test_x = vect.transform(x_test.apply(' '.join))\n",
        "    lr = LogisticRegression(random_state=42).fit(train_x, y_train)\n",
        "    y_train_pred = lr.predict(train_x)\n",
        "    y_test_pred = lr.predict(test_x)\n",
        "    print(f\"Experiment {tst}: \")\n",
        "    print(classification_report(y_train, y_train_pred))\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "    print(\"=\"*30)\n",
        "\n",
        "# low-frequency tokens (terms) are less able to display tweet sentiment (feeling expression relies on more common words or symbols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQNrh0CD3YVb",
        "outputId": "74880135-4686-4ce2-ba3e-25c2fa6da4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment high: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.74      0.74     86048\n",
            "           1       0.73      0.71      0.72     84077\n",
            "\n",
            "    accuracy                           0.73    170125\n",
            "   macro avg       0.73      0.73      0.73    170125\n",
            "weighted avg       0.73      0.73      0.73    170125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.74      0.73     28863\n",
            "           1       0.72      0.72      0.72     27846\n",
            "\n",
            "    accuracy                           0.73     56709\n",
            "   macro avg       0.73      0.73      0.73     56709\n",
            "weighted avg       0.73      0.73      0.73     56709\n",
            "\n",
            "==============================\n",
            "Experiment middle: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.84      0.67     86048\n",
            "           1       0.65      0.30      0.41     84077\n",
            "\n",
            "    accuracy                           0.57    170125\n",
            "   macro avg       0.60      0.57      0.54    170125\n",
            "weighted avg       0.60      0.57      0.54    170125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.84      0.67     28863\n",
            "           1       0.64      0.29      0.40     27846\n",
            "\n",
            "    accuracy                           0.57     56709\n",
            "   macro avg       0.60      0.57      0.53     56709\n",
            "weighted avg       0.60      0.57      0.54     56709\n",
            "\n",
            "==============================\n",
            "Experiment low: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.95      0.67     86048\n",
            "           1       0.65      0.10      0.18     84077\n",
            "\n",
            "    accuracy                           0.53    170125\n",
            "   macro avg       0.59      0.52      0.42    170125\n",
            "weighted avg       0.58      0.53      0.43    170125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.94      0.67     28863\n",
            "           1       0.63      0.10      0.17     27846\n",
            "\n",
            "    accuracy                           0.53     56709\n",
            "   macro avg       0.58      0.52      0.42     56709\n",
            "weighted avg       0.58      0.53      0.43     56709\n",
            "\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = make_pipeline(CountVectorizer(ngram_range=(1,2), max_features=800), LogisticRegression(random_state=42)).fit(x_train.apply(' '.join), y_train)\n",
        "y_train_pred = pipe.predict(x_train.apply(' '.join))\n",
        "y_test_pred = pipe.predict(x_test.apply(' '.join))\n",
        "\n",
        "print(classification_report(y_train, y_train_pred))\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "# overfitted model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGsZXdB_zsKm",
        "outputId": "7f6219d2-f682-48fc-e33f-8119845fec52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     86048\n",
            "           1       0.98      0.98      0.98     84077\n",
            "\n",
            "    accuracy                           0.98    170125\n",
            "   macro avg       0.98      0.98      0.98    170125\n",
            "weighted avg       0.98      0.98      0.98    170125\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.79      0.79     28863\n",
            "           1       0.79      0.79      0.79     27846\n",
            "\n",
            "    accuracy                           0.79     56709\n",
            "   macro avg       0.79      0.79      0.79     56709\n",
            "weighted avg       0.79      0.79      0.79     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance = pd.DataFrame({\"importance\": np.abs(pipe[-1].coef_.flatten()), \"feature\": pipe[0].get_feature_names_out()})\n",
        "\n",
        "importance = importance.sort_values(by=\"importance\", ascending=False)\n",
        "importance = importance.head(n=12)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "sns.barplot(x=importance[\"feature\"], y=importance[\"importance\"], palette=\"viridis\")\n",
        "plt.title(\"Top LR Importance Features\", size=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Qi00UmnHzsIM",
        "outputId": "ada4694b-69de-4737-deeb-87507963ed41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "avxDE23dS9xA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe2 = make_pipeline(TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize),\n",
        "                      LogisticRegression(random_state=42))\n",
        "\n",
        "pipe2.fit(x_train, y_train)\n",
        "pred = pipe2.predict(x_test)\n",
        "print(classification_report(pred, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeHPh8zBSc5_",
        "outputId": "4aef19d8-649d-41b0-dd65-3d5121d59a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28905\n",
            "           1       1.00      1.00      1.00     27804\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_based = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, max_features=1500)\n",
        "naive = GaussianNB()\n",
        "\n",
        "x_train_transformed = count_based.fit_transform(x_train)\n",
        "x_test_transformed = count_based.transform(x_test)\n",
        "naive.fit(x_train_transformed.toarray(), y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lYvTeX10eyEj",
        "outputId": "9437a749-4021-4056-d15c-d1dfcad8c071"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = naive.predict(x_test_transformed.toarray())\n",
        "print(classification_report(y_test, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJY_8NqjjIKr",
        "outputId": "ba580ca9-904a-4ad0-febc-f26b074e83b8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     28725\n",
            "           1       0.99      0.98      0.99     27984\n",
            "\n",
            "    accuracy                           0.99     56709\n",
            "   macro avg       0.99      0.99      0.99     56709\n",
            "weighted avg       0.99      0.99      0.99     56709\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "importance = pd.DataFrame({\"importance\": np.abs(pipe2[1].coef_.flatten()), \"feature\": pipe2[0].get_feature_names_out()})\n",
        "\n",
        "importance = importance.sort_values(by=\"importance\", ascending=False)\n",
        "importance = importance.head(n=12)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "sns.barplot(x=importance[\"feature\"], y=importance[\"importance\"], palette=\"viridis\")\n",
        "plt.title(\"Top LR Importance Features\", size=14)\n",
        "plt.show()\n",
        "# this is TRUE amazing: brackets are the most powerful features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "MoImw-EnTb9L",
        "outputId": "353267f4-3a07-41d5-b11f-50966d8ddf1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)  # analyzer=\"char\" for language recognition, also good for small emoji\n",
        "cnt = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
        "hash = HashingVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
        "\n",
        "for vect in ((tfidf, cnt, hash)):\n",
        "    pipe3 = make_pipeline(vect,\n",
        "                          LogisticRegression(random_state=42))\n",
        "\n",
        "    pipe3.fit(x_train, y_train)\n",
        "    pred = pipe3.predict(x_test)\n",
        "    print(classification_report(pred, y_test))\n",
        "    print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ0n7009Vd96",
        "outputId": "57ce8372-1d52-492a-93df-9231bae4cca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28905\n",
            "           1       1.00      1.00      1.00     27804\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28851\n",
            "           1       1.00      1.00      1.00     27858\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     28854\n",
            "           1       1.00      1.00      1.00     27855\n",
            "\n",
            "    accuracy                           1.00     56709\n",
            "   macro avg       1.00      1.00      1.00     56709\n",
            "weighted avg       1.00      1.00      1.00     56709\n",
            "\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hashing vectorizer n_features: The number of features (columns) in the output matrices. \n",
        "# Small numbers of features are likely to cause hash collisions, but large numbers will cause larger coefficient dimensions in linear learners."
      ],
      "metadata": {
        "id": "gZHFXZszWUav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n in (2**5, 2**8, 2**9):\n",
        "\n",
        "    pipe3 = make_pipeline(HashingVectorizer(n_features=n, tokenizer=word_tokenize),\n",
        "                          LogisticRegression(random_state=42))\n",
        "\n",
        "    pipe3.fit(x_train, y_train)\n",
        "    pred = pipe3.predict(x_test)\n",
        "    print(classification_report(pred, y_test))\n",
        "    print(\"=\"*30)\n",
        "\n",
        "# 2**10 is pretty suitable: as 2**11 gives 100% accuracy "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9sIz1xpXDh-",
        "outputId": "92df89fc-79f7-42c2-d2fe-2e97c3d01567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.90      0.91     29383\n",
            "           1       0.90      0.91      0.90     27326\n",
            "\n",
            "    accuracy                           0.91     56709\n",
            "   macro avg       0.91      0.91      0.91     56709\n",
            "weighted avg       0.91      0.91      0.91     56709\n",
            "\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98     29188\n",
            "           1       0.97      0.99      0.98     27521\n",
            "\n",
            "    accuracy                           0.98     56709\n",
            "   macro avg       0.98      0.98      0.98     56709\n",
            "weighted avg       0.98      0.98      0.98     56709\n",
            "\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     29086\n",
            "           1       0.98      0.99      0.99     27623\n",
            "\n",
            "    accuracy                           0.99     56709\n",
            "   macro avg       0.99      0.99      0.99     56709\n",
            "weighted avg       0.99      0.99      0.99     56709\n",
            "\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = CountVectorizer(ngram_range=(1, 1), max_features=2048, tokenizer=word_tokenize)\n",
        "\n",
        "train_x = cnt.fit_transform(x_train)\n",
        "test_x = cnt.transform(x_test)\n",
        "\n",
        "train_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1nf5jR0y4wN",
        "outputId": "5ef6f9ed-1fcf-4fde-a424-7264d1e962e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(170125, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x.toarray().astype(np.float32)\n",
        "test_x = test_x.toarray().astype(np.float32)"
      ],
      "metadata": {
        "id": "URpU0vUA18sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we won't make validation ds, just observing common stats\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_x, y_train)).cache().shuffle(buffer_size=len(train_x)).prefetch(buffer_size=tf.data.AUTOTUNE).batch(128)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_x, y_test)).prefetch(buffer_size=tf.data.AUTOTUNE).batch(128)"
      ],
      "metadata": {
        "id": "xrp2O25B0UHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple model: just like two sequntial linear regressions + activation\n",
        "dense_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "dense_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "             tf.keras.callbacks.ReduceLROnPlateau(patience=2),\n",
        "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "            ]"
      ],
      "metadata": {
        "id": "xGdf-d0qwgEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = dense_model.fit(train_ds, epochs=10, validation_data=test_ds, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGxFgwku23vZ",
        "outputId": "b216567e-13e7-4c0a-fc4f-14888706e9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 30s 22ms/step - loss: 0.0266 - accuracy: 0.9935 - val_loss: 0.0078 - val_accuracy: 0.9973 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 30s 23ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0073 - val_accuracy: 0.9979 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 30s 22ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0070 - val_accuracy: 0.9978 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9975 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0072 - val_accuracy: 0.9980 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 29s 22ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9980 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 31s 23ms/step - loss: 8.0370e-04 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9982 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "1330/1330 [==============================] - 30s 22ms/step - loss: 7.1070e-04 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9981 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "1330/1330 [==============================] - 30s 22ms/step - loss: 6.3331e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9980 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "1330/1330 [==============================] - 30s 22ms/step - loss: 5.4965e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9981 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM\n",
        "\n",
        "max_features = 4000\n",
        "sequence_length = 64\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    text = vectorize_layer(text)\n",
        "    return text, label\n",
        "\n",
        "vectorize_layer.adapt(x_train.values)"
      ],
      "metadata": {
        "id": "TMWYETDN0WAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def squeeze(x,z):\n",
        "    \"\"\" dimensions issues after applying batch at the end: input is 1d array \"\"\"\n",
        "    return tf.squeeze(x, axis=1), z"
      ],
      "metadata": {
        "id": "Yu7fRT4U0V9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train.values, y_train)) \\\n",
        "                          .map(vectorize_text) \\\n",
        "                          .cache() \\\n",
        "                          .shuffle(len(x_train)) \\\n",
        "                          .prefetch(buffer_size=tf.data.AUTOTUNE) \\\n",
        "                          .batch(128) \\\n",
        "                          .map(squeeze)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test.values, y_test)) \\\n",
        "                          .map(vectorize_text) \\\n",
        "                          .cache() \\\n",
        "                          .batch(128) \\\n",
        "                          .prefetch(buffer_size=tf.data.AUTOTUNE) \\\n",
        "                          .map(squeeze)"
      ],
      "metadata": {
        "id": "k1zhluYr0V6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(max_features+1, 128, mask_zero=True),\n",
        "    tf.keras.layers.LSTM(64, return_sequences=False),  # obtain last hidden state [B, 128], otherwise all hidden states: [B, seq_len, 128]\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "lstm_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "             tf.keras.callbacks.ReduceLROnPlateau(patience=2),\n",
        "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "            ]"
      ],
      "metadata": {
        "id": "V8pS0vtP5l5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = lstm_model.fit(train_ds, epochs=10, validation_data=test_ds, callbacks=callbacks)\n",
        "# strong overfitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NZNCq6P5l25",
        "outputId": "2d013aad-078f-4a9f-9cf7-2dbd61d1cb73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1330/1330 [==============================] - 23s 12ms/step - loss: 0.4015 - accuracy: 0.7826 - val_loss: 0.3676 - val_accuracy: 0.8036 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "1330/1330 [==============================] - 16s 12ms/step - loss: 0.3583 - accuracy: 0.8111 - val_loss: 0.3628 - val_accuracy: 0.8057 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "1330/1330 [==============================] - 15s 11ms/step - loss: 0.3440 - accuracy: 0.8202 - val_loss: 0.3650 - val_accuracy: 0.8062 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "1330/1330 [==============================] - 16s 12ms/step - loss: 0.3313 - accuracy: 0.8282 - val_loss: 0.3650 - val_accuracy: 0.8069 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "1330/1330 [==============================] - 16s 12ms/step - loss: 0.3033 - accuracy: 0.8468 - val_loss: 0.3864 - val_accuracy: 0.8051 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "1330/1330 [==============================] - 17s 13ms/step - loss: 0.2981 - accuracy: 0.8494 - val_loss: 0.3889 - val_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "1330/1330 [==============================] - 18s 13ms/step - loss: 0.2931 - accuracy: 0.8528 - val_loss: 0.3943 - val_accuracy: 0.8042 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer"
      ],
      "metadata": {
        "id": "fEanRx5HzsF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 4000\n",
        "sequence_length = 256\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    text = vectorize_layer(text)\n",
        "    mask = tf.cast(tf.not_equal(text, 0), dtype=tf.bool)\n",
        "    mask = tf.expand_dims(mask, axis=-2)\n",
        "    return (text, mask), label\n",
        "\n",
        "vectorize_layer.adapt(x_train.values)"
      ],
      "metadata": {
        "id": "W0l-SwQERzrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def squeeze(x,z):\n",
        "    \"\"\" dimensions issues after applying batch at the end: input is 1d array \"\"\"\n",
        "    return (tf.squeeze(x[0], axis=1), tf.squeeze(x[1], axis=1)), z"
      ],
      "metadata": {
        "id": "ezlIa4ysRzon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train.values, y_train)) \\\n",
        "                          .map(vectorize_text) \\\n",
        "                          .cache() \\\n",
        "                          .shuffle(len(x_train)) \\\n",
        "                          .prefetch(buffer_size=tf.data.AUTOTUNE) \\\n",
        "                          .batch(128) \\\n",
        "                          .map(squeeze)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test.values, y_test)) \\\n",
        "                          .map(vectorize_text) \\\n",
        "                          .cache() \\\n",
        "                          .batch(128) \\\n",
        "                          .prefetch(buffer_size=tf.data.AUTOTUNE) \\\n",
        "                          .map(squeeze)"
      ],
      "metadata": {
        "id": "HQjh5WeJ9YBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, mask, head_size, num_heads, ff_dim, dropout=0.1, ff_type=\"cnn\"):\n",
        "    # Attention and Normalization\n",
        "    x = tf.keras.layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "        )(inputs, inputs, attention_mask=mask)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    x = tf.keras.layers.Add()([x, inputs])\n",
        "    res = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    if ff_type == \"cnn\":\n",
        "        # Convolutional Feed Forward Part\n",
        "        x = tf.keras.layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)  # each word window; activation: gelu\n",
        "        x = tf.keras.layers.Dropout(dropout)(x)\n",
        "        x = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "\n",
        "    elif ff_type == \"dense\":\n",
        "        # Dense FFN\n",
        "        x = tf.keras.layers.Dense(units=ff_dim, activation=\"relu\")(res)  # gelu\n",
        "        x = tf.keras.layers.Dropout(dropout)(x)\n",
        "        x = tf.keras.layers.Dense(units=inputs.shape[-1])(x)\n",
        "    else:\n",
        "        raise NotImplementedError(\"Set ff_type to 'cnn' or 'dense'\")\n",
        "\n",
        "    x = tf.keras.layers.Add()([x, res])\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "XzVhLyC29aC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SeqEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super(SeqEmbedding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
        "        self.pos_encoding = self.positional_encoding(length=1024, depth=d_model)\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def positional_encoding(self, length, depth):\n",
        "        depth = depth / 2\n",
        "\n",
        "        positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "        depths = np.arange(depth)[np.newaxis, :] / depth   # (1, depth)\n",
        "\n",
        "        angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "        angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "        pos_encoding = np.concatenate(\n",
        "            [np.sin(angle_rads), np.cos(angle_rads)], axis=-1\n",
        "            ) \n",
        "\n",
        "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "        return x"
      ],
      "metadata": {
        "id": "IPzcpOCh9aAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeanPooling(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(MeanPooling, self).__init__()\n",
        "        \n",
        "    def call(self, inputs, masks):\n",
        "        masks = tf.squeeze(masks, axis=1)\n",
        "        expanded_masks = tf.broadcast_to(masks[..., None], shape=tf.shape(inputs))\n",
        "        expanded_masks = tf.cast(expanded_masks, dtype=tf.float32)\n",
        "        sum_embeddings = tf.reduce_sum(inputs * expanded_masks, axis=1)\n",
        "        sum_masks = tf.reduce_sum(expanded_masks, axis=1)\n",
        "        sum_masks = tf.clip_by_value(sum_masks, clip_value_min=1e-9, clip_value_max=tf.reduce_max(sum_masks))\n",
        "        mean_embeddings = sum_embeddings / sum_masks\n",
        "        return mean_embeddings"
      ],
      "metadata": {
        "id": "4_FK4Sc5eO78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "                input_shape,\n",
        "                num_heads=4,\n",
        "                num_transformer_blocks=4,\n",
        "                mlp_units=[128,],\n",
        "                n_classes=1,\n",
        "                emb_dim=256,\n",
        "                dropout=0.1,\n",
        "                mlp_dropout=0.1,\n",
        "                ff_type=\"dense\",\n",
        "):\n",
        "    head_size = emb_dim // num_heads\n",
        "    ff_dim = emb_dim * 4\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape, name=\"input\")  # [128, 64] if len_seq = 128\n",
        "    mask = tf.keras.Input(shape=(1, sequence_length), name=\"mask\")  # [128, 1, 64] of type bool\n",
        "\n",
        "    x = inputs\n",
        "    x = SeqEmbedding(max_features+1, emb_dim)(x)  # [B, seq_len, emb_dim] = [128, 64, 256]\n",
        "\n",
        "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, mask, head_size, num_heads, ff_dim, dropout)  # [128, 64, 256]\n",
        "\n",
        "    # x = tf.keras.layers.GlobalAveragePooling1D()(x)  # [128, 256]\n",
        "    x = MeanPooling()(x, mask)  # [128, 256] w.r.t mask\n",
        "\n",
        "    for dim in mlp_units:\n",
        "        x = tf.keras.layers.Dense(dim, activation=\"relu\")(x)  # [128, 128]\n",
        "        x = tf.keras.layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = tf.keras.layers.Dense(n_classes)(x)  # [128, 1]\n",
        "    return tf.keras.Model([inputs, mask], outputs, name=\"Transformer\")"
      ],
      "metadata": {
        "id": "zkGPDXI29Z-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(input_shape=(sequence_length,), mlp_dropout=0.2, num_transformer_blocks=2, ff_type=\"cnn\")"
      ],
      "metadata": {
        "id": "uCNuItD19e8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq tensorflow_addons\n",
        "from tensorflow_addons.optimizers import AdamW"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtxbUDJE9e6S",
        "outputId": "0759ae50-9a45-4334-a872-80a25a5716bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=AdamW(learning_rate=0.0001, weight_decay=0.0001),\n",
        "              metrics=tf.metrics.BinaryAccuracy(threshold=0.5))\n",
        "\n",
        "callbacks = [\n",
        "             tf.keras.callbacks.ReduceLROnPlateau(patience=2),\n",
        "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "            ]\n",
        "\n",
        "epochs = 40\n",
        "history = model.fit(train_ds, validation_data=test_ds, epochs=epochs, callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF1awPO89e4H",
        "outputId": "c24b6c08-62d9-4531-d2e1-c1f183f25fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "1330/1330 [==============================] - 351s 258ms/step - loss: 0.4064 - binary_accuracy: 0.7658 - val_loss: 0.3632 - val_binary_accuracy: 0.7889 - lr: 1.0000e-04\n",
            "Epoch 2/40\n",
            "1330/1330 [==============================] - 350s 263ms/step - loss: 0.3552 - binary_accuracy: 0.8006 - val_loss: 0.3589 - val_binary_accuracy: 0.7915 - lr: 1.0000e-04\n",
            "Epoch 3/40\n",
            "1330/1330 [==============================] - 343s 258ms/step - loss: 0.3455 - binary_accuracy: 0.8084 - val_loss: 0.3565 - val_binary_accuracy: 0.7952 - lr: 1.0000e-04\n",
            "Epoch 4/40\n",
            "1330/1330 [==============================] - 343s 257ms/step - loss: 0.3390 - binary_accuracy: 0.8136 - val_loss: 0.3571 - val_binary_accuracy: 0.7969 - lr: 1.0000e-04\n",
            "Epoch 5/40\n",
            "1330/1330 [==============================] - 342s 257ms/step - loss: 0.3314 - binary_accuracy: 0.8187 - val_loss: 0.3668 - val_binary_accuracy: 0.8099 - lr: 1.0000e-04\n",
            "Epoch 6/40\n",
            "1330/1330 [==============================] - 349s 262ms/step - loss: 0.3124 - binary_accuracy: 0.8329 - val_loss: 0.3669 - val_binary_accuracy: 0.8079 - lr: 1.0000e-05\n",
            "Epoch 7/40\n",
            "1330/1330 [==============================] - 343s 258ms/step - loss: 0.3153 - binary_accuracy: 0.8321 - val_loss: 0.3652 - val_binary_accuracy: 0.8051 - lr: 1.0000e-05\n",
            "Epoch 8/40\n",
            "1330/1330 [==============================] - 343s 257ms/step - loss: 0.3303 - binary_accuracy: 0.8267 - val_loss: 0.3749 - val_binary_accuracy: 0.8029 - lr: 1.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# deep models seem to be too complex for given task"
      ],
      "metadata": {
        "id": "4dD1YkXP9lH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GgdfVG529lF3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}