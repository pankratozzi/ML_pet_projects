{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a0e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, re\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086cc800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using \"CUDA\" device.\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Currently using \"{device.upper()}\" device.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c15983",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "token_transform = get_tokenizer(\"spacy\", language=\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed72ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20658</th>\n",
       "      <td>5</td>\n",
       "      <td>Сбербанк бомбовая компания на сегодняшний день. Лидер банков.!! Держитесь в том же духе.</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20634</th>\n",
       "      <td>5</td>\n",
       "      <td>Недавно пользуюсь, но то, что я использовал, работает отлично.</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20633</th>\n",
       "      <td>5</td>\n",
       "      <td>все отлично!</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20632</th>\n",
       "      <td>2</td>\n",
       "      <td>Уважаемые разработчики, после последнего обновления я не могу зайти в приложение, зеленая полоска зависает на инициализации антивируса. У меня хонор 8 или вы теперь все сделали только для самсунгов? Когда вы обратите внимание на мои отзывы, я уже пишу вам ТРЕТИЙ раз!</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20631</th>\n",
       "      <td>2</td>\n",
       "      <td>Что вообще случилось после последнего обновления? Инициализация интивируса очень очень оооочень долгая и с момента обновления ни разу я не дождалась окончания этой инициализации и соответственно ни разу не зашла в приложение! Было плохо,стало еще хуже!</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating  \\\n",
       "20658       5   \n",
       "20634       5   \n",
       "20633       5   \n",
       "20632       2   \n",
       "20631       2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                           Content  \\\n",
       "20658                                                                                                                                                                                     Сбербанк бомбовая компания на сегодняшний день. Лидер банков.!! Держитесь в том же духе.   \n",
       "20634                                                                                                                                                                                                               Недавно пользуюсь, но то, что я использовал, работает отлично.   \n",
       "20633                                                                                                                                                                                                                                                                 все отлично!   \n",
       "20632  Уважаемые разработчики, после последнего обновления я не могу зайти в приложение, зеленая полоска зависает на инициализации антивируса. У меня хонор 8 или вы теперь все сделали только для самсунгов? Когда вы обратите внимание на мои отзывы, я уже пишу вам ТРЕТИЙ раз!   \n",
       "20631                 Что вообще случилось после последнего обновления? Инициализация интивируса очень очень оооочень долгая и с момента обновления ни разу я не дождалась окончания этой инициализации и соответственно ни разу не зашла в приложение! Было плохо,стало еще хуже!   \n",
       "\n",
       "            Date  \n",
       "20658 2017-06-01  \n",
       "20634 2017-06-01  \n",
       "20633 2017-06-01  \n",
       "20632 2017-06-01  \n",
       "20631 2017-06-01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"feedbacks_summer.xls\", parse_dates=[\"Date\"]).sort_values(\"Date\")\n",
    "data.head()\n",
    "\n",
    "# we will solve classification task as ratings are provided as descrete values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3fa0d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    14586\n",
       "1     2276\n",
       "4     2138\n",
       "3      911\n",
       "2      748\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7163512",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"month\"] = data[\"Date\"].dt.month\n",
    "data[\"day\"] = data[\"Date\"].dt.day\n",
    "\n",
    "data.drop(\"Date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e15adc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, tokenized=False):\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", ' ', str(text))\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "\n",
    "    text = re.sub(\"\\W+\", ' ', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    if tokenized:\n",
    "        tokens = list(tokenize(text))\n",
    "        words = [_.text for _ in tokens]\n",
    "        words = [w for w in words if w not in stopword_ru]\n",
    "        return \" \".join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "        tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-':\n",
    "            w = w[1:]\n",
    "        if len(w)>1:\n",
    "            if w in cache:\n",
    "                words_lem.append(cache[w])\n",
    "            else:\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3c4220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and split\n",
    "\n",
    "data[\"Content\"] = data[\"Content\"].apply(lambda x: clean_text(x, tokenized=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "88a47387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"Content\"].str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5f28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~(data[\"Content\"].str.len() == 0)]\n",
    "data[\"Rating\"] = data[\"Rating\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d25b08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform(data_sample[0])  # [1] - label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "951c0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX, UNK_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a236e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split by date? not so huge period -> just shuffle\n",
    "\n",
    "train, valid = train_test_split(data, test_size=0.1, shuffle=True, stratify=data[\"Rating\"], random_state=42)\n",
    "valid, test = train_test_split(valid, test_size=500, shuffle=True, random_state=42)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1f66fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = train[\"Rating\"].value_counts().to_list()\n",
    "num_samples = sum(class_counts)\n",
    "labels = train[\"Rating\"].values - 1\n",
    "\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb53281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, max_len=64):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        row = self.data.iloc[ix].squeeze()\n",
    "        text = row[\"Content\"]\n",
    "        label = row[\"Rating\"]\n",
    "        \n",
    "        return text, label\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        texts, labels = list(zip(*batch))\n",
    "        \n",
    "        text_batch = torch.zeros((len(texts), self.max_len)).fill_(PAD_IDX).long()\n",
    "        \n",
    "        # constant max_length\n",
    "        for i in range(len(texts)):\n",
    "            sample = text_transform(texts[i])[:self.max_len]\n",
    "            text_batch[i, :len(sample)] = sample\n",
    "\n",
    "        # text_batch = pad_sequence(text_batch, padding_value=PAD_IDX, batch_first=True).to(device) # pads only to current max\n",
    "        \n",
    "        labels = torch.cat([torch.tensor(label).unsqueeze(0) for label in labels]).to(device)\n",
    "        return text_batch.to(device), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7615c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = TextDataset(data)\n",
    "\n",
    "vocabulary = build_vocab_from_iterator(yield_tokens(data_iter),  # define Dataset\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "vocabulary.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69efe1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def tensor_transform(token_ids, drop_specials=True):\n",
    "    if drop_specials:\n",
    "        return torch.tensor(token_ids)\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "text_transform = sequential_transforms(token_transform,\n",
    "                                       vocabulary,\n",
    "                                       tensor_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ef37ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextDataset(train)\n",
    "valid_ds = TextDataset(valid)\n",
    "test_ds = TextDataset(test)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=train_ds.collate_fn)\n",
    "# train_dataloader = DataLoader(train_ds, batch_size=128, shuffle=False, sampler=sampler, collate_fn=train_ds.collate_fn)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=128, collate_fn=valid_ds.collate_fn)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=64, collate_fn=test_ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5865fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0, path='model.pth'):\n",
    "        self.path = path\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model=None):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            if model is not None:\n",
    "                checkpoint = {\n",
    "                    'model': model,\n",
    "                }\n",
    "                torch.save(checkpoint, self.path)\n",
    "                print(f'Model saved to: {self.path}')\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True\n",
    "                \n",
    "def calc_accuracy(y_pred, y_true):\n",
    "    return (y_true == torch.max(y_pred, 1)[1]).float().mean()\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\" \n",
    "    https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/focal_loss.py\n",
    "    \n",
    "    Shape:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, \n",
    "                 alpha: torch.Tensor = None, \n",
    "                 gamma: float = 2.0, \n",
    "                 reduction: str = 'mean',\n",
    "                 ignore_index: int = -100,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha (Tensor, optional): Weights for each class. Defaults to None.\n",
    "            gamma (float, optional): A constant, as described in the paper.\n",
    "                Defaults to 2.0\n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'.\n",
    "                Defaults to 'mean'.\n",
    "            ignore_index (int, optional): class label to ignore.\n",
    "                Defaults to -100.\n",
    "        \"\"\"\n",
    "        if reduction not in ('mean', 'sum', 'none'):\n",
    "            raise ValueError(\n",
    "                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super(FocalLoss, self).__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(\n",
    "            weight=alpha, reduction='none', ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim > 2:\n",
    "            c = x.shape[1]  # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            y = y.view(-1)  # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n",
    "        \n",
    "        y = y.long()\n",
    "        unignored_mask = y != self.ignore_index\n",
    "        y = y[unignored_mask]\n",
    "        if len(y) == 0:\n",
    "            return torch.tensor(0.)\n",
    "        x = x[unignored_mask]\n",
    "\n",
    "        # compute weighted cross entropy term: -alpha * log(pt) (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # get true class column from each row\n",
    "        all_rows = torch.arange(len(x))\n",
    "        log_pt = log_p[all_rows, y]\n",
    "\n",
    "        # compute focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt)**self.gamma\n",
    "\n",
    "        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f77a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(data, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    texts, labels = data\n",
    "    optimizer.zero_grad()\n",
    "    output = model(texts)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    accuracy = calc_accuracy(output, labels)\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "    texts, labels = data\n",
    "    \n",
    "    out = model(texts)\n",
    "    loss = criterion(out, labels)\n",
    "    \n",
    "    accuracy = calc_accuracy(out, labels)\n",
    "    \n",
    "    return loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a54e7292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, epochs=40, print_freq=50):\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        train_loss, train_accs = [], []\n",
    "        for step, batch in enumerate(train_dataloader, 1):\n",
    "            time_1 = time.time()\n",
    "\n",
    "            loss, accuracy = train_one_batch(batch, model, criterion, optimizer)\n",
    "\n",
    "            train_loss.append(loss)\n",
    "            train_accs.append(accuracy)\n",
    "\n",
    "            if step % print_freq == 0:\n",
    "                print('epoch:', epoch, \n",
    "                      '\\tstep:', step, '/', len(train_dataloader),\n",
    "                      '\\ttrain loss:', '{:.4f}'.format(loss),\n",
    "                      '\\ttrain accuracy:','{:.4f}'.format(accuracy),\n",
    "                      '\\ttime:', '{:.4f}'.format((time.time()-time_1)*print_freq), 's')\n",
    "\n",
    "        valid_loss, valid_accs = [], []\n",
    "        for step, batch in enumerate(tqdm(valid_dataloader)):\n",
    "            loss, accuracy = validate_one_batch(batch, model, criterion)\n",
    "\n",
    "            valid_loss.append(loss)\n",
    "            valid_accs.append(accuracy)\n",
    "\n",
    "        print('epoch:', epoch, '/', epochs,\n",
    "              '\\ttrain loss:', '{:.4f}'.format(np.mean(train_loss)),\n",
    "              '\\tvalid loss:', '{:.4f}'.format(np.mean(valid_loss)),\n",
    "              '\\ttrain accuracy', '{:.4f}'.format(np.mean(train_accs)),\n",
    "              '\\tvalid accuracy', '{:.4f}'.format(np.mean(valid_accs)))\n",
    "\n",
    "        stopper(np.mean(valid_loss), model)\n",
    "        if stopper.early_stop:\n",
    "            checkpoint = torch.load(\"model.pth\", map_location=device)\n",
    "            model = checkpoint['model']\n",
    "            break\n",
    "        scheduler.step(np.mean(valid_loss))\n",
    "\n",
    "    test_loss, test_accs = [], []\n",
    "    for step, batch in enumerate(tqdm(test_dataloader)):\n",
    "        loss, accuracy = validate_one_batch(batch, model, criterion)\n",
    "\n",
    "        test_loss.append(loss)\n",
    "        test_accs.append(accuracy)\n",
    "\n",
    "    print('\\ttest loss:', '{:.4f}'.format(np.mean(test_loss)),\n",
    "          '\\ttest accuracy', '{:.4f}'.format(np.mean(test_accs)),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359c13f",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "* CNN\n",
    "* LSTM \n",
    "* LSTM-CNN\n",
    "* Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9443a4d4",
   "metadata": {},
   "source": [
    "**CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0553912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=5, dropout=0.1, **kwargs):\n",
    "        super(CNNModel ,self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)  #, padding_idx=PAD_IDX)  # default = 0\n",
    "        self.conv1 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1)\n",
    "        \n",
    "        self.cconv1 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=1, padding=0)\n",
    "        self.cconv2 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=2, padding=1)\n",
    "        self.cconv3 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=3, padding=1)\n",
    "        self.cconv4 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=5, padding=2)\n",
    "        self.cbatch = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim*2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(hidden_dim*2, hidden_dim*2, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim*2, hidden_dim*4, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(hidden_dim*4, hidden_dim*4, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.reducer = nn.Linear(hidden_dim*4, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.contiguous().permute(0,2,1)  # [B, SEQ_LEN, hidden] -> [B, hidden, SEQ_LEN] to slide over sequence for n-gramms\n",
    "        \n",
    "        # x = self.conv1(x)  # comment to simplify\n",
    "        # x = F.relu(x)\n",
    "        \n",
    "        in_x1 = self.cconv1(x)\n",
    "        in_x2 = self.cconv1(x)\n",
    "        in_x3 = self.cconv1(x)\n",
    "        in_x4 = self.cconv1(x)\n",
    "        in_x = torch.cat([in_x1, in_x2, in_x3, in_x4], dim=1)\n",
    "        # in_x = self.cbatch(x)\n",
    "        in_x = F.relu(in_x)\n",
    "        \n",
    "        x = self.conv2(in_x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.pool(x)\n",
    "        x = torch.max(x, dim=2)[0]  # obtain max n-gramm info\n",
    "        # x = x.contiguous().view(x.size(0), -1)\n",
    "        x = self.reducer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab025046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_classes=5).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.1)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2c8cba8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 143 \ttrain loss: 0.6754 \ttrain accuracy: 0.7969 \ttime: 0.5044 s\n",
      "epoch: 1 \tstep: 100 / 143 \ttrain loss: 0.8444 \ttrain accuracy: 0.7031 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 0.8926 \tvalid loss: 0.7425 \ttrain accuracy 0.7076 \tvalid accuracy 0.7298\n",
      "epoch: 2 \tstep: 50 / 143 \ttrain loss: 0.7142 \ttrain accuracy: 0.7500 \ttime: 0.7812 s\n",
      "epoch: 2 \tstep: 100 / 143 \ttrain loss: 0.7884 \ttrain accuracy: 0.7109 \ttime: 0.6000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.7108 \tvalid loss: 0.7263 \ttrain accuracy 0.7527 \tvalid accuracy 0.7437\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 143 \ttrain loss: 0.6253 \ttrain accuracy: 0.7656 \ttime: 0.7838 s\n",
      "epoch: 3 \tstep: 100 / 143 \ttrain loss: 0.5406 \ttrain accuracy: 0.8047 \ttime: 0.7779 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 61.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.6679 \tvalid loss: 0.6938 \ttrain accuracy 0.7677 \tvalid accuracy 0.7475\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 143 \ttrain loss: 0.6675 \ttrain accuracy: 0.7578 \ttime: 0.7784 s\n",
      "epoch: 4 \tstep: 100 / 143 \ttrain loss: 0.5924 \ttrain accuracy: 0.7734 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.6377 \tvalid loss: 0.6891 \ttrain accuracy 0.7777 \tvalid accuracy 0.7554\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 143 \ttrain loss: 0.6113 \ttrain accuracy: 0.7812 \ttime: 0.0875 s\n",
      "epoch: 5 \tstep: 100 / 143 \ttrain loss: 0.5761 \ttrain accuracy: 0.7969 \ttime: 0.7846 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.6098 \tvalid loss: 0.6841 \ttrain accuracy 0.7843 \tvalid accuracy 0.7553\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 143 \ttrain loss: 0.5564 \ttrain accuracy: 0.8047 \ttime: 0.5995 s\n",
      "epoch: 6 \tstep: 100 / 143 \ttrain loss: 0.5142 \ttrain accuracy: 0.8203 \ttime: 0.7844 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.5731 \tvalid loss: 0.7411 \ttrain accuracy 0.7942 \tvalid accuracy 0.7515\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 7 \tstep: 50 / 143 \ttrain loss: 0.5362 \ttrain accuracy: 0.7969 \ttime: 0.6004 s\n",
      "epoch: 7 \tstep: 100 / 143 \ttrain loss: 0.5234 \ttrain accuracy: 0.7891 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.5450 \tvalid loss: 0.7115 \ttrain accuracy 0.8058 \tvalid accuracy 0.7535\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 8 \tstep: 50 / 143 \ttrain loss: 0.4389 \ttrain accuracy: 0.8438 \ttime: 0.6001 s\n",
      "epoch: 8 \tstep: 100 / 143 \ttrain loss: 0.5128 \ttrain accuracy: 0.8125 \ttime: 0.3882 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.5186 \tvalid loss: 0.7698 \ttrain accuracy 0.8141 \tvalid accuracy 0.7422\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 9 \tstep: 50 / 143 \ttrain loss: 0.5304 \ttrain accuracy: 0.8125 \ttime: 0.5502 s\n",
      "epoch: 9 \tstep: 100 / 143 \ttrain loss: 0.4870 \ttrain accuracy: 0.8047 \ttime: 0.7773 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.4585 \tvalid loss: 0.8064 \ttrain accuracy 0.8362 \tvalid accuracy 0.7418\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 119.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.6681 \ttest accuracy 0.7626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c8529",
   "metadata": {},
   "source": [
    "**Bidirectional LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6c416b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=5, dropout=0.1, num_layers=2, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_mid = nn.Linear(hidden_dim*4, hidden_dim*2)\n",
    "        self.fc_out = nn.Linear(hidden_dim*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "                \n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        avg_pool = torch.mean(x, dim=1)\n",
    "        max_pool = torch.max(x, dim=1)[0]\n",
    "        \n",
    "        x = torch.cat((avg_pool, max_pool), dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc_mid(self.dropout(x)))\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ded441a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_layers=1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = FocalLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2eb6bebe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 143 \ttrain loss: 1.0736 \ttrain accuracy: 0.7344 \ttime: 0.0000 s\n",
      "epoch: 1 \tstep: 100 / 143 \ttrain loss: 0.9460 \ttrain accuracy: 0.7109 \ttime: 0.5500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 61.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 1.1043 \tvalid loss: 0.9209 \ttrain accuracy 0.6804 \tvalid accuracy 0.6976\n",
      "epoch: 2 \tstep: 50 / 143 \ttrain loss: 0.8735 \ttrain accuracy: 0.7031 \ttime: 0.0000 s\n",
      "epoch: 2 \tstep: 100 / 143 \ttrain loss: 0.8829 \ttrain accuracy: 0.7031 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 62.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.8674 \tvalid loss: 0.8355 \ttrain accuracy 0.7102 \tvalid accuracy 0.7221\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 143 \ttrain loss: 0.7605 \ttrain accuracy: 0.7109 \ttime: 0.0000 s\n",
      "epoch: 3 \tstep: 100 / 143 \ttrain loss: 0.7622 \ttrain accuracy: 0.7344 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 60.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.8042 \tvalid loss: 0.7984 \ttrain accuracy 0.7265 \tvalid accuracy 0.7319\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 143 \ttrain loss: 0.7229 \ttrain accuracy: 0.7734 \ttime: 0.7809 s\n",
      "epoch: 4 \tstep: 100 / 143 \ttrain loss: 0.7718 \ttrain accuracy: 0.7109 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.7768 \tvalid loss: 0.7753 \ttrain accuracy 0.7311 \tvalid accuracy 0.7366\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 143 \ttrain loss: 0.8357 \ttrain accuracy: 0.7266 \ttime: 0.7808 s\n",
      "epoch: 5 \tstep: 100 / 143 \ttrain loss: 0.7520 \ttrain accuracy: 0.7188 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 64.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.7559 \tvalid loss: 0.7570 \ttrain accuracy 0.7369 \tvalid accuracy 0.7411\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 143 \ttrain loss: 0.8109 \ttrain accuracy: 0.6953 \ttime: 0.0000 s\n",
      "epoch: 6 \tstep: 100 / 143 \ttrain loss: 0.6021 \ttrain accuracy: 0.7891 \ttime: 0.6039 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.7357 \tvalid loss: 0.7438 \ttrain accuracy 0.7435 \tvalid accuracy 0.7418\n",
      "Model saved to: model.pth\n",
      "epoch: 7 \tstep: 50 / 143 \ttrain loss: 0.6336 \ttrain accuracy: 0.7969 \ttime: 0.5495 s\n",
      "epoch: 7 \tstep: 100 / 143 \ttrain loss: 0.7532 \ttrain accuracy: 0.7422 \ttime: 0.5089 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.7205 \tvalid loss: 0.7327 \ttrain accuracy 0.7483 \tvalid accuracy 0.7424\n",
      "Model saved to: model.pth\n",
      "epoch: 8 \tstep: 50 / 143 \ttrain loss: 0.7197 \ttrain accuracy: 0.7344 \ttime: 0.7807 s\n",
      "epoch: 8 \tstep: 100 / 143 \ttrain loss: 0.7835 \ttrain accuracy: 0.7266 \ttime: 0.2999 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 64.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.7111 \tvalid loss: 0.7251 \ttrain accuracy 0.7518 \tvalid accuracy 0.7437\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 143 \ttrain loss: 0.8122 \ttrain accuracy: 0.7266 \ttime: 0.5496 s\n",
      "epoch: 9 \tstep: 100 / 143 \ttrain loss: 0.6631 \ttrain accuracy: 0.7812 \ttime: 0.5500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 63.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.7007 \tvalid loss: 0.7188 \ttrain accuracy 0.7542 \tvalid accuracy 0.7457\n",
      "Model saved to: model.pth\n",
      "epoch: 10 \tstep: 50 / 143 \ttrain loss: 0.6609 \ttrain accuracy: 0.7656 \ttime: 1.0917 s\n",
      "epoch: 10 \tstep: 100 / 143 \ttrain loss: 0.8132 \ttrain accuracy: 0.6875 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.6938 \tvalid loss: 0.7146 \ttrain accuracy 0.7562 \tvalid accuracy 0.7496\n",
      "Model saved to: model.pth\n",
      "epoch: 11 \tstep: 50 / 143 \ttrain loss: 0.6839 \ttrain accuracy: 0.7578 \ttime: 0.0000 s\n",
      "epoch: 11 \tstep: 100 / 143 \ttrain loss: 0.5222 \ttrain accuracy: 0.8203 \ttime: 0.5503 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.6887 \tvalid loss: 0.7089 \ttrain accuracy 0.7573 \tvalid accuracy 0.7489\n",
      "Model saved to: model.pth\n",
      "epoch: 12 \tstep: 50 / 143 \ttrain loss: 0.7375 \ttrain accuracy: 0.7266 \ttime: 0.7807 s\n",
      "epoch: 12 \tstep: 100 / 143 \ttrain loss: 0.7784 \ttrain accuracy: 0.7266 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.6800 \tvalid loss: 0.7044 \ttrain accuracy 0.7599 \tvalid accuracy 0.7496\n",
      "Model saved to: model.pth\n",
      "epoch: 13 \tstep: 50 / 143 \ttrain loss: 0.5910 \ttrain accuracy: 0.7812 \ttime: 0.5500 s\n",
      "epoch: 13 \tstep: 100 / 143 \ttrain loss: 0.6412 \ttrain accuracy: 0.7969 \ttime: 0.5499 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 / 40 \ttrain loss: 0.6753 \tvalid loss: 0.7003 \ttrain accuracy 0.7611 \tvalid accuracy 0.7522\n",
      "Model saved to: model.pth\n",
      "epoch: 14 \tstep: 50 / 143 \ttrain loss: 0.4886 \ttrain accuracy: 0.8438 \ttime: 0.2500 s\n",
      "epoch: 14 \tstep: 100 / 143 \ttrain loss: 0.7449 \ttrain accuracy: 0.7578 \ttime: 0.3499 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 / 40 \ttrain loss: 0.6658 \tvalid loss: 0.6963 \ttrain accuracy 0.7656 \tvalid accuracy 0.7542\n",
      "Model saved to: model.pth\n",
      "epoch: 15 \tstep: 50 / 143 \ttrain loss: 0.8283 \ttrain accuracy: 0.6875 \ttime: 0.5498 s\n",
      "epoch: 15 \tstep: 100 / 143 \ttrain loss: 0.6779 \ttrain accuracy: 0.7344 \ttime: 0.7817 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 65.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 / 40 \ttrain loss: 0.6639 \tvalid loss: 0.6932 \ttrain accuracy 0.7643 \tvalid accuracy 0.7555\n",
      "Model saved to: model.pth\n",
      "epoch: 16 \tstep: 50 / 143 \ttrain loss: 0.5577 \ttrain accuracy: 0.8281 \ttime: 0.0000 s\n",
      "epoch: 16 \tstep: 100 / 143 \ttrain loss: 0.8473 \ttrain accuracy: 0.6953 \ttime: 0.2996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 62.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 / 40 \ttrain loss: 0.6559 \tvalid loss: 0.6905 \ttrain accuracy 0.7680 \tvalid accuracy 0.7549\n",
      "Model saved to: model.pth\n",
      "epoch: 17 \tstep: 50 / 143 \ttrain loss: 0.9218 \ttrain accuracy: 0.6484 \ttime: 0.0000 s\n",
      "epoch: 17 \tstep: 100 / 143 \ttrain loss: 0.6658 \ttrain accuracy: 0.7734 \ttime: 0.5500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 / 40 \ttrain loss: 0.6489 \tvalid loss: 0.6873 \ttrain accuracy 0.7704 \tvalid accuracy 0.7569\n",
      "Model saved to: model.pth\n",
      "epoch: 18 \tstep: 50 / 143 \ttrain loss: 0.6277 \ttrain accuracy: 0.7891 \ttime: 0.8887 s\n",
      "epoch: 18 \tstep: 100 / 143 \ttrain loss: 0.6447 \ttrain accuracy: 0.7891 \ttime: 0.5499 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 61.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 / 40 \ttrain loss: 0.6457 \tvalid loss: 0.6844 \ttrain accuracy 0.7703 \tvalid accuracy 0.7575\n",
      "Model saved to: model.pth\n",
      "epoch: 19 \tstep: 50 / 143 \ttrain loss: 0.6163 \ttrain accuracy: 0.7812 \ttime: 0.0000 s\n",
      "epoch: 19 \tstep: 100 / 143 \ttrain loss: 0.7049 \ttrain accuracy: 0.7422 \ttime: 0.5500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 / 40 \ttrain loss: 0.6410 \tvalid loss: 0.6822 \ttrain accuracy 0.7726 \tvalid accuracy 0.7549\n",
      "Model saved to: model.pth\n",
      "epoch: 20 \tstep: 50 / 143 \ttrain loss: 0.5153 \ttrain accuracy: 0.8359 \ttime: 0.7814 s\n",
      "epoch: 20 \tstep: 100 / 143 \ttrain loss: 0.6106 \ttrain accuracy: 0.7812 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 62.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 / 40 \ttrain loss: 0.6354 \tvalid loss: 0.6800 \ttrain accuracy 0.7758 \tvalid accuracy 0.7588\n",
      "Model saved to: model.pth\n",
      "epoch: 21 \tstep: 50 / 143 \ttrain loss: 0.4450 \ttrain accuracy: 0.8516 \ttime: 0.0000 s\n",
      "epoch: 21 \tstep: 100 / 143 \ttrain loss: 0.5966 \ttrain accuracy: 0.8203 \ttime: 0.3492 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 / 40 \ttrain loss: 0.6303 \tvalid loss: 0.6787 \ttrain accuracy 0.7771 \tvalid accuracy 0.7654\n",
      "Model saved to: model.pth\n",
      "epoch: 22 \tstep: 50 / 143 \ttrain loss: 0.6392 \ttrain accuracy: 0.7656 \ttime: 0.8371 s\n",
      "epoch: 22 \tstep: 100 / 143 \ttrain loss: 0.6607 \ttrain accuracy: 0.7656 \ttime: 0.5500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 / 40 \ttrain loss: 0.6271 \tvalid loss: 0.6754 \ttrain accuracy 0.7795 \tvalid accuracy 0.7640\n",
      "Model saved to: model.pth\n",
      "epoch: 23 \tstep: 50 / 143 \ttrain loss: 0.7722 \ttrain accuracy: 0.7109 \ttime: 0.7819 s\n",
      "epoch: 23 \tstep: 100 / 143 \ttrain loss: 0.6445 \ttrain accuracy: 0.7656 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 / 40 \ttrain loss: 0.6222 \tvalid loss: 0.6730 \ttrain accuracy 0.7811 \tvalid accuracy 0.7647\n",
      "Model saved to: model.pth\n",
      "epoch: 24 \tstep: 50 / 143 \ttrain loss: 0.5538 \ttrain accuracy: 0.7812 \ttime: 0.0000 s\n",
      "epoch: 24 \tstep: 100 / 143 \ttrain loss: 0.7795 \ttrain accuracy: 0.6875 \ttime: 0.3279 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 / 40 \ttrain loss: 0.6172 \tvalid loss: 0.6708 \ttrain accuracy 0.7811 \tvalid accuracy 0.7647\n",
      "Model saved to: model.pth\n",
      "epoch: 25 \tstep: 50 / 143 \ttrain loss: 0.5271 \ttrain accuracy: 0.8125 \ttime: 0.7812 s\n",
      "epoch: 25 \tstep: 100 / 143 \ttrain loss: 0.6007 \ttrain accuracy: 0.8125 \ttime: 0.7822 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 / 40 \ttrain loss: 0.6107 \tvalid loss: 0.6700 \ttrain accuracy 0.7850 \tvalid accuracy 0.7601\n",
      "Model saved to: model.pth\n",
      "epoch: 26 \tstep: 50 / 143 \ttrain loss: 0.6377 \ttrain accuracy: 0.7734 \ttime: 0.5000 s\n",
      "epoch: 26 \tstep: 100 / 143 \ttrain loss: 0.5582 \ttrain accuracy: 0.8047 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 66.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 / 40 \ttrain loss: 0.6043 \tvalid loss: 0.6687 \ttrain accuracy 0.7871 \tvalid accuracy 0.7680\n",
      "Model saved to: model.pth\n",
      "epoch: 27 \tstep: 50 / 143 \ttrain loss: 0.6815 \ttrain accuracy: 0.7812 \ttime: 0.7816 s\n",
      "epoch: 27 \tstep: 100 / 143 \ttrain loss: 0.5535 \ttrain accuracy: 0.8281 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 / 40 \ttrain loss: 0.5997 \tvalid loss: 0.6689 \ttrain accuracy 0.7895 \tvalid accuracy 0.7660\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 28 \tstep: 50 / 143 \ttrain loss: 0.5912 \ttrain accuracy: 0.8125 \ttime: 0.5830 s\n",
      "epoch: 28 \tstep: 100 / 143 \ttrain loss: 0.5293 \ttrain accuracy: 0.8281 \ttime: 0.7843 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 / 40 \ttrain loss: 0.5940 \tvalid loss: 0.6758 \ttrain accuracy 0.7909 \tvalid accuracy 0.7713\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 29 \tstep: 50 / 143 \ttrain loss: 0.5277 \ttrain accuracy: 0.8594 \ttime: 0.7802 s\n",
      "epoch: 29 \tstep: 100 / 143 \ttrain loss: 0.5646 \ttrain accuracy: 0.8359 \ttime: 0.7812 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 61.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 / 40 \ttrain loss: 0.5922 \tvalid loss: 0.6687 \ttrain accuracy 0.7910 \tvalid accuracy 0.7640\n",
      "Model saved to: model.pth\n",
      "epoch: 30 \tstep: 50 / 143 \ttrain loss: 0.4568 \ttrain accuracy: 0.8516 \ttime: 0.5000 s\n",
      "epoch: 30 \tstep: 100 / 143 \ttrain loss: 0.6901 \ttrain accuracy: 0.7422 \ttime: 0.7818 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 / 40 \ttrain loss: 0.5841 \tvalid loss: 0.6692 \ttrain accuracy 0.7936 \tvalid accuracy 0.7673\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 31 \tstep: 50 / 143 \ttrain loss: 0.5317 \ttrain accuracy: 0.8047 \ttime: 0.7811 s\n",
      "epoch: 31 \tstep: 100 / 143 \ttrain loss: 0.5831 \ttrain accuracy: 0.8125 \ttime: 0.5008 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 63.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 / 40 \ttrain loss: 0.5780 \tvalid loss: 0.6674 \ttrain accuracy 0.7972 \tvalid accuracy 0.7726\n",
      "Model saved to: model.pth\n",
      "epoch: 32 \tstep: 50 / 143 \ttrain loss: 0.5244 \ttrain accuracy: 0.7969 \ttime: 0.0000 s\n",
      "epoch: 32 \tstep: 100 / 143 \ttrain loss: 0.5768 \ttrain accuracy: 0.7969 \ttime: 0.4005 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 / 40 \ttrain loss: 0.5739 \tvalid loss: 0.6742 \ttrain accuracy 0.7995 \tvalid accuracy 0.7707\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 33 \tstep: 50 / 143 \ttrain loss: 0.4883 \ttrain accuracy: 0.8594 \ttime: 0.7807 s\n",
      "epoch: 33 \tstep: 100 / 143 \ttrain loss: 0.5847 \ttrain accuracy: 0.7734 \ttime: 0.2095 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 / 40 \ttrain loss: 0.5698 \tvalid loss: 0.6701 \ttrain accuracy 0.8007 \tvalid accuracy 0.7726\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 34 \tstep: 50 / 143 \ttrain loss: 0.5083 \ttrain accuracy: 0.8359 \ttime: 0.7813 s\n",
      "epoch: 34 \tstep: 100 / 143 \ttrain loss: 0.6129 \ttrain accuracy: 0.7578 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 62.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 / 40 \ttrain loss: 0.5597 \tvalid loss: 0.6726 \ttrain accuracy 0.8022 \tvalid accuracy 0.7660\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 35 \tstep: 50 / 143 \ttrain loss: 0.4788 \ttrain accuracy: 0.8516 \ttime: 0.0000 s\n",
      "epoch: 35 \tstep: 100 / 143 \ttrain loss: 0.6768 \ttrain accuracy: 0.8281 \ttime: 0.7814 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 / 40 \ttrain loss: 0.5599 \tvalid loss: 0.6690 \ttrain accuracy 0.8047 \tvalid accuracy 0.7694\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 118.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.6482 \ttest accuracy 0.7646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff6953",
   "metadata": {},
   "source": [
    "**packed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ccdc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=5, dropout=0.1, bilstm=True, num_layers=2, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=bilstm,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "        scale = 2 if bilstm else 1\n",
    "        self.pool = nn.AdaptiveAvgPool1d(5)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_mid = nn.Linear(hidden_dim*10, hidden_dim*scale)\n",
    "        self.fc_out = nn.Linear(hidden_dim*scale, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        text_lengths = torch.sum((x != PAD_IDX).type(torch.int32), dim=1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # ignore padding\n",
    "        packed_embedded = pack_padded_sequence(x, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)\n",
    "        \n",
    "        output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        output = output.contiguous().transpose(1,2)\n",
    "        output = self.pool(output)\n",
    "\n",
    "        output = output.contiguous().view(batch_size, -1)\n",
    "\n",
    "        x = F.relu(self.fc_mid(self.dropout(output)))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57d3ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_layers=1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd4d74b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 143 \ttrain loss: 1.5775 \ttrain accuracy: 0.6484 \ttime: 0.5495 s\n",
      "epoch: 1 \tstep: 100 / 143 \ttrain loss: 1.5215 \ttrain accuracy: 0.6719 \ttime: 0.8000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 1.5290 \tvalid loss: 1.3989 \ttrain accuracy 0.5561 \tvalid accuracy 0.6982\n",
      "epoch: 2 \tstep: 50 / 143 \ttrain loss: 1.1617 \ttrain accuracy: 0.8047 \ttime: 1.0395 s\n",
      "epoch: 2 \tstep: 100 / 143 \ttrain loss: 1.0608 \ttrain accuracy: 0.7188 \ttime: 0.9388 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 47.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 1.2191 \tvalid loss: 1.1285 \ttrain accuracy 0.7148 \tvalid accuracy 0.7147\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 143 \ttrain loss: 1.2074 \ttrain accuracy: 0.6875 \ttime: 0.7000 s\n",
      "epoch: 3 \tstep: 100 / 143 \ttrain loss: 0.9346 \ttrain accuracy: 0.7734 \ttime: 0.6999 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 1.0284 \tvalid loss: 0.9824 \ttrain accuracy 0.7265 \tvalid accuracy 0.7226\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 143 \ttrain loss: 0.8284 \ttrain accuracy: 0.7344 \ttime: 0.7499 s\n",
      "epoch: 4 \tstep: 100 / 143 \ttrain loss: 0.7598 \ttrain accuracy: 0.7969 \ttime: 1.0882 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.9046 \tvalid loss: 0.8846 \ttrain accuracy 0.7355 \tvalid accuracy 0.7318\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 143 \ttrain loss: 0.8700 \ttrain accuracy: 0.7422 \ttime: 0.0000 s\n",
      "epoch: 5 \tstep: 100 / 143 \ttrain loss: 0.7163 \ttrain accuracy: 0.7891 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 52.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.8271 \tvalid loss: 0.8307 \ttrain accuracy 0.7401 \tvalid accuracy 0.7371\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 143 \ttrain loss: 0.9825 \ttrain accuracy: 0.6484 \ttime: 0.9500 s\n",
      "epoch: 6 \tstep: 100 / 143 \ttrain loss: 0.7686 \ttrain accuracy: 0.7812 \ttime: 0.7996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.7874 \tvalid loss: 0.7977 \ttrain accuracy 0.7458 \tvalid accuracy 0.7404\n",
      "Model saved to: model.pth\n",
      "epoch: 7 \tstep: 50 / 143 \ttrain loss: 0.7539 \ttrain accuracy: 0.7500 \ttime: 0.5997 s\n",
      "epoch: 7 \tstep: 100 / 143 \ttrain loss: 0.6682 \ttrain accuracy: 0.7969 \ttime: 0.7812 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.7640 \tvalid loss: 0.7773 \ttrain accuracy 0.7461 \tvalid accuracy 0.7417\n",
      "Model saved to: model.pth\n",
      "epoch: 8 \tstep: 50 / 143 \ttrain loss: 0.7572 \ttrain accuracy: 0.7734 \ttime: 0.7812 s\n",
      "epoch: 8 \tstep: 100 / 143 \ttrain loss: 0.7016 \ttrain accuracy: 0.8047 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.7462 \tvalid loss: 0.7616 \ttrain accuracy 0.7467 \tvalid accuracy 0.7437\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 143 \ttrain loss: 0.6023 \ttrain accuracy: 0.8281 \ttime: 0.7813 s\n",
      "epoch: 9 \tstep: 100 / 143 \ttrain loss: 0.5976 \ttrain accuracy: 0.8047 \ttime: 1.0893 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 52.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.7279 \tvalid loss: 0.7505 \ttrain accuracy 0.7497 \tvalid accuracy 0.7410\n",
      "Model saved to: model.pth\n",
      "epoch: 10 \tstep: 50 / 143 \ttrain loss: 0.8375 \ttrain accuracy: 0.7344 \ttime: 0.6495 s\n",
      "epoch: 10 \tstep: 100 / 143 \ttrain loss: 0.6606 \ttrain accuracy: 0.7812 \ttime: 0.6028 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.7174 \tvalid loss: 0.7414 \ttrain accuracy 0.7515 \tvalid accuracy 0.7417\n",
      "Model saved to: model.pth\n",
      "epoch: 11 \tstep: 50 / 143 \ttrain loss: 0.6334 \ttrain accuracy: 0.7812 \ttime: 0.4555 s\n",
      "epoch: 11 \tstep: 100 / 143 \ttrain loss: 0.8402 \ttrain accuracy: 0.7031 \ttime: 0.7812 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.7068 \tvalid loss: 0.7336 \ttrain accuracy 0.7520 \tvalid accuracy 0.7449\n",
      "Model saved to: model.pth\n",
      "epoch: 12 \tstep: 50 / 143 \ttrain loss: 0.7221 \ttrain accuracy: 0.7500 \ttime: 0.8997 s\n",
      "epoch: 12 \tstep: 100 / 143 \ttrain loss: 0.6568 \ttrain accuracy: 0.7344 \ttime: 0.3025 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.6971 \tvalid loss: 0.7272 \ttrain accuracy 0.7553 \tvalid accuracy 0.7462\n",
      "Model saved to: model.pth\n",
      "epoch: 13 \tstep: 50 / 143 \ttrain loss: 0.6671 \ttrain accuracy: 0.7578 \ttime: 0.7001 s\n",
      "epoch: 13 \tstep: 100 / 143 \ttrain loss: 0.6638 \ttrain accuracy: 0.7500 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 / 40 \ttrain loss: 0.6900 \tvalid loss: 0.7222 \ttrain accuracy 0.7571 \tvalid accuracy 0.7482\n",
      "Model saved to: model.pth\n",
      "epoch: 14 \tstep: 50 / 143 \ttrain loss: 0.7448 \ttrain accuracy: 0.7188 \ttime: 0.8984 s\n",
      "epoch: 14 \tstep: 100 / 143 \ttrain loss: 0.8394 \ttrain accuracy: 0.7031 \ttime: 0.4913 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 / 40 \ttrain loss: 0.6813 \tvalid loss: 0.7168 \ttrain accuracy 0.7587 \tvalid accuracy 0.7488\n",
      "Model saved to: model.pth\n",
      "epoch: 15 \tstep: 50 / 143 \ttrain loss: 0.6429 \ttrain accuracy: 0.7734 \ttime: 0.0000 s\n",
      "epoch: 15 \tstep: 100 / 143 \ttrain loss: 0.5503 \ttrain accuracy: 0.8203 \ttime: 0.5500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 / 40 \ttrain loss: 0.6738 \tvalid loss: 0.7129 \ttrain accuracy 0.7596 \tvalid accuracy 0.7514\n",
      "Model saved to: model.pth\n",
      "epoch: 16 \tstep: 50 / 143 \ttrain loss: 0.6956 \ttrain accuracy: 0.7578 \ttime: 0.9011 s\n",
      "epoch: 16 \tstep: 100 / 143 \ttrain loss: 0.6189 \ttrain accuracy: 0.7578 \ttime: 0.9996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 / 40 \ttrain loss: 0.6725 \tvalid loss: 0.7086 \ttrain accuracy 0.7603 \tvalid accuracy 0.7508\n",
      "Model saved to: model.pth\n",
      "epoch: 17 \tstep: 50 / 143 \ttrain loss: 0.6047 \ttrain accuracy: 0.7812 \ttime: 0.6496 s\n",
      "epoch: 17 \tstep: 100 / 143 \ttrain loss: 0.6433 \ttrain accuracy: 0.7656 \ttime: 0.5995 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 / 40 \ttrain loss: 0.6622 \tvalid loss: 0.7042 \ttrain accuracy 0.7635 \tvalid accuracy 0.7488\n",
      "Model saved to: model.pth\n",
      "epoch: 18 \tstep: 50 / 143 \ttrain loss: 0.5966 \ttrain accuracy: 0.8047 \ttime: 0.5534 s\n",
      "epoch: 18 \tstep: 100 / 143 \ttrain loss: 0.6684 \ttrain accuracy: 0.7891 \ttime: 0.7806 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 / 40 \ttrain loss: 0.6574 \tvalid loss: 0.7013 \ttrain accuracy 0.7656 \tvalid accuracy 0.7527\n",
      "Model saved to: model.pth\n",
      "epoch: 19 \tstep: 50 / 143 \ttrain loss: 0.5986 \ttrain accuracy: 0.7734 \ttime: 0.7812 s\n",
      "epoch: 19 \tstep: 100 / 143 \ttrain loss: 0.6003 \ttrain accuracy: 0.7969 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 / 40 \ttrain loss: 0.6502 \tvalid loss: 0.6988 \ttrain accuracy 0.7689 \tvalid accuracy 0.7521\n",
      "Model saved to: model.pth\n",
      "epoch: 20 \tstep: 50 / 143 \ttrain loss: 0.7160 \ttrain accuracy: 0.7109 \ttime: 0.7561 s\n",
      "epoch: 20 \tstep: 100 / 143 \ttrain loss: 0.7209 \ttrain accuracy: 0.7422 \ttime: 0.6550 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 60.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 / 40 \ttrain loss: 0.6428 \tvalid loss: 0.6965 \ttrain accuracy 0.7728 \tvalid accuracy 0.7540\n",
      "Model saved to: model.pth\n",
      "epoch: 21 \tstep: 50 / 143 \ttrain loss: 0.7459 \ttrain accuracy: 0.7188 \ttime: 0.6993 s\n",
      "epoch: 21 \tstep: 100 / 143 \ttrain loss: 0.5711 \ttrain accuracy: 0.8125 \ttime: 0.8997 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 / 40 \ttrain loss: 0.6382 \tvalid loss: 0.6944 \ttrain accuracy 0.7714 \tvalid accuracy 0.7540\n",
      "Model saved to: model.pth\n",
      "epoch: 22 \tstep: 50 / 143 \ttrain loss: 0.7200 \ttrain accuracy: 0.7422 \ttime: 0.5496 s\n",
      "epoch: 22 \tstep: 100 / 143 \ttrain loss: 0.6012 \ttrain accuracy: 0.8047 \ttime: 0.6497 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 49.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 / 40 \ttrain loss: 0.6333 \tvalid loss: 0.6950 \ttrain accuracy 0.7740 \tvalid accuracy 0.7573\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 23 \tstep: 50 / 143 \ttrain loss: 0.6729 \ttrain accuracy: 0.7656 \ttime: 0.1548 s\n",
      "epoch: 23 \tstep: 100 / 143 \ttrain loss: 0.6000 \ttrain accuracy: 0.8047 \ttime: 1.1500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 / 40 \ttrain loss: 0.6275 \tvalid loss: 0.6921 \ttrain accuracy 0.7760 \tvalid accuracy 0.7573\n",
      "Model saved to: model.pth\n",
      "epoch: 24 \tstep: 50 / 143 \ttrain loss: 0.5698 \ttrain accuracy: 0.8047 \ttime: 1.2945 s\n",
      "epoch: 24 \tstep: 100 / 143 \ttrain loss: 0.6207 \ttrain accuracy: 0.7969 \ttime: 0.7812 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 / 40 \ttrain loss: 0.6233 \tvalid loss: 0.6904 \ttrain accuracy 0.7791 \tvalid accuracy 0.7606\n",
      "Model saved to: model.pth\n",
      "epoch: 25 \tstep: 50 / 143 \ttrain loss: 0.5342 \ttrain accuracy: 0.8125 \ttime: 0.6000 s\n",
      "epoch: 25 \tstep: 100 / 143 \ttrain loss: 0.6034 \ttrain accuracy: 0.7969 \ttime: 0.6005 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 / 40 \ttrain loss: 0.6181 \tvalid loss: 0.6900 \ttrain accuracy 0.7776 \tvalid accuracy 0.7547\n",
      "Model saved to: model.pth\n",
      "epoch: 26 \tstep: 50 / 143 \ttrain loss: 0.6789 \ttrain accuracy: 0.7578 \ttime: 0.8553 s\n",
      "epoch: 26 \tstep: 100 / 143 \ttrain loss: 0.6163 \ttrain accuracy: 0.7969 \ttime: 0.6500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 52.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 / 40 \ttrain loss: 0.6106 \tvalid loss: 0.6905 \ttrain accuracy 0.7822 \tvalid accuracy 0.7553\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 27 \tstep: 50 / 143 \ttrain loss: 0.5831 \ttrain accuracy: 0.8047 \ttime: 1.1487 s\n",
      "epoch: 27 \tstep: 100 / 143 \ttrain loss: 0.7079 \ttrain accuracy: 0.7422 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 / 40 \ttrain loss: 0.6067 \tvalid loss: 0.6894 \ttrain accuracy 0.7849 \tvalid accuracy 0.7540\n",
      "Model saved to: model.pth\n",
      "epoch: 28 \tstep: 50 / 143 \ttrain loss: 0.6097 \ttrain accuracy: 0.8125 \ttime: 0.6000 s\n",
      "epoch: 28 \tstep: 100 / 143 \ttrain loss: 0.5551 \ttrain accuracy: 0.8203 \ttime: 1.3887 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 / 40 \ttrain loss: 0.5989 \tvalid loss: 0.6900 \ttrain accuracy 0.7870 \tvalid accuracy 0.7554\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 29 \tstep: 50 / 143 \ttrain loss: 0.6499 \ttrain accuracy: 0.7812 \ttime: 0.6000 s\n",
      "epoch: 29 \tstep: 100 / 143 \ttrain loss: 0.5952 \ttrain accuracy: 0.8125 \ttime: 0.6996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 52.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 / 40 \ttrain loss: 0.5985 \tvalid loss: 0.6888 \ttrain accuracy 0.7872 \tvalid accuracy 0.7592\n",
      "Model saved to: model.pth\n",
      "epoch: 30 \tstep: 50 / 143 \ttrain loss: 0.4803 \ttrain accuracy: 0.8359 \ttime: 0.8001 s\n",
      "epoch: 30 \tstep: 100 / 143 \ttrain loss: 0.7710 \ttrain accuracy: 0.7266 \ttime: 0.7000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 / 40 \ttrain loss: 0.5905 \tvalid loss: 0.6905 \ttrain accuracy 0.7893 \tvalid accuracy 0.7599\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 31 \tstep: 50 / 143 \ttrain loss: 0.6284 \ttrain accuracy: 0.7344 \ttime: 1.3235 s\n",
      "epoch: 31 \tstep: 100 / 143 \ttrain loss: 0.7310 \ttrain accuracy: 0.7266 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 / 40 \ttrain loss: 0.5868 \tvalid loss: 0.6911 \ttrain accuracy 0.7889 \tvalid accuracy 0.7586\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 32 \tstep: 50 / 143 \ttrain loss: 0.5526 \ttrain accuracy: 0.8125 \ttime: 0.7818 s\n",
      "epoch: 32 \tstep: 100 / 143 \ttrain loss: 0.5437 \ttrain accuracy: 0.8047 \ttime: 0.3142 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 / 40 \ttrain loss: 0.5805 \tvalid loss: 0.6927 \ttrain accuracy 0.7918 \tvalid accuracy 0.7593\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 33 \tstep: 50 / 143 \ttrain loss: 0.6932 \ttrain accuracy: 0.7109 \ttime: 1.0958 s\n",
      "epoch: 33 \tstep: 100 / 143 \ttrain loss: 0.5686 \ttrain accuracy: 0.7656 \ttime: 0.7000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 / 40 \ttrain loss: 0.5736 \tvalid loss: 0.6948 \ttrain accuracy 0.7953 \tvalid accuracy 0.7580\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 97.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.6660 \ttest accuracy 0.7685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88738e9",
   "metadata": {},
   "source": [
    "**LSTM / hidden**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe344995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=5, dropout=0.1, bilstm=True, num_layers=2, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=bilstm,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_mid = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        text_lengths = torch.sum((x != PAD_IDX).type(torch.int32), dim=1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # ignore padding\n",
    "        packed_embedded = pack_padded_sequence(x, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)  # h_c = [2, B, hidden]\n",
    "\n",
    "        # concatenation of the final forward and reverse hidden states\n",
    "        x = self.dropout(torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1))\n",
    "\n",
    "        x = F.relu(self.fc_mid(self.dropout(x)))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a782797",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_layers=1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eb949b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 143 \ttrain loss: 1.6232 \ttrain accuracy: 0.1250 \ttime: 0.9767 s\n",
      "epoch: 1 \tstep: 100 / 143 \ttrain loss: 1.5113 \ttrain accuracy: 0.5781 \ttime: 0.7808 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 1.5594 \tvalid loss: 1.3415 \ttrain accuracy 0.3382 \tvalid accuracy 0.6609\n",
      "epoch: 2 \tstep: 50 / 143 \ttrain loss: 1.1425 \ttrain accuracy: 0.6562 \ttime: 0.7814 s\n",
      "epoch: 2 \tstep: 100 / 143 \ttrain loss: 0.9691 \ttrain accuracy: 0.7031 \ttime: 0.9850 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 1.0635 \tvalid loss: 0.9809 \ttrain accuracy 0.6893 \tvalid accuracy 0.6884\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 143 \ttrain loss: 0.8928 \ttrain accuracy: 0.6719 \ttime: 0.7815 s\n",
      "epoch: 3 \tstep: 100 / 143 \ttrain loss: 0.8593 \ttrain accuracy: 0.7031 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.9015 \tvalid loss: 0.9096 \ttrain accuracy 0.6956 \tvalid accuracy 0.6910\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 143 \ttrain loss: 0.9469 \ttrain accuracy: 0.6484 \ttime: 1.1974 s\n",
      "epoch: 4 \tstep: 100 / 143 \ttrain loss: 0.7703 \ttrain accuracy: 0.7031 \ttime: 0.7500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.8426 \tvalid loss: 0.8667 \ttrain accuracy 0.7017 \tvalid accuracy 0.6970\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 143 \ttrain loss: 0.8994 \ttrain accuracy: 0.6641 \ttime: 0.3026 s\n",
      "epoch: 5 \tstep: 100 / 143 \ttrain loss: 0.7962 \ttrain accuracy: 0.7031 \ttime: 0.3056 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.8054 \tvalid loss: 0.8287 \ttrain accuracy 0.7135 \tvalid accuracy 0.7068\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 143 \ttrain loss: 0.7650 \ttrain accuracy: 0.7500 \ttime: 1.1117 s\n",
      "epoch: 6 \tstep: 100 / 143 \ttrain loss: 0.7645 \ttrain accuracy: 0.7578 \ttime: 0.7842 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.7664 \tvalid loss: 0.7919 \ttrain accuracy 0.7321 \tvalid accuracy 0.7160\n",
      "Model saved to: model.pth\n",
      "epoch: 7 \tstep: 50 / 143 \ttrain loss: 0.7910 \ttrain accuracy: 0.7422 \ttime: 0.0000 s\n",
      "epoch: 7 \tstep: 100 / 143 \ttrain loss: 0.8355 \ttrain accuracy: 0.7109 \ttime: 0.7817 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.7381 \tvalid loss: 0.7674 \ttrain accuracy 0.7440 \tvalid accuracy 0.7245\n",
      "Model saved to: model.pth\n",
      "epoch: 8 \tstep: 50 / 143 \ttrain loss: 0.6984 \ttrain accuracy: 0.7734 \ttime: 0.5555 s\n",
      "epoch: 8 \tstep: 100 / 143 \ttrain loss: 0.6221 \ttrain accuracy: 0.8125 \ttime: 0.7808 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.7191 \tvalid loss: 0.7546 \ttrain accuracy 0.7481 \tvalid accuracy 0.7258\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 143 \ttrain loss: 0.7070 \ttrain accuracy: 0.7344 \ttime: 0.7819 s\n",
      "epoch: 9 \tstep: 100 / 143 \ttrain loss: 0.7681 \ttrain accuracy: 0.7109 \ttime: 0.4496 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.7063 \tvalid loss: 0.7459 \ttrain accuracy 0.7524 \tvalid accuracy 0.7304\n",
      "Model saved to: model.pth\n",
      "epoch: 10 \tstep: 50 / 143 \ttrain loss: 0.7585 \ttrain accuracy: 0.7188 \ttime: 0.7772 s\n",
      "epoch: 10 \tstep: 100 / 143 \ttrain loss: 0.6334 \ttrain accuracy: 0.7812 \ttime: 0.7769 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.6970 \tvalid loss: 0.7391 \ttrain accuracy 0.7538 \tvalid accuracy 0.7337\n",
      "Model saved to: model.pth\n",
      "epoch: 11 \tstep: 50 / 143 \ttrain loss: 0.8539 \ttrain accuracy: 0.7109 \ttime: 0.6500 s\n",
      "epoch: 11 \tstep: 100 / 143 \ttrain loss: 0.7653 \ttrain accuracy: 0.6797 \ttime: 1.2882 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.6914 \tvalid loss: 0.7332 \ttrain accuracy 0.7561 \tvalid accuracy 0.7383\n",
      "Model saved to: model.pth\n",
      "epoch: 12 \tstep: 50 / 143 \ttrain loss: 0.7576 \ttrain accuracy: 0.7188 \ttime: 0.5499 s\n",
      "epoch: 12 \tstep: 100 / 143 \ttrain loss: 0.6725 \ttrain accuracy: 0.7812 \ttime: 0.6501 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.6831 \tvalid loss: 0.7269 \ttrain accuracy 0.7600 \tvalid accuracy 0.7417\n",
      "Model saved to: model.pth\n",
      "epoch: 13 \tstep: 50 / 143 \ttrain loss: 0.6184 \ttrain accuracy: 0.7500 \ttime: 0.7773 s\n",
      "epoch: 13 \tstep: 100 / 143 \ttrain loss: 0.6016 \ttrain accuracy: 0.7969 \ttime: 0.7845 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 / 40 \ttrain loss: 0.6764 \tvalid loss: 0.7222 \ttrain accuracy 0.7600 \tvalid accuracy 0.7430\n",
      "Model saved to: model.pth\n",
      "epoch: 14 \tstep: 50 / 143 \ttrain loss: 0.8015 \ttrain accuracy: 0.7109 \ttime: 1.1586 s\n",
      "epoch: 14 \tstep: 100 / 143 \ttrain loss: 0.6155 \ttrain accuracy: 0.8047 \ttime: 0.6500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 60.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 / 40 \ttrain loss: 0.6709 \tvalid loss: 0.7182 \ttrain accuracy 0.7624 \tvalid accuracy 0.7462\n",
      "Model saved to: model.pth\n",
      "epoch: 15 \tstep: 50 / 143 \ttrain loss: 0.6735 \ttrain accuracy: 0.7812 \ttime: 0.5996 s\n",
      "epoch: 15 \tstep: 100 / 143 \ttrain loss: 0.8324 \ttrain accuracy: 0.7109 \ttime: 0.7500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 / 40 \ttrain loss: 0.6623 \tvalid loss: 0.7145 \ttrain accuracy 0.7635 \tvalid accuracy 0.7469\n",
      "Model saved to: model.pth\n",
      "epoch: 16 \tstep: 50 / 143 \ttrain loss: 0.5646 \ttrain accuracy: 0.7891 \ttime: 0.7812 s\n",
      "epoch: 16 \tstep: 100 / 143 \ttrain loss: 0.7432 \ttrain accuracy: 0.7188 \ttime: 0.6996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 / 40 \ttrain loss: 0.6572 \tvalid loss: 0.7103 \ttrain accuracy 0.7654 \tvalid accuracy 0.7462\n",
      "Model saved to: model.pth\n",
      "epoch: 17 \tstep: 50 / 143 \ttrain loss: 0.7166 \ttrain accuracy: 0.7266 \ttime: 0.3675 s\n",
      "epoch: 17 \tstep: 100 / 143 \ttrain loss: 0.6615 \ttrain accuracy: 0.7578 \ttime: 0.7807 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 / 40 \ttrain loss: 0.6479 \tvalid loss: 0.7077 \ttrain accuracy 0.7685 \tvalid accuracy 0.7515\n",
      "Model saved to: model.pth\n",
      "epoch: 18 \tstep: 50 / 143 \ttrain loss: 0.6570 \ttrain accuracy: 0.8125 \ttime: 0.6500 s\n",
      "epoch: 18 \tstep: 100 / 143 \ttrain loss: 0.6993 \ttrain accuracy: 0.7500 \ttime: 0.6500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 / 40 \ttrain loss: 0.6463 \tvalid loss: 0.7048 \ttrain accuracy 0.7707 \tvalid accuracy 0.7521\n",
      "Model saved to: model.pth\n",
      "epoch: 19 \tstep: 50 / 143 \ttrain loss: 0.5984 \ttrain accuracy: 0.7734 \ttime: 0.6999 s\n",
      "epoch: 19 \tstep: 100 / 143 \ttrain loss: 0.6219 \ttrain accuracy: 0.7891 \ttime: 0.7807 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 / 40 \ttrain loss: 0.6402 \tvalid loss: 0.7013 \ttrain accuracy 0.7717 \tvalid accuracy 0.7547\n",
      "Model saved to: model.pth\n",
      "epoch: 20 \tstep: 50 / 143 \ttrain loss: 0.5591 \ttrain accuracy: 0.8281 \ttime: 0.6407 s\n",
      "epoch: 20 \tstep: 100 / 143 \ttrain loss: 0.6841 \ttrain accuracy: 0.7812 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 / 40 \ttrain loss: 0.6351 \tvalid loss: 0.6987 \ttrain accuracy 0.7746 \tvalid accuracy 0.7560\n",
      "Model saved to: model.pth\n",
      "epoch: 21 \tstep: 50 / 143 \ttrain loss: 0.6305 \ttrain accuracy: 0.7812 \ttime: 0.7212 s\n",
      "epoch: 21 \tstep: 100 / 143 \ttrain loss: 0.6575 \ttrain accuracy: 0.7734 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21 / 40 \ttrain loss: 0.6300 \tvalid loss: 0.6967 \ttrain accuracy 0.7770 \tvalid accuracy 0.7567\n",
      "Model saved to: model.pth\n",
      "epoch: 22 \tstep: 50 / 143 \ttrain loss: 0.6326 \ttrain accuracy: 0.7656 \ttime: 0.6991 s\n",
      "epoch: 22 \tstep: 100 / 143 \ttrain loss: 0.7405 \ttrain accuracy: 0.7031 \ttime: 0.2612 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22 / 40 \ttrain loss: 0.6256 \tvalid loss: 0.6945 \ttrain accuracy 0.7764 \tvalid accuracy 0.7573\n",
      "Model saved to: model.pth\n",
      "epoch: 23 \tstep: 50 / 143 \ttrain loss: 0.5815 \ttrain accuracy: 0.7734 \ttime: 1.5297 s\n",
      "epoch: 23 \tstep: 100 / 143 \ttrain loss: 0.5451 \ttrain accuracy: 0.8125 \ttime: 0.7500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23 / 40 \ttrain loss: 0.6211 \tvalid loss: 0.6920 \ttrain accuracy 0.7783 \tvalid accuracy 0.7580\n",
      "Model saved to: model.pth\n",
      "epoch: 24 \tstep: 50 / 143 \ttrain loss: 0.6088 \ttrain accuracy: 0.8281 \ttime: 0.7000 s\n",
      "epoch: 24 \tstep: 100 / 143 \ttrain loss: 0.6607 \ttrain accuracy: 0.7734 \ttime: 0.7815 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24 / 40 \ttrain loss: 0.6155 \tvalid loss: 0.6892 \ttrain accuracy 0.7824 \tvalid accuracy 0.7594\n",
      "Model saved to: model.pth\n",
      "epoch: 25 \tstep: 50 / 143 \ttrain loss: 0.5586 \ttrain accuracy: 0.7969 \ttime: 0.7000 s\n",
      "epoch: 25 \tstep: 100 / 143 \ttrain loss: 0.4709 \ttrain accuracy: 0.8281 \ttime: 0.7818 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25 / 40 \ttrain loss: 0.6119 \tvalid loss: 0.6874 \ttrain accuracy 0.7811 \tvalid accuracy 0.7574\n",
      "Model saved to: model.pth\n",
      "epoch: 26 \tstep: 50 / 143 \ttrain loss: 0.6600 \ttrain accuracy: 0.7344 \ttime: 0.9455 s\n",
      "epoch: 26 \tstep: 100 / 143 \ttrain loss: 0.5585 \ttrain accuracy: 0.8438 \ttime: 0.4007 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 / 40 \ttrain loss: 0.6048 \tvalid loss: 0.6871 \ttrain accuracy 0.7839 \tvalid accuracy 0.7620\n",
      "Model saved to: model.pth\n",
      "epoch: 27 \tstep: 50 / 143 \ttrain loss: 0.7487 \ttrain accuracy: 0.7031 \ttime: 0.0000 s\n",
      "epoch: 27 \tstep: 100 / 143 \ttrain loss: 0.6243 \ttrain accuracy: 0.7734 \ttime: 0.4931 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27 / 40 \ttrain loss: 0.6000 \tvalid loss: 0.6858 \ttrain accuracy 0.7853 \tvalid accuracy 0.7646\n",
      "Model saved to: model.pth\n",
      "epoch: 28 \tstep: 50 / 143 \ttrain loss: 0.5400 \ttrain accuracy: 0.7891 \ttime: 0.7491 s\n",
      "epoch: 28 \tstep: 100 / 143 \ttrain loss: 0.5669 \ttrain accuracy: 0.7891 \ttime: 0.7806 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28 / 40 \ttrain loss: 0.5966 \tvalid loss: 0.6826 \ttrain accuracy 0.7869 \tvalid accuracy 0.7594\n",
      "Model saved to: model.pth\n",
      "epoch: 29 \tstep: 50 / 143 \ttrain loss: 0.5459 \ttrain accuracy: 0.7891 \ttime: 0.6000 s\n",
      "epoch: 29 \tstep: 100 / 143 \ttrain loss: 0.5710 \ttrain accuracy: 0.7969 \ttime: 0.6996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 49.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29 / 40 \ttrain loss: 0.5927 \tvalid loss: 0.6830 \ttrain accuracy 0.7866 \tvalid accuracy 0.7594\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 30 \tstep: 50 / 143 \ttrain loss: 0.6000 \ttrain accuracy: 0.7891 \ttime: 0.6499 s\n",
      "epoch: 30 \tstep: 100 / 143 \ttrain loss: 0.5552 \ttrain accuracy: 0.8203 \ttime: 0.8499 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 49.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30 / 40 \ttrain loss: 0.5857 \tvalid loss: 0.6828 \ttrain accuracy 0.7899 \tvalid accuracy 0.7627\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 31 \tstep: 50 / 143 \ttrain loss: 0.6702 \ttrain accuracy: 0.7422 \ttime: 0.7812 s\n",
      "epoch: 31 \tstep: 100 / 143 \ttrain loss: 0.4736 \ttrain accuracy: 0.8438 \ttime: 0.6037 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31 / 40 \ttrain loss: 0.5845 \tvalid loss: 0.6822 \ttrain accuracy 0.7911 \tvalid accuracy 0.7620\n",
      "Model saved to: model.pth\n",
      "epoch: 32 \tstep: 50 / 143 \ttrain loss: 0.5399 \ttrain accuracy: 0.7812 \ttime: 0.8011 s\n",
      "epoch: 32 \tstep: 100 / 143 \ttrain loss: 0.6583 \ttrain accuracy: 0.7734 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32 / 40 \ttrain loss: 0.5775 \tvalid loss: 0.6810 \ttrain accuracy 0.7934 \tvalid accuracy 0.7626\n",
      "Model saved to: model.pth\n",
      "epoch: 33 \tstep: 50 / 143 \ttrain loss: 0.5938 \ttrain accuracy: 0.7812 \ttime: 0.7812 s\n",
      "epoch: 33 \tstep: 100 / 143 \ttrain loss: 0.6210 \ttrain accuracy: 0.7891 \ttime: 0.8232 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33 / 40 \ttrain loss: 0.5711 \tvalid loss: 0.6821 \ttrain accuracy 0.7974 \tvalid accuracy 0.7627\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 34 \tstep: 50 / 143 \ttrain loss: 0.4567 \ttrain accuracy: 0.8203 \ttime: 0.7813 s\n",
      "epoch: 34 \tstep: 100 / 143 \ttrain loss: 0.6541 \ttrain accuracy: 0.7500 \ttime: 0.7776 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 / 40 \ttrain loss: 0.5696 \tvalid loss: 0.6805 \ttrain accuracy 0.7945 \tvalid accuracy 0.7627\n",
      "Model saved to: model.pth\n",
      "epoch: 35 \tstep: 50 / 143 \ttrain loss: 0.5712 \ttrain accuracy: 0.7812 \ttime: 0.7772 s\n",
      "epoch: 35 \tstep: 100 / 143 \ttrain loss: 0.6587 \ttrain accuracy: 0.7578 \ttime: 0.6991 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 / 40 \ttrain loss: 0.5647 \tvalid loss: 0.6837 \ttrain accuracy 0.7973 \tvalid accuracy 0.7639\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 36 \tstep: 50 / 143 \ttrain loss: 0.5840 \ttrain accuracy: 0.7734 \ttime: 0.7844 s\n",
      "epoch: 36 \tstep: 100 / 143 \ttrain loss: 0.4909 \ttrain accuracy: 0.8359 \ttime: 0.8432 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 / 40 \ttrain loss: 0.5607 \tvalid loss: 0.6818 \ttrain accuracy 0.8009 \tvalid accuracy 0.7633\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 37 \tstep: 50 / 143 \ttrain loss: 0.6012 \ttrain accuracy: 0.7891 \ttime: 0.5499 s\n",
      "epoch: 37 \tstep: 100 / 143 \ttrain loss: 0.6432 \ttrain accuracy: 0.7422 \ttime: 0.5541 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37 / 40 \ttrain loss: 0.5553 \tvalid loss: 0.6839 \ttrain accuracy 0.8032 \tvalid accuracy 0.7646\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 38 \tstep: 50 / 143 \ttrain loss: 0.4834 \ttrain accuracy: 0.8281 \ttime: 1.1027 s\n",
      "epoch: 38 \tstep: 100 / 143 \ttrain loss: 0.4945 \ttrain accuracy: 0.8516 \ttime: 0.7118 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 52.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38 / 40 \ttrain loss: 0.5489 \tvalid loss: 0.6825 \ttrain accuracy 0.8031 \tvalid accuracy 0.7627\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 98.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.6663 \ttest accuracy 0.7674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ed45e",
   "metadata": {},
   "source": [
    "**LSTM + CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84354e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, dropout=0.1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer1 = nn.Sequential(\n",
    "                            nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
    "                            nn.BatchNorm1d(out_channels),\n",
    "                            nn.ReLU()\n",
    "                )\n",
    "        self.layer2 = nn.Sequential(\n",
    "                            nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                            nn.BatchNorm1d(out_channels)\n",
    "                )\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.downsample = nn.Sequential(\n",
    "                                    nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
    "                                    nn.BatchNorm1d(out_channels),\n",
    "                    )\n",
    "        else:\n",
    "            self.downsample = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(residual)\n",
    "        x = x + residual\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=5, dropout=0.1, num_layers=2, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "        layers = []\n",
    "        in_channels = hidden_dim * 2\n",
    "        out_channels = hidden_dim\n",
    "        for _ in range(2):\n",
    "            layers.extend([\n",
    "                    ResidualBlock(in_channels, in_channels, stride=1, dropout=dropout),\n",
    "                    ResidualBlock(in_channels, out_channels, stride=2, dropout=dropout), \n",
    "                ])\n",
    "            in_channels = out_channels \n",
    "            out_channels //= 2\n",
    "        self.residuals = nn.Sequential(*layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_mid = nn.Linear(hidden_dim*8, hidden_dim*2)\n",
    "        self.fc_out = nn.Linear(hidden_dim*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.embedding(x)\n",
    "                \n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        x = x.contiguous().transpose(1,2)  # permute channels and features\n",
    "        x = self.residuals(x)\n",
    "        x = x.contiguous().view(batch_size, -1)\n",
    "\n",
    "        x = F.relu(self.fc_mid(self.dropout(x)))\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68f7e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_layers=1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f7336ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 143 \ttrain loss: 1.0797 \ttrain accuracy: 0.6641 \ttime: 1.1514 s\n",
      "epoch: 1 \tstep: 100 / 143 \ttrain loss: 0.8327 \ttrain accuracy: 0.7266 \ttime: 1.2996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 46.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 0.9891 \tvalid loss: 0.8372 \ttrain accuracy 0.6851 \tvalid accuracy 0.7081\n",
      "epoch: 2 \tstep: 50 / 143 \ttrain loss: 0.7938 \ttrain accuracy: 0.7500 \ttime: 0.7808 s\n",
      "epoch: 2 \tstep: 100 / 143 \ttrain loss: 0.7792 \ttrain accuracy: 0.7344 \ttime: 0.8496 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.8299 \tvalid loss: 0.7961 \ttrain accuracy 0.7194 \tvalid accuracy 0.7300\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 143 \ttrain loss: 0.7601 \ttrain accuracy: 0.7266 \ttime: 0.7808 s\n",
      "epoch: 3 \tstep: 100 / 143 \ttrain loss: 0.9265 \ttrain accuracy: 0.6797 \ttime: 1.4932 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.7908 \tvalid loss: 0.7626 \ttrain accuracy 0.7273 \tvalid accuracy 0.7275\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 143 \ttrain loss: 0.7310 \ttrain accuracy: 0.7500 \ttime: 1.0858 s\n",
      "epoch: 4 \tstep: 100 / 143 \ttrain loss: 0.7474 \ttrain accuracy: 0.7266 \ttime: 1.9822 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.7602 \tvalid loss: 0.7450 \ttrain accuracy 0.7328 \tvalid accuracy 0.7254\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 143 \ttrain loss: 0.6807 \ttrain accuracy: 0.7500 \ttime: 0.8000 s\n",
      "epoch: 5 \tstep: 100 / 143 \ttrain loss: 0.7815 \ttrain accuracy: 0.7188 \ttime: 0.8996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 61.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.7442 \tvalid loss: 0.7407 \ttrain accuracy 0.7376 \tvalid accuracy 0.7351\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 143 \ttrain loss: 0.6892 \ttrain accuracy: 0.7656 \ttime: 0.7813 s\n",
      "epoch: 6 \tstep: 100 / 143 \ttrain loss: 0.7314 \ttrain accuracy: 0.7500 \ttime: 0.6180 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 61.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.7283 \tvalid loss: 0.7285 \ttrain accuracy 0.7436 \tvalid accuracy 0.7372\n",
      "Model saved to: model.pth\n",
      "epoch: 7 \tstep: 50 / 143 \ttrain loss: 0.8850 \ttrain accuracy: 0.6875 \ttime: 1.4497 s\n",
      "epoch: 7 \tstep: 100 / 143 \ttrain loss: 0.6061 \ttrain accuracy: 0.7734 \ttime: 0.9000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.7182 \tvalid loss: 0.7834 \ttrain accuracy 0.7440 \tvalid accuracy 0.7252\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 8 \tstep: 50 / 143 \ttrain loss: 0.8270 \ttrain accuracy: 0.7266 \ttime: 1.5094 s\n",
      "epoch: 8 \tstep: 100 / 143 \ttrain loss: 0.6053 \ttrain accuracy: 0.8281 \ttime: 0.8500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.7132 \tvalid loss: 0.7246 \ttrain accuracy 0.7460 \tvalid accuracy 0.7377\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 143 \ttrain loss: 0.8092 \ttrain accuracy: 0.6875 \ttime: 0.8500 s\n",
      "epoch: 9 \tstep: 100 / 143 \ttrain loss: 0.6394 \ttrain accuracy: 0.7500 \ttime: 0.9500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 54.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.6986 \tvalid loss: 0.7253 \ttrain accuracy 0.7497 \tvalid accuracy 0.7370\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 10 \tstep: 50 / 143 \ttrain loss: 0.6530 \ttrain accuracy: 0.7734 \ttime: 0.9500 s\n",
      "epoch: 10 \tstep: 100 / 143 \ttrain loss: 0.7112 \ttrain accuracy: 0.7109 \ttime: 0.8468 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.6880 \tvalid loss: 0.7099 \ttrain accuracy 0.7556 \tvalid accuracy 0.7436\n",
      "Model saved to: model.pth\n",
      "epoch: 11 \tstep: 50 / 143 \ttrain loss: 0.6249 \ttrain accuracy: 0.7734 \ttime: 0.7818 s\n",
      "epoch: 11 \tstep: 100 / 143 \ttrain loss: 0.6996 \ttrain accuracy: 0.7422 \ttime: 0.9134 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 56.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.6777 \tvalid loss: 0.7400 \ttrain accuracy 0.7598 \tvalid accuracy 0.7390\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 12 \tstep: 50 / 143 \ttrain loss: 0.7106 \ttrain accuracy: 0.7422 \ttime: 1.5624 s\n",
      "epoch: 12 \tstep: 100 / 143 \ttrain loss: 0.6282 \ttrain accuracy: 0.7891 \ttime: 0.9947 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.6699 \tvalid loss: 0.7050 \ttrain accuracy 0.7633 \tvalid accuracy 0.7437\n",
      "Model saved to: model.pth\n",
      "epoch: 13 \tstep: 50 / 143 \ttrain loss: 0.6872 \ttrain accuracy: 0.7188 \ttime: 0.7807 s\n",
      "epoch: 13 \tstep: 100 / 143 \ttrain loss: 0.6602 \ttrain accuracy: 0.7266 \ttime: 0.8504 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 / 40 \ttrain loss: 0.6659 \tvalid loss: 0.7196 \ttrain accuracy 0.7631 \tvalid accuracy 0.7430\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 14 \tstep: 50 / 143 \ttrain loss: 0.6351 \ttrain accuracy: 0.7578 \ttime: 0.3069 s\n",
      "epoch: 14 \tstep: 100 / 143 \ttrain loss: 0.6999 \ttrain accuracy: 0.7188 \ttime: 1.1346 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 / 40 \ttrain loss: 0.6559 \tvalid loss: 0.7259 \ttrain accuracy 0.7667 \tvalid accuracy 0.7422\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 15 \tstep: 50 / 143 \ttrain loss: 0.7012 \ttrain accuracy: 0.7266 \ttime: 0.7826 s\n",
      "epoch: 15 \tstep: 100 / 143 \ttrain loss: 0.5366 \ttrain accuracy: 0.8203 \ttime: 1.2471 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 60.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 / 40 \ttrain loss: 0.6497 \tvalid loss: 0.7005 \ttrain accuracy 0.7670 \tvalid accuracy 0.7450\n",
      "Model saved to: model.pth\n",
      "epoch: 16 \tstep: 50 / 143 \ttrain loss: 0.5232 \ttrain accuracy: 0.8203 \ttime: 1.4925 s\n",
      "epoch: 16 \tstep: 100 / 143 \ttrain loss: 0.6563 \ttrain accuracy: 0.7344 \ttime: 0.9504 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 58.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 / 40 \ttrain loss: 0.6418 \tvalid loss: 0.6988 \ttrain accuracy 0.7714 \tvalid accuracy 0.7475\n",
      "Model saved to: model.pth\n",
      "epoch: 17 \tstep: 50 / 143 \ttrain loss: 0.5102 \ttrain accuracy: 0.8516 \ttime: 1.1846 s\n",
      "epoch: 17 \tstep: 100 / 143 \ttrain loss: 0.7219 \ttrain accuracy: 0.7344 \ttime: 1.0408 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 / 40 \ttrain loss: 0.6316 \tvalid loss: 0.7110 \ttrain accuracy 0.7733 \tvalid accuracy 0.7396\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 18 \tstep: 50 / 143 \ttrain loss: 0.6631 \ttrain accuracy: 0.7500 \ttime: 0.6060 s\n",
      "epoch: 18 \tstep: 100 / 143 \ttrain loss: 0.4072 \ttrain accuracy: 0.8828 \ttime: 0.9472 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 / 40 \ttrain loss: 0.6260 \tvalid loss: 0.6994 \ttrain accuracy 0.7773 \tvalid accuracy 0.7488\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 19 \tstep: 50 / 143 \ttrain loss: 0.6293 \ttrain accuracy: 0.7578 \ttime: 0.7820 s\n",
      "epoch: 19 \tstep: 100 / 143 \ttrain loss: 0.6642 \ttrain accuracy: 0.7188 \ttime: 2.0393 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 59.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 / 40 \ttrain loss: 0.6150 \tvalid loss: 0.7309 \ttrain accuracy 0.7798 \tvalid accuracy 0.7489\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 20 \tstep: 50 / 143 \ttrain loss: 0.4249 \ttrain accuracy: 0.8750 \ttime: 0.9496 s\n",
      "epoch: 20 \tstep: 100 / 143 \ttrain loss: 0.5064 \ttrain accuracy: 0.8438 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 57.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 / 40 \ttrain loss: 0.6039 \tvalid loss: 0.7035 \ttrain accuracy 0.7832 \tvalid accuracy 0.7476\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.6778 \ttest accuracy 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61badf",
   "metadata": {},
   "source": [
    "**Transformer Encoder + positional encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3dc3303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_transform(token_ids, drop_specials=False):\n",
    "    if drop_specials:\n",
    "        return torch.tensor(token_ids)\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "def validate_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "    texts, labels = data\n",
    "    \n",
    "    out = model(texts)\n",
    "    loss = criterion(out, labels)\n",
    "    \n",
    "    accuracy = calc_accuracy(out, labels)\n",
    "    \n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "text_transform = sequential_transforms(token_transform,\n",
    "                                       vocabulary,\n",
    "                                       tensor_transform)\n",
    "\n",
    "train_ds = TextDataset(train)\n",
    "valid_ds = TextDataset(valid)\n",
    "test_ds = TextDataset(test)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=train_ds.collate_fn)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=128, collate_fn=valid_ds.collate_fn)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=64, collate_fn=test_ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d1961a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=500):  # max_len = max batch\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.scale * self.pe[:x.size(0), :]  # [B,seq_len,hidden] + s*[B,1,hidden] = every sentence is encoded similar\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * np.sqrt(self.emb_size)\n",
    "    \n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, dropout, relu=False):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc1 = nn.Linear(dim, dim//2)\n",
    "        self.fc2 = nn.Linear(dim//2, dim//4)\n",
    "        self.relu = nn.ReLU() if relu else nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden, num_classes=5, enc_layers=2, nhead=4, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.embedding = TokenEmbedding(vocab_size, hidden)\n",
    "        self.pos_encoder = PositionalEncoding(hidden, dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden,\n",
    "                                                   nhead=nhead, \n",
    "                                                   dim_feedforward=hidden*4, \n",
    "                                                   dropout=dropout,\n",
    "                                                   activation=nn.ReLU(), \n",
    "                                                   batch_first=True,\n",
    "                                                   norm_first=False)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=enc_layers)\n",
    "        \n",
    "        self.mlp = MLP(hidden*hidden, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden*hidden//4, num_classes)\n",
    "        \n",
    "        for p in self.parameters():  # more acceptable for transformer than kaiming\n",
    "            if p.dim() > 1:  # not bias\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        # self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, module):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal(m.weight, mode='fan_in')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant(m.weight, 1)\n",
    "                nn.init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight, mode='fan_in')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant(m.bias, 0) \n",
    "\n",
    "    def make_len_mask(self, inp):\n",
    "        return (inp == PAD_IDX).transpose(0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pad_mask = self.make_len_mask(x).transpose(0,1)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        output = self.transformer(src=x, src_key_padding_mask=pad_mask)\n",
    "        output = output.view(output.size(0), -1)\n",
    "\n",
    "        output = self.mlp(output)\n",
    "        \n",
    "        output = self.fc_out(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "174915dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = TransformerModel(len(vocabulary), hidden=64, num_classes=5, enc_layers=2, nhead=4, dropout=0.3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a626ddb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 143 \ttrain loss: 1.0800 \ttrain accuracy: 0.6641 \ttime: 0.0000 s\n",
      "epoch: 1 \tstep: 100 / 143 \ttrain loss: 1.0646 \ttrain accuracy: 0.6797 \ttime: 0.7821 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 46.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 1.0447 \tvalid loss: 1.4515 \ttrain accuracy 0.6920 \tvalid accuracy 0.3352\n",
      "epoch: 2 \tstep: 50 / 143 \ttrain loss: 0.8268 \ttrain accuracy: 0.7109 \ttime: 0.7841 s\n",
      "epoch: 2 \tstep: 100 / 143 \ttrain loss: 0.7028 \ttrain accuracy: 0.7578 \ttime: 0.5398 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.8469 \tvalid loss: 0.9109 \ttrain accuracy 0.7194 \tvalid accuracy 0.6891\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 143 \ttrain loss: 0.7635 \ttrain accuracy: 0.7109 \ttime: 0.7814 s\n",
      "epoch: 3 \tstep: 100 / 143 \ttrain loss: 0.6141 \ttrain accuracy: 0.8281 \ttime: 0.7500 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 52.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.7473 \tvalid loss: 0.7655 \ttrain accuracy 0.7462 \tvalid accuracy 0.7456\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 143 \ttrain loss: 0.6748 \ttrain accuracy: 0.7812 \ttime: 1.1456 s\n",
      "epoch: 4 \tstep: 100 / 143 \ttrain loss: 0.7424 \ttrain accuracy: 0.7500 \ttime: 1.2349 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 48.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.6955 \tvalid loss: 0.7187 \ttrain accuracy 0.7585 \tvalid accuracy 0.7521\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 143 \ttrain loss: 0.6082 \ttrain accuracy: 0.7500 \ttime: 0.7500 s\n",
      "epoch: 5 \tstep: 100 / 143 \ttrain loss: 0.6422 \ttrain accuracy: 0.7891 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 48.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.6658 \tvalid loss: 0.6953 \ttrain accuracy 0.7693 \tvalid accuracy 0.7575\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 143 \ttrain loss: 0.7145 \ttrain accuracy: 0.7344 \ttime: 0.6998 s\n",
      "epoch: 6 \tstep: 100 / 143 \ttrain loss: 0.7253 \ttrain accuracy: 0.7500 \ttime: 0.2040 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.6382 \tvalid loss: 0.7088 \ttrain accuracy 0.7776 \tvalid accuracy 0.7607\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 7 \tstep: 50 / 143 \ttrain loss: 0.7187 \ttrain accuracy: 0.7188 \ttime: 0.6588 s\n",
      "epoch: 7 \tstep: 100 / 143 \ttrain loss: 0.6011 \ttrain accuracy: 0.7891 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.6205 \tvalid loss: 0.7143 \ttrain accuracy 0.7842 \tvalid accuracy 0.7646\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 8 \tstep: 50 / 143 \ttrain loss: 0.6347 \ttrain accuracy: 0.7578 \ttime: 0.4602 s\n",
      "epoch: 8 \tstep: 100 / 143 \ttrain loss: 0.7941 \ttrain accuracy: 0.7109 \ttime: 0.7816 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.5944 \tvalid loss: 0.6942 \ttrain accuracy 0.7922 \tvalid accuracy 0.7673\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 143 \ttrain loss: 0.5664 \ttrain accuracy: 0.7969 \ttime: 0.6997 s\n",
      "epoch: 9 \tstep: 100 / 143 \ttrain loss: 0.5094 \ttrain accuracy: 0.8359 \ttime: 0.6996 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 49.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.5733 \tvalid loss: 0.7065 \ttrain accuracy 0.7989 \tvalid accuracy 0.7718\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 10 \tstep: 50 / 143 \ttrain loss: 0.5397 \ttrain accuracy: 0.8047 \ttime: 0.7813 s\n",
      "epoch: 10 \tstep: 100 / 143 \ttrain loss: 0.4515 \ttrain accuracy: 0.8516 \ttime: 0.6979 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.5614 \tvalid loss: 0.6984 \ttrain accuracy 0.8010 \tvalid accuracy 0.7691\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 11 \tstep: 50 / 143 \ttrain loss: 0.5216 \ttrain accuracy: 0.8281 \ttime: 0.7495 s\n",
      "epoch: 11 \tstep: 100 / 143 \ttrain loss: 0.5344 \ttrain accuracy: 0.8203 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.5405 \tvalid loss: 0.7543 \ttrain accuracy 0.8095 \tvalid accuracy 0.7659\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 12 \tstep: 50 / 143 \ttrain loss: 0.5297 \ttrain accuracy: 0.8203 \ttime: 0.7003 s\n",
      "epoch: 12 \tstep: 100 / 143 \ttrain loss: 0.5073 \ttrain accuracy: 0.8125 \ttime: 0.7807 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 53.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.5217 \tvalid loss: 0.7490 \ttrain accuracy 0.8170 \tvalid accuracy 0.7666\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 86.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.6841 \ttest accuracy 0.7689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66e62d",
   "metadata": {},
   "source": [
    "**Transformer & CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9da0e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module): \n",
    "    def __init__(self, d_model, dropout=0.1, max_len=500):  # max_len = max batch\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.scale * self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        return self.embedding(tokens.long()) * np.sqrt(self.emb_size)\n",
    "    \n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, dropout, relu=False, batchnorm=False, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "        self.batchnorm = batchnorm\n",
    "        \n",
    "        if batchnorm:\n",
    "            self.batch1 = nn.BatchNorm1d(dim//2)\n",
    "            self.batch2 = nn.BatchNorm1d(dim//4)\n",
    "            \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc1 = nn.Linear(dim, dim//2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(dim//2, dim//4)\n",
    "        self.relu = nn.ReLU() if relu else nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        if self.batchnorm:\n",
    "            x = self.batch1(x)\n",
    "        x = self.relu(x)        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        if self.batchnorm:\n",
    "            x = self.batch2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class KMaxPool(nn.Module):\n",
    "    def __init__(self, k=\"half\", **kwargs):\n",
    "        super(KMaxPool, self).__init__(**kwargs)\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x from transformer: batch_size, time_steps, channel\n",
    "        if self.k == \"half\":\n",
    "            time_steps = x.size(1)\n",
    "            self.k = time_steps // 2\n",
    "        k_max, k_argmax = x.topk(self.k, dim=1)\n",
    "        return k_max\n",
    "\n",
    "    \n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, ff_dim, nheads=4, dropout=0.1, mode=\"cnn\", activation=\"relu\", **kwargs):\n",
    "        super(TransformerEncoderLayer, self).__init__(**kwargs)\n",
    "        # scores = softmax(q@k_T / sqrt(d_model), + mask padding) @ v, q,k,v = x for encoder, q=x, k=v=enc_out for decoder x_att\n",
    "        # heads: q,k,v = reshape(batch_size, -1, nheads, d_model//nheads)\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=d_model, num_heads=nheads, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.ff_net = FFNetwork(in_channels=d_model, hidden=ff_dim, mode=mode, dropout=dropout, activation=activation)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        shortcut = x\n",
    "        x, _ = self.mha(query=x, key=x, value=x, key_padding_mask=mask)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = x + shortcut\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        x = self.ff_net(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class FFNetwork(nn.Module):\n",
    "    def __init__(self, in_channels, hidden, mode=\"cnn\", activation=\"relu\", dropout=0.1, **kwargs):\n",
    "        super(FFNetwork, self).__init__(**kwargs)\n",
    "        assert mode in [\"cnn\", \"linear\"], \"set mode to 'linear' or 'cnn'\"\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=hidden, kernel_size=1, padding=0)\n",
    "        self.activation = nn.ReLU() if activation == \"relu\" else nn.GELU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.conv2 = nn.Conv1d(in_channels=hidden, out_channels=in_channels, kernel_size=3, padding=1)\n",
    "        self.norm = nn.LayerNorm(in_channels)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=in_channels, out_features=hidden)\n",
    "        self.fc2 = nn.Linear(in_features=hidden, out_features=in_channels)\n",
    "        \n",
    "    def forward(self, x):  \n",
    "        if self.mode == \"cnn\":\n",
    "            x = x.contiguous().transpose(1,2)\n",
    "            shortcut = x\n",
    "            x = self.conv1(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.conv2(x)\n",
    "            \n",
    "        else:\n",
    "            shortcut = x\n",
    "            x = self.fc1(x)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            \n",
    "        x = x + shortcut\n",
    "        if self.mode == \"cnn\":\n",
    "            x = x.contiguous().transpose(1,2)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model=64, ff_dim=256, nheads=4, dropout=0.1, mode=\"cnn\", num_layers=2, activation=\"relu\", **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.layers = []\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            self.layers.append(TransformerEncoderLayer(d_model=d_model, \n",
    "                                                       ff_dim=ff_dim, \n",
    "                                                       nheads=nheads, \n",
    "                                                       dropout=dropout, \n",
    "                                                       mode=mode,\n",
    "                                                       activation=activation).to(device))\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden, num_classes=5, enc_layers=2, nhead=4, dropout=0.1, mode=\"cnn\", \n",
    "                 activation=\"relu\", kmax=None, **kwargs):\n",
    "        super(TransformerModel, self).__init__(**kwargs)\n",
    "        self.mode = mode\n",
    "        self.embedding = TokenEmbedding(vocab_size, hidden)\n",
    "        self.pos_encoder = PositionalEncoding(hidden, dropout)\n",
    "        \n",
    "        self.transformer = TransformerEncoder(d_model=hidden, \n",
    "                                              ff_dim=hidden*4, \n",
    "                                              nheads=nhead, \n",
    "                                              dropout=dropout, \n",
    "                                              mode=mode, \n",
    "                                              num_layers=enc_layers,\n",
    "                                              activation=activation)\n",
    "        \n",
    "        self.kmax = kmax\n",
    "        if kmax is not None:\n",
    "            if kmax == \"half\":\n",
    "                kmax = 32\n",
    "            self.kmax_pool = KMaxPool(k=kmax)\n",
    "            act = nn.ReLU() if activation == \"relu\" else nn.GELU()\n",
    "            self.reducer = nn.Sequential(\n",
    "                    nn.Linear(in_features=kmax*hidden, out_features=hidden),\n",
    "                    act\n",
    "                )\n",
    "            \n",
    "        self.mlp = MLP(hidden*hidden, dropout=dropout, batchnorm=True)\n",
    "        if mode == \"cnn\":\n",
    "            self.fc_out = nn.Linear(hidden, num_classes)\n",
    "        else:\n",
    "            self.fc_out = nn.Linear(hidden*hidden//4, num_classes)\n",
    "        \n",
    "        for p in self.parameters():  # more acceptable for transformer\n",
    "            if p.dim() > 1:  # not bias\n",
    "                nn.init.xavier_uniform_(p)\n",
    "        # self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, module):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal(m.weight, mode='fan_in')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant(m.weight, 1)\n",
    "                nn.init.constant(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal(m.weight, mode='fan_in')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant(m.bias, 0) \n",
    "\n",
    "    def make_len_mask(self, inp):\n",
    "        return (inp == PAD_IDX).transpose(0, 1)  # as originally x = [Seq, B]\n",
    "\n",
    "    def forward(self, x):\n",
    "        pad_mask = self.make_len_mask(x).transpose(0,1)  # transpose to [B, Seq] as x = [B, Seq], mha_inp = [B,Seq]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "        output = self.transformer(x, pad_mask)\n",
    "        if self.mode == \"cnn\":\n",
    "            if self.kmax is not None:\n",
    "                output = self.kmax_pool(x)\n",
    "                output = output.contiguous().view(output.size(0), -1)\n",
    "                output = self.reducer(output)\n",
    "            else:\n",
    "                output = torch.max(output, dim=1)[0]\n",
    "        else:\n",
    "            output = output.view(output.size(0), -1)\n",
    "            output = self.mlp(output)\n",
    "        \n",
    "        output = self.fc_out(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b3bcc6e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = TransformerModel(len(vocabulary), 64, num_classes=5, enc_layers=2, nhead=4, dropout=0.2, \n",
    "                         activation=\"relu\", mode=\"cnn\", kmax=None).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = FocalLoss()\n",
    "\n",
    "# betas = (0.9, 0.999), b1 (momentum) collects previous grads to skip local minima\n",
    "# b2 makes lr higher if grads were large at prev. step and vice versa\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.5, 0.9), weight_decay=0.0005)  \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "03fad044",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 143 \ttrain loss: 0.8964 \ttrain accuracy: 0.7266 \ttime: 0.1902 s\n",
      "epoch: 1 \tstep: 100 / 143 \ttrain loss: 0.7967 \ttrain accuracy: 0.7656 \ttime: 0.2835 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 48.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 0.9140 \tvalid loss: 0.8323 \ttrain accuracy 0.7074 \tvalid accuracy 0.7357\n",
      "epoch: 2 \tstep: 50 / 143 \ttrain loss: 0.6787 \ttrain accuracy: 0.7734 \ttime: 0.9616 s\n",
      "epoch: 2 \tstep: 100 / 143 \ttrain loss: 0.6841 \ttrain accuracy: 0.7656 \ttime: 0.6027 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 50.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.6941 \tvalid loss: 0.7436 \ttrain accuracy 0.7599 \tvalid accuracy 0.7476\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 143 \ttrain loss: 0.7149 \ttrain accuracy: 0.7500 \ttime: 0.7806 s\n",
      "epoch: 3 \tstep: 100 / 143 \ttrain loss: 0.7862 \ttrain accuracy: 0.7344 \ttime: 0.7783 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 49.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.6343 \tvalid loss: 0.7040 \ttrain accuracy 0.7785 \tvalid accuracy 0.7633\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 143 \ttrain loss: 0.4924 \ttrain accuracy: 0.8438 \ttime: 0.9515 s\n",
      "epoch: 4 \tstep: 100 / 143 \ttrain loss: 0.5545 \ttrain accuracy: 0.8047 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.5892 \tvalid loss: 0.6907 \ttrain accuracy 0.7952 \tvalid accuracy 0.7751\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 143 \ttrain loss: 0.5120 \ttrain accuracy: 0.8281 \ttime: 0.3083 s\n",
      "epoch: 5 \tstep: 100 / 143 \ttrain loss: 0.4012 \ttrain accuracy: 0.8672 \ttime: 0.7818 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 46.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.5442 \tvalid loss: 0.6733 \ttrain accuracy 0.8108 \tvalid accuracy 0.7789\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 143 \ttrain loss: 0.4425 \ttrain accuracy: 0.8438 \ttime: 0.6000 s\n",
      "epoch: 6 \tstep: 100 / 143 \ttrain loss: 0.4769 \ttrain accuracy: 0.8438 \ttime: 0.0000 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.4976 \tvalid loss: 0.6894 \ttrain accuracy 0.8299 \tvalid accuracy 0.7755\n",
      "INFO: Early stopping counter 1 of 5\n",
      "epoch: 7 \tstep: 50 / 143 \ttrain loss: 0.3671 \ttrain accuracy: 0.8984 \ttime: 0.7840 s\n",
      "epoch: 7 \tstep: 100 / 143 \ttrain loss: 0.3588 \ttrain accuracy: 0.8828 \ttime: 0.5069 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.4407 \tvalid loss: 0.7031 \ttrain accuracy 0.8545 \tvalid accuracy 0.7802\n",
      "INFO: Early stopping counter 2 of 5\n",
      "epoch: 8 \tstep: 50 / 143 \ttrain loss: 0.3080 \ttrain accuracy: 0.8984 \ttime: 0.5501 s\n",
      "epoch: 8 \tstep: 100 / 143 \ttrain loss: 0.4426 \ttrain accuracy: 0.8516 \ttime: 0.7813 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 55.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.3835 \tvalid loss: 0.7356 \ttrain accuracy 0.8783 \tvalid accuracy 0.7758\n",
      "INFO: Early stopping counter 3 of 5\n",
      "epoch: 9 \tstep: 50 / 143 \ttrain loss: 0.3166 \ttrain accuracy: 0.8906 \ttime: 0.0000 s\n",
      "epoch: 9 \tstep: 100 / 143 \ttrain loss: 0.3729 \ttrain accuracy: 0.8594 \ttime: 0.8595 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 52.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.3367 \tvalid loss: 0.7377 \ttrain accuracy 0.8950 \tvalid accuracy 0.7704\n",
      "INFO: Early stopping counter 4 of 5\n",
      "epoch: 10 \tstep: 50 / 143 \ttrain loss: 0.2639 \ttrain accuracy: 0.8906 \ttime: 0.7782 s\n",
      "epoch: 10 \tstep: 100 / 143 \ttrain loss: 0.3267 \ttrain accuracy: 0.9062 \ttime: 0.7815 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 51.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.3207 \tvalid loss: 0.7424 \ttrain accuracy 0.9030 \tvalid accuracy 0.7715\n",
      "INFO: Early stopping counter 5 of 5\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 82.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.6420 \ttest accuracy 0.7928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf8ee8",
   "metadata": {},
   "source": [
    "**Sber-AI RuRoberta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1373b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c42476cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/ruRoberta-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2d98b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"feedbacks_summer.xls\", parse_dates=[\"Date\"]).sort_values(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6c76756",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~(data[\"Content\"].str.len() == 0)]\n",
    "data[\"Rating\"] = data[\"Rating\"] - 1\n",
    "\n",
    "data[\"Content\"] = data[\"Content\"].apply(lambda x: clean_text(x, tokenized=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3edcd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size=0.1, shuffle=True, stratify=data[\"Rating\"], random_state=42)\n",
    "valid, test = train_test_split(valid, test_size=500, shuffle=True, random_state=42)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b5deafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_for_roberta(text):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for sent in tqdm(text):\n",
    "        encoded_sent = tokenizer(sent, padding='max_length', truncation=True, max_length=64)\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3bc6784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 18593/18593 [00:02<00:00, 7381.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1566/1566 [00:00<00:00, 7928.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 8164.95it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ids, train_masks = tokenize_for_roberta(train[\"Content\"].values)\n",
    "train_labels = torch.LongTensor(train[\"Rating\"].values)\n",
    "\n",
    "valid_ids, valid_masks = tokenize_for_roberta(valid[\"Content\"].values)\n",
    "valid_labels = torch.LongTensor(valid[\"Rating\"].values)\n",
    "\n",
    "test_ids, test_masks = tokenize_for_roberta(test[\"Content\"].values)\n",
    "test_labels = torch.LongTensor(test[\"Rating\"].values)\n",
    "\n",
    "train_ds = TensorDataset(train_ids, train_masks, train_labels)\n",
    "valid_ds = TensorDataset(valid_ids, valid_masks, valid_labels)\n",
    "test_ds = TensorDataset(test_ids, test_masks, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d00b6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)\n",
    "        sum_mask = input_mask_expanded.sum(dim=1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class MaxPooling(nn.Module):\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        last_hidden_state[input_mask_expanded == 0] = -1e9\n",
    "        max_embeddings = torch.max(last_hidden_state, dim=1)[0]\n",
    "        return max_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a751f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaModel(nn.Module):\n",
    "    def __init__(self, extractor=None, num_classes=5, dropout=0.1, pool_type=\"max\", **kwargs):\n",
    "        super(RobertaModel, self).__init__(**kwargs)\n",
    "        \n",
    "        if extractor is None:\n",
    "            self.extractor = AutoModelForMaskedLM.from_pretrained(\"sberbank-ai/ruRoberta-large\").to(device)\n",
    "        for p in self.extractor.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "        self.pooler = MaxPooling() if pool_type == \"max\" else MeanPooling()\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        out = self.extractor(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
    "        pooler = torch.cat(out.hidden_states, dim=1)[:, 0]  # [B, 1024] without pooling layer\n",
    "        \n",
    "        out = self.pooler(out.hidden_states[-1], mask)  # last layer hidden states [B, seq, hidden] - [8, 64, 1024]\n",
    "        out = self.drop(out)\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5388a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(data, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    data = [d.to(device) for d in data]\n",
    "    texts, masks, labels = data\n",
    "    optimizer.zero_grad()\n",
    "    output = model(texts, masks)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    accuracy = calc_accuracy(output, labels)\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "    data = [d.to(device) for d in data]\n",
    "    texts, masks, labels = data\n",
    "    \n",
    "    out = model(texts, masks)\n",
    "    loss = criterion(out, labels)\n",
    "    \n",
    "    accuracy = calc_accuracy(out, labels)\n",
    "    \n",
    "    return loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b284738",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = RobertaModel(pool_type=\"mean\").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(roberta.fc.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df9366",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(roberta, print_freq=500)  # out of memory for hold out check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b61305",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model.pth\", map_location=device)\n",
    "roberta = checkpoint[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eefb0a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:08<00:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.5871 \ttest accuracy 0.8016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accs = [], []\n",
    "for step, batch in enumerate(tqdm(test_dataloader)):\n",
    "    loss, accuracy = validate_one_batch(batch, roberta, criterion)\n",
    "\n",
    "    test_loss.append(loss)\n",
    "    test_accs.append(accuracy)\n",
    "\n",
    "print('\\ttest loss:', '{:.4f}'.format(np.mean(test_loss)),\n",
    "      '\\ttest accuracy', '{:.4f}'.format(np.mean(test_accs)),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbfe07a",
   "metadata": {},
   "source": [
    "**Simple model repeater**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b14bc6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    def __init__(self, hidden, vocab_size, num_classes=5):\n",
    "        super(Learner, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(2)\n",
    "        self.fc1 = nn.Linear(hidden*2, hidden)\n",
    "        self.fc = nn.Linear(hidden, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [B, seq, hidden]\n",
    "        x = x.contiguous().transpose(1,2)  # [B, hidden, seq]\n",
    "        \n",
    "        x = self.pool(x)  # [B, hidden, 2]\n",
    "        \n",
    "        x = x.contiguous().view(x.size(0), -1)  # [B, hidden * 2]\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65eb796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, beta=0.75, temperature=2.0, **kwargs):\n",
    "        super(DistillLoss, self).__init__(**kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.T = temperature\n",
    "    \n",
    "    def forward(self, outputs, labels, t_outputs):\n",
    "        log_out = F.log_softmax(outputs / self.T, dim=1)\n",
    "        t_log_out = F.softmax(t_outputs / self.T, dim=1)\n",
    "\n",
    "        kl_loss = F.kl_div(log_out, t_log_out) * (self.alpha * self.T**2)\n",
    "        ce_loss = F.cross_entropy(outputs, labels) * self.beta\n",
    "        \n",
    "        loss = kl_loss + ce_loss\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "919d453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(data, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    data = [d.to(device) for d in data]\n",
    "    \n",
    "    texts, masks, labels = data\n",
    "    \n",
    "    t_output = roberta(texts, masks)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(texts)\n",
    "    print(output)\n",
    "    print(output.shape)\n",
    "    \n",
    "    loss = criterion(output, labels, t_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    accuracy = calc_accuracy(output, labels)\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "    data = [d.to(device) for d in data]\n",
    "    texts, masks, labels = data\n",
    "\n",
    "    t_output = roberta(texts, masks)\n",
    "    \n",
    "    output = model(texts)\n",
    "    loss = criterion(output, labels, t_output)\n",
    "    \n",
    "    accuracy = calc_accuracy(out, labels)\n",
    "    \n",
    "    return loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8197a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = Learner(64, len(vocabulary)).to(device)\n",
    "roberta.eval()\n",
    "\n",
    "if device == 'cuda':\n",
    "    student = nn.DataParallel(student)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "criterion = DistillLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4, path=\"student.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc058c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, print_freq = 40, 500\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    train_loss, train_accs = [], []\n",
    "    for step, batch in enumerate(train_dataloader, 1):\n",
    "        time_1 = time.time()\n",
    "\n",
    "        loss, accuracy = train_one_batch(batch, student, criterion, optimizer)\n",
    "\n",
    "        train_loss.append(loss)\n",
    "        train_accs.append(accuracy)\n",
    "\n",
    "        if step % print_freq == 0:\n",
    "            print('epoch:', epoch, \n",
    "                  '\\tstep:', step, '/', len(train_dataloader),\n",
    "                  '\\ttrain loss:', '{:.4f}'.format(loss),\n",
    "                  '\\ttrain accuracy:','{:.4f}'.format(accuracy),\n",
    "                  '\\ttime:', '{:.4f}'.format((time.time()-time_1)*print_freq), 's')\n",
    "\n",
    "    valid_loss, valid_accs = [], []\n",
    "    for step, batch in enumerate(tqdm(valid_dataloader)):\n",
    "        loss, accuracy = validate_one_batch(batch, student, criterion)\n",
    "\n",
    "        valid_loss.append(loss)\n",
    "        valid_accs.append(accuracy)\n",
    "\n",
    "    print('epoch:', epoch, '/', epochs,\n",
    "          '\\ttrain loss:', '{:.4f}'.format(np.mean(train_loss)),\n",
    "          '\\tvalid loss:', '{:.4f}'.format(np.mean(valid_loss)),\n",
    "          '\\ttrain accuracy', '{:.4f}'.format(np.mean(train_accs)),\n",
    "          '\\tvalid accuracy', '{:.4f}'.format(np.mean(valid_accs)))\n",
    "\n",
    "    stopper(np.mean(valid_loss), model)\n",
    "    if stopper.early_stop:\n",
    "        checkpoint = torch.load(\"model.pth\", map_location=device)\n",
    "        model = checkpoint['model']\n",
    "        break\n",
    "    scheduler.step(np.mean(valid_loss))\n",
    "\n",
    "test_loss, test_accs = [], []\n",
    "for step, batch in enumerate(tqdm(test_dataloader)):\n",
    "    loss, accuracy = validate_one_batch(batch, student, criterion)\n",
    "\n",
    "    test_loss.append(loss)\n",
    "    test_accs.append(accuracy)\n",
    "\n",
    "print('\\ttest loss:', '{:.4f}'.format(np.mean(test_loss)),\n",
    "      '\\ttest accuracy', '{:.4f}'.format(np.mean(test_accs)),)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test1] *",
   "language": "python",
   "name": "conda-env-test1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
