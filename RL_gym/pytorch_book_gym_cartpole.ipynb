{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_book_gym_cartpole.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVI_gVN4oE56",
        "outputId": "2cb985ae-33a5-4ea8-f882-c982a79ad9c2"
      },
      "source": [
        "!apt-get install -y xvfb python-opengl\n",
        "!pip install gym pyvirtualdisplay"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,281 kB of archives.\n",
            "After this operation, 7,686 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 1,281 kB in 1s (1,116 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-2.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYLKfExNo9dC"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import cv2\n",
        "from collections import deque, namedtuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57PezN23p4Do"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhcnOfX-p-SC"
      },
      "source": [
        "display = Display(visible=0, size=(400, 400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXNsWcpwqXrb"
      },
      "source": [
        "class DQNetwork(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 24)\n",
        "        self.fc2 = nn.Linear(24, 24)\n",
        "        self.fc3 = nn.Linear(24, action_size)\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tbl7o8yrJvW"
      },
      "source": [
        "class Agent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(0)\n",
        "        self.buffer_size = 2000\n",
        "        self.batch_size = 64\n",
        "        self.gamma = 0.99\n",
        "        self.lr = 0.0025\n",
        "        self.update_every = 4\n",
        "        self.local = DQNetwork(state_size, action_size).to(device)\n",
        "        self.optimizer = optim.Adam(self.local.parameters(), lr=self.lr)\n",
        "        self.memory = deque(maxlen=self.buffer_size)\n",
        "        self.experience = namedtuple('Experience', field_names=['state', 'action', 'reward', 'next_state',\n",
        "                                                                'done'])\n",
        "        self.t_step = 0\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        self.memory.append(self.experience(state, action, reward, next_state, done))\n",
        "        self.t_step = (self.t_step + 1) % self.update_every\n",
        "        if self.t_step == 0:\n",
        "            if len(self.memory) > self.batch_size:\n",
        "                experiences = self.sample_experiences()\n",
        "                self.learn(experiences, self.gamma)\n",
        "\n",
        "    def learn(self, experiences, gamma):\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "        Q_expected = self.local(states).gather(1, actions)\n",
        "        Q_targets_next = self.local(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "    \n",
        "    def act(self, state, eps=0.):\n",
        "        if random.random() > eps:\n",
        "            state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "            self.local.eval()\n",
        "            with torch.no_grad():\n",
        "                action_values = self.local(state)\n",
        "            self.local.train()\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def sample_experiences(self):\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "        return states, actions, rewards, next_states, dones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bvB0ksnqKQL"
      },
      "source": [
        "display.start()\n",
        "env = gym.make('CartPole-v1')\n",
        "agent = Agent(env.observation_space.shape[0], env.action_space.n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I07Ds1vJw1EX"
      },
      "source": [
        "scores = []\n",
        "scores_window = deque(maxlen=100)\n",
        "n_episodes = 5000\n",
        "max_t = 5000\n",
        "eps_start = 1.0\n",
        "eps_end = 0.001\n",
        "eps_decay = 0.9995\n",
        "eps = eps_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "rAfnp1UixdbP",
        "outputId": "2acf1b46-dab7-4a79-eb08-fc3341fd33b0"
      },
      "source": [
        "for i_episode in range(1, n_episodes + 1):\n",
        "    state = env.reset()\n",
        "    prev_screen = env.render(mode='rgb_array')\n",
        "    plt.imshow(prev_screen)\n",
        "    state_size = env.observation_space.shape[0]\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    score = 0\n",
        "\n",
        "    for i in range(max_t):  \n",
        "        action = agent.act(state, eps)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        screen = env.render(mode='rgb_array')\n",
        "        plt.imshow(screen)\n",
        "        ipythondisplay.clear_output(wait=True)\n",
        "        ipythondisplay.display(plt.gcf())\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        reward = reward if not done or score == 499 else -10\n",
        "        agent.step(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        score += reward\n",
        "        if done:\n",
        "            break\n",
        "    ipythondisplay.clear_output(wait=True)\n",
        "    scores_window.append(score)\n",
        "    scores.append(score)\n",
        "    eps = max(eps_end, eps_decay * eps)\n",
        "    time.sleep(2)\n",
        "    print('\\rEpisode: {}\\tReward: {} \\tAverage Score: {:.2f} \\tEpsilon: {}'.format(i_episode, score, \n",
        "                                                                                   np.mean(scores_window), eps), \n",
        "          end='')\n",
        "    if i_episode % 100 == 0:\n",
        "        time.sleep(2)\n",
        "        print('\\rEpisode: {} \\tAverage Score: {:.2f} \\tEpsilon: {}'.format(i_episode, np.mean(scores_window), eps))\n",
        "    if i_episode > 10 and np.mean(scores[-10:]) > 450:\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIjbDNAn31FD"
      },
      "source": [
        "plt.plot(scores)\n",
        "plt.title('Scores over increasing episodes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnZcyNZX0I9o"
      },
      "source": [
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyEGZI_QLf1j",
        "outputId": "65840cd6-4b62-44fe-85fb-6b02f0cc66fe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement colorization (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for colorization\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}